{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_fastai.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wtzJO_iVMWcm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "EFF COLAB. enough nonesense, random errors, frequent disconnections. downloading this notebook going local.\n",
        "\n",
        "## IMDb \n",
        "implementing fastai's version of imdb text classification. in other notebook, adopting for D"
      ]
    },
    {
      "metadata": {
        "id": "loEJj5O7J0Ex",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "figure out how to save model. \n",
        "upload data from deloitte,  process test data in same way as other data. \n",
        "get a good pred, upload\n",
        "\n",
        "data in. rationalize data structure. had mismatch with max 1000"
      ]
    },
    {
      "metadata": {
        "id": "T9jMDrgPMWcn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At Fast.ai we have introduced a new module called fastai.text which replaces the torchtext library that was used in our 2018 dl1 course. The fastai.text module also supersedes the fastai.nlp library but retains many of the key functions."
      ]
    },
    {
      "metadata": {
        "id": "cVqBQoL1HXG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1 # kills the kernal, loses the machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CGv--rGmMxbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install fastai\n",
        "!pip install git+https://github.com/fastai/fastai.git # grabbing latest version\n",
        "!pip install spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qGNYbbAHMWcp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.text import *\n",
        "import html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g86Ey53PMWcv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Fastai.text module introduces several custom tokens.\n",
        "\n",
        "We need to download the IMDB large movie reviews from this site: http://ai.stanford.edu/~amaas/data/sentiment/\n",
        "Direct link : [Link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) and untar it into the PATH location. We use pathlib which makes directory traveral a breeze."
      ]
    },
    {
      "metadata": {
        "id": "lqqb_xRRMWcw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BOS = 'xbos'  # beginning-of-sentence tag\n",
        "FLD = 'xfld'  # data field tag\n",
        "\n",
        "PATH=Path('imdb_data/aclImdb/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eva7LVasSRWI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aadc358-a660-4f83-cf2b-5973a7e7c8aa"
      },
      "cell_type": "code",
      "source": [
        "!mkdir \"imdb_data\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘imdb_data’: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8JcYbeJPPWEK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Downloading IMDB dataset\n",
        "!curl http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz | tar xvz -C \"imdb_data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kNbwDW_UMWc0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Standardize format"
      ]
    },
    {
      "metadata": {
        "id": "kz3P4RXaMWc1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "CLAS_PATH=Path('imdb_data/imdb_clas/')\n",
        "CLAS_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "LM_PATH=Path('imdb_data/imdb_lm/')\n",
        "LM_PATH.mkdir(exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEeU74qNMWc5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The imdb dataset has 3 classes. positive, negative and unsupervised(sentiment is unknown). \n",
        "There are 75k training reviews(12.5k pos, 12.5k neg, 50k unsup)\n",
        "There are 25k validation reviews(12.5k pos, 12.5k neg & no unsup)\n",
        "\n",
        "Refer to the README file in the imdb corpus for further information about the dataset."
      ]
    },
    {
      "metadata": {
        "id": "nu_qI7rSMWc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Grabbing text and labels from files, saving in np array. D data shouldn't have to do this.\n",
        "\n",
        "CLASSES = ['neg', 'pos', 'unsup']\n",
        "MAX = 10000 # just for getting set up\n",
        "\n",
        "def get_texts(path):\n",
        "    texts,labels = [],[]\n",
        "    for idx,label in enumerate(CLASSES):\n",
        "        for fname in (path/label).glob('*.*'):\n",
        "            texts.append(fname.open('r').read())\n",
        "            labels.append(idx)\n",
        "    return np.array(texts)[:MAX],np.array(labels)[:MAX]\n",
        "    #return np.array(texts),np.array(labels)\n",
        "\n",
        "trn_texts,trn_labels = get_texts(PATH/'train')\n",
        "val_texts,val_labels = get_texts(PATH/'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2vW76jrMWc9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b83ac64e-090a-4c9a-f209-044d976cbb45"
      },
      "cell_type": "code",
      "source": [
        "len(trn_texts),len(val_texts)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "vodLUCvlMWdD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "col_names = ['labels','text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2UJthMKMWdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use a random permutation np array to shuffle the text reviews."
      ]
    },
    {
      "metadata": {
        "id": "lsYKbsIqMWdG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.random.seed(42)\n",
        "trn_idx = np.random.permutation(len(trn_texts))\n",
        "val_idx = np.random.permutation(len(val_texts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qDkLtJKGMWdJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_texts = trn_texts[trn_idx]\n",
        "val_texts = val_texts[val_idx]\n",
        "\n",
        "trn_labels = trn_labels[trn_idx]\n",
        "val_labels = val_labels[val_idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PslKkYK8dsfS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "48388b6a-3067-4b4d-b131-2a1a62617967"
      },
      "cell_type": "code",
      "source": [
        "trn_texts[:1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"I absolutely hate this programme, what kind of people sit and watch this garbage?? OK my dad and mum love it lol but i make sure I'm well out of the room before it comes on. Its so depressing and dreary but the worst thing about it is the acting i cant stand all detective programmes such as this because the detectives are so wooden and heartless. What happened to detective programmes with real mystery??? I mean who wants to know what happened to fictional characters we know nothing about that died over 20 years ago??? I wish the bbc would put more comedy on bbc1 cos now with the vicar of dibley finished there is more room for crap like this.\"],\n",
              "      dtype='<U14282')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "idKxx8HRMWdO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
        "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qudgI568V-IE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "3570aa43-d2ab-4243-ea4b-60dfcb006130"
      },
      "cell_type": "code",
      "source": [
        "df_trn.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I absolutely hate this programme, what kind of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Darkly comic serendipity about a cosmetics sal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Recap: Ron is about to marry Mel. They are dee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>I watched this movie at a Sneak Preview screen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>I doubt Jigsaw was hip even at the time, the w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels                                               text\n",
              "0       0  I absolutely hate this programme, what kind of...\n",
              "1       0  Darkly comic serendipity about a cosmetics sal...\n",
              "2       0  Recap: Ron is about to marry Mel. They are dee...\n",
              "3       0  I watched this movie at a Sneak Preview screen...\n",
              "4       0  I doubt Jigsaw was hip even at the time, the w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "0MoDQwVsMWdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# What does this cell do?\n",
        "\n",
        "df_trn[df_trn['labels']!=2].to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
        "df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
        "\n",
        "(CLAS_PATH/'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P44CWABEMWdX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We start by creating the data for the Language Model(LM). The LM's goal is to learn the structure of the english language. It learns language by trying to predict the next word given a set of previous words(ngrams). Since the LM does not classify reviews, the labels can be ignored.\n",
        "\n",
        "The LM can benefit from all the textual data and there is no need to exclude the unsup/unclassified movie reviews.\n",
        "\n",
        "We first concat all the train(pos/neg/unsup = **75k**) and test(pos/neg=**25k**) reviews into a big chunk of **100k** reviews. And then we use sklearn splitter to divide up the 100k texts into 90% training and 10% validation sets."
      ]
    },
    {
      "metadata": {
        "id": "ysDMBBMPd8xI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "934ddd75-2425-4763-e9bc-3ca17119bbba"
      },
      "cell_type": "code",
      "source": [
        "np.array(df_trn.text)[:1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"I absolutely hate this programme, what kind of people sit and watch this garbage?? OK my dad and mum love it lol but i make sure I'm well out of the room before it comes on. Its so depressing and dreary but the worst thing about it is the acting i cant stand all detective programmes such as this because the detectives are so wooden and heartless. What happened to detective programmes with real mystery??? I mean who wants to know what happened to fictional characters we know nothing about that died over 20 years ago??? I wish the bbc would put more comedy on bbc1 cos now with the vicar of dibley finished there is more room for crap like this.\"],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "MVUrNXhhMWdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# using only val_texts here to avoid mem error. np.concatenate([trn_texts, val_texts])\n",
        "\n",
        "# can concat test in here as well, to use for language model\n",
        "\n",
        "trn_texts,val_texts = sklearn.model_selection.train_test_split(np.array(df_trn.text), test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TObbrEeOMWda",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "026eb864-5517-43f6-b27a-3a04b6ae525c"
      },
      "cell_type": "code",
      "source": [
        "print(len(trn_texts), len(val_texts))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9000 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fDNBb1xOMWdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Don't care about labels here\n",
        "\n",
        "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
        "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
        "\n",
        "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
        "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tB-tMUTzMWdi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Language model tokens"
      ]
    },
    {
      "metadata": {
        "id": "_QWoYYt0MWdj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this section, we start cleaning up the messy text. There are 2 main activities we need to perform:\n",
        "\n",
        "1. Clean up extra spaces, tab chars, new ln chars and other characters and replace them with standard ones\n",
        "2. Use the awesome [spacy](http://spacy.io) library to tokenize the data. Since spacy does not provide a parallel/multicore version of the tokenizer, the fastai library adds this functionality. This parallel version uses all the cores of your CPUs and runs much faster than the serial version of the spacy tokenizer.\n",
        "\n",
        "Tokenization is the process of splitting the text into separate tokens so that each token can be assigned a unique index. This means we can convert the text into integer indexes our models can use.\n",
        "\n",
        "We use an appropriate chunksize as the tokenization process is memory intensive"
      ]
    },
    {
      "metadata": {
        "id": "2qLPT5QtMWdk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chunksize= 5000 # 24000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "URPNdSmqMWdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "re1 = re.compile(r'  +')\n",
        "\n",
        "def fixup(x):\n",
        "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
        "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
        "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
        "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
        "    return re1.sub(' ', html.unescape(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wrAqnwZiMWdq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_texts(df, n_lbls=1):\n",
        "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
        "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
        "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
        "    texts = list(texts.apply(fixup).values)\n",
        "\n",
        "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
        "    return tok, list(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fELR8np1MWdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_all(df, n_lbls):\n",
        "    tok, labels = [], []\n",
        "    for i, r in enumerate(df):\n",
        "        print(i)\n",
        "        tok_, labels_ = get_texts(r, n_lbls)\n",
        "        tok += tok_;\n",
        "        labels += labels_\n",
        "    return tok, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q_SDTbi6MWdw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
        "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U5hg58Q7MWdy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "fb7bc9ce-a29c-4063-d0de-7d29960713b7"
      },
      "cell_type": "code",
      "source": [
        "tok_trn, trn_labels = get_all(df_trn, 1)\n",
        "tok_val, val_labels = get_all(df_val, 1)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD4exjCsMWd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(LM_PATH/'tmp').mkdir(exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "keFRqwVrMWd4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
        "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vbrNTnY6MWd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
        "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtWt3_28frW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "cccc143d-de70-4512-be37-bcacd79b51d2"
      },
      "cell_type": "code",
      "source": [
        "tok_trn[:10], tok_trn.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list(['\\n', 'xbos', 'xfld', '1', 'what', 'can', 'i', 'say', '.', 'a', 'kamal', 'hassan', 'movie', 'being', 'horrible', '.', 'he', 'acts', 'very', 'well', ',', 'but', 'it', 'is', 'a', 'horrible', 'story', ',', 'along', 'with', 'horrible', 'direction', '.', 'in', 'my', 'kind', 'opinion', ',', 'the', 'director', 'gautham', 'menon', 'must', 'give', 'up', 'directing', '.', 'there', 'is', 'a', 'lot', 'of', 'tragedy', 'throughout', 'the', 'movie', '.', 'apart', 'from', 'that', ',', 'one', 'can', 'just', 'not', 'believe', 'how', 'true', 'were', 'those', 'horrendous', 'crimes', '.', 'there', 'was', 'no', 'practicality', 'in', 'the', 'movie', '.', 'gautham', 'is', 'just', 'running', 'out', 'of', 'stories', '.', 'but', 'both', 'kamal', 'hassan', 'and', 'jyothika', 'act', 'really', 'well', '.', 'the', 'villains', 'look', 'too', 'ugly', ',', 'though', 'their', 'performance', 'was', 'not', 'bad', '.', 'i', 'do', 'not', 'think', 'this', 'is', 'a', 'sunday', 'afternoon', 'movie', 'like', 'padayappa', 'which', 'you', 'can', 'see', 'with', 'the', 'family', '.', 'you', 'will', 'not', 'get', 'sleep', 'seeing', 'this', 'movie', '!', '!', 'however', ',', 'harris', 'jayaraj', 'again', 'did', 'a', 'great', 'job', ',', 'and', 'that', 'is', 'why', 'i', 'have', 'given', 'this', 'movie', '4', 'out', 'of', '10', '.', 'his', 'song', \"'\", 'partha', 'modail', 'nallae', \"'\", 'is', 'soulful', 'and', 'soothing', '.', 'apart', 'from', 'that', ',', 'great', 'cinematography', '.', 'on', 'the', 'whole', ',', 'this', 'is', 'just', 'a', 'bad', ',', 'bad', 'movie', '.', 'kamal', 'hassan', ',', 'i', 'think', ',', 'should', 'have', 'rejected', 'this', 'movie', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'this', 'movie', 'was', 'extremely', 'boring', '.', 'it', 'should', 'least', 'not', 'more', 'than', '15', 'minutes', '.', 'the', 'images', 'of', 'child', 'and', 'animal', 'being', 'killed', 'were', 'little', 'bit', 'disturbing', '.', '\\n\\n', 'usually', 'i', 'do', \"n't\", 'write', 'comments', 'but', 'this', 'one', 'was', 'so', 'bad', 'having', 'so', 'many', 'good', 'and', 'excellent', 'comments', '.', 'i', 'think', 'in', 'this', 'case', 'we', 'are', 'one', 'step', 'closer', 'to', 'honest', 'assessment', 'of', 'this', 'title', '.', '\\n\\n', 'what', 'more', 'can', 'i', 'say', '?', 'i', 'fall', 'asleep', 'during', 'this', 'movie', '3', 'times', '.', 'it', 'was', 'about', '4', 'hours', 'after', 'i', 'had', 'woken', 'up', 'from', '8', 'hours', 'long', 'sleeping', 'period', '.', 'i', 'think', 'it', 'is', 'the', 'point', 'itself', '.', '\\n\\n', 'there', 'is', 'no', 'dialog', 'between', 'characters', 'except', 'maybe', '2', 'sentences', 'at', 'the', 'very', 'end', '.', '\\n\\n', 'when', 'you', 'fall', 'asleep', 'once', 'watching', 'it', 'do', 'not', 'try', 'to', 'rewind', 'and', 'catch', 'up', 'because', 'you', 'will', 'fall', 'asleep', 'again', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'i', 'was', 'one', 'of', 'quite', 'a', 'few', 'extras', 'in', 'this', 'big', 'bomb', '.', 'i', 'just', 'happened', 'to', 'be', 'in', 'the', 'right', 'place', 'working', 'safety', 'for', 'the', 'race', 'scenes', 'at', 'a.i.r', '.', 'as', 'it', 'was', 'know', 'as', 'back', 'then.thank', 'goodness', 'my', 'scene', 'in', 'in', 'the', 'first', 'few', 'minutes', 'of', 'the', 'movie', 'and', 'i', 'do', \"n't\", 'have', 'to', 'sit', 'through', 'the', 'whole', 'thing', '.', 'it', 'was', 'more', 'of', 'a', 'big', 'party', 'than', 'a', 'movie', 'set', 'but', 'hey', ',', 'the', 'pay', 'was', 'good.attention', 'to', 'detail', 'was', 'not', 'a', 'strong', 'point', 'for', 'this', 'one', ',', 'but', 'who', 'was', 'going', 'to', 'know.the', 'funny', 'thing', 'was', 'seeing', 'the', 'cars', 'in', 'the', 'track', 'at', 'the', 'really', 'slow', 'speed', 'and', 'then', 'in', 'the', 'movie', 'speeded', 'up', 'to', 'the', 'what', 'was', 'close', 'to', 'normal', 'speed.a', 'lot', 'of', 'the', 'scenes', 'were', 'changed', 'as', 'they', 'were', 'filmed', 'i', 'suppose', 'to', 'shave', 'cost', 'and', 'time.but', 'every', 'one', 'was', 'having', 'such', 'a', 'good', 'time', 'who', 'cared', '!']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'sorry', 'to', 'go', 'against', 'the', 'flow', 'but', 'i', 'thought', 'this', 'film', 'was', 'unrealistic', ',', 'boring', 'and', 'way', 'too', 'long', '.', 'i', 'got', 'tired', 'of', 'watching', 'gena', 'rowlands', 'long', 'arduous', 'battle', 'with', 'herself', 'and', 'the', 'crisis', 'she', 'was', 'experiencing', '.', 'maybe', 'the', 'film', 'has', 'some', 'cinematic', 'value', 'or', 'represented', 'an', 'important', 'step', 'for', 'the', 'director', 'but', 'for', 'pure', 'entertainment', 'value', 'i', 'wish', 'i', 'would', 'have', 'skipped', 'it', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'i', 'thought', 'it', 'would', 'at', 'least', 'be', 'aesthetically', 'beautiful', '.', 'it', 'was', 'slow', ',', 'pretentious', ',', 'and', 'boring', '.', 'i', 'almost', 'fell', 'asleep', '.', 'there', 'are', 'some', 'decent', 'songs', ',', 'but', 'there', 'is', 'this', 'one', 'song', 'at', 'the', 'end', 'which', 'is', 'just', 'some', 'guy', 'yelling', 'out', '\"', 'yao', 'tk_rep', '4', 'w', '!', '\"', 'while', 'someone', 'taps', 'randomly', 'on', 'a', 'wooden', 'object', '.', 'that', 'being', 'said', ',', 'there', 'are', 'some', 'pretty', 'songs', ',', 'but', 'it', \"'s\", 'not', 'worth', 'seeing', 'hte', 'movie', 'over', '.', 'go', 'on', 'itunes', '(', 'they', 'have', 'the', 'album', ')', ',', 'preview', 'it', ',', 'and', 'choose', 'the', 'good', 'ones', '.', '\\n\\n', 'half', 'the', 'movie', 'is', 'some', 'guy', 'making', 'tea', '.', 'well', ',', 'that', \"'s\", 'a', 'slight', 'exaggeration', '.', 'but', 'you', \"'ll\", 'see', 'what', 'i', 'mean', 'if', 'you', 'see', 'it', '.', 'that', 'being', 'said', ':', 't_up', 'do', \"n't\", 't_up', 'see', 'it', '!']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'first', 'this', 'deserves', 'about', '5', 'stars', 'due', 'to', 'acting', '(', 'some', 'which', 'would', 'give', 'me', 'a', 'better', 'subjective', 'opinion', 'and', 't_up', 'not', 'an', 'objective', 'one', 'as', 'it', 'should', 'by', 'giving', 'this', 'one', ',', 't_up', 'well', 't_up', 'deserved', ',', 'star', ')', 'but', 'then', 'i', 'know', 'that', 'those', 'facts', 'are', 'used', 'for', 'the', 'actor(s', ')', 't_up', 'names', 'to', 'increase', 'the', 'rating', 'of', 'something', 'like', 'this', '...', '\\n\\n', 'i', 'do', 'have', 'a', 'problem', 'with', 'such', 'productions', ';', 'yet', 'another', 'attempt', '(', 'just', 'like', '\"', 'untraceable', '\"', ')', 'of', 'a', 'systematic', 'propagandistic', 'feature', 'promoting', 'government', 'intrusion', 'on', 'your', 'rights', '(', 'how', 'interesting', 'that', 'it', 'comes', 'at', 'a', 'moment', 'when', 't_up', 'ips', 'providers', 'trying', 'to', '\"', 'preferentiate', '\"', '=', 't_up', 'censor', 'information', ',', 'and', 'the', 'americans', 'and', 'canadians', 'are', 'fighting', 't_up', 'against', 'that', 'at', 'this', 'very', 'moments', ')', '.', 'this', 'time', 'is', 'not', 'by', 'labeling', 'torrent', 'file', 'transfers', 'as', 'evil', '(', 'that', 'one', 'was', 'intended', 'to', 'remind', 'you', 'of', 'such', 'feeling', 'whenever', 'you', 'transfer', 'data', 'on', 'the', 'net', ')', ',', 'but', 'by', 'literally', 'attempting', 'in', 'creating', 'a', 'sexual', 'frustrated', 'population', 'as', 'a', 'whole', '.', 't_up', 'seems', 't_up', 'like', 't_up', 'fear', 't_up', 'promotion', 'is', 't_up', 'hollywood', \"'s\", 't_up', 'norm', 't_up', 'this', 't_up', 'days', ',', 'especially', 'when', 'coming', 'to', 'thrillers', 'which', 'is', 'the', 'most', '\"', 'on', 'demand', '\"', 'motion', 'picture', 'genre', 'for', 'past', '2', 'decades', 'or', 'so', '=', 'most', 'viewed', ',', 'best', 'way', 'to', 'try', 'influence', 'the', 'society', 'as', 'a', 'whole', '.', 'such', 'levels', 'of', 'violence', 'are', 'depicted', 'in', 'this', '2', 'features', 'of', 'morally', 'and', '\"', 'ethical', '\"', 'people', ',', 'that', 'it', 'gives', 'a', 'new', 'much', 'needed', 'meaning', 'to', '\"', 'anti', '-', 'heroes', '\"', 'figures', '.', 'make', 'no', 'mistake', ',', 'this', 'is', 't_up', 'not', '\"', 't_up', 'dexter', '\"', 'which', 'was', 'meant', 'to', 'be', 'high', '-', 'quality', 'entertainment', '.', 't_up', 'stop', 't_up', 'selling', '\"', 't_up', 'fear', '\"', 'please', ',', 'the', 'world', 'would', 'be', 'a', 'better', 'place', 'without', 'it', 'and', 'the', 'dollars', 'made', 'of', 'it', '.', '\\n\\n', 'the', 'opening', 'scene', 'and', 'generally', 'the', 'first', '10', 'minutes', 'really', 'give', 'a', 'frightful', 'picture', 'of', 'an', 'erroll', 'babbage', 'that', 'is', 't_up', 'clearlly', 'suffering', 'of', 'sexual', 'frustration', '.', 'the', 'way', 'he', 'handles', 'the', 'black', 'male', 'is', 'very', 'disturbing', 'if', 'not', 'outright', 'racist(for', 'sure', 'a', '\"', 'cliche', '\"', 'at', 'least', ')', '(', 'in', 'real', 'life', 'someone', 'would', 'probably', 'get', 'a', 'beating', 'for', 'it', ',', 'you', 'will', 'see', 'what', 'i', 'mean', ')', '.', 'the', 'second', 'scene', '(', 'with', 'claire', 'danes', \"'s\", 'character', 'present', ')', 'is', 'even', 'more', 'extreme', '.', 'at', 'that', 'point', 'i', 'realized', ',', 'in', 'my', 'opinion', 'that', 'erroll', 'babbage', 'is', 'a', 'very', 'dangerous', 'individual', 'to', 'people', 'around', 'him.how', 'many', 'people', ',', 'that', 'have', 'seen', 'or', 'will', 'see', 'this', 'movie', ',', 'have', 'never', 'been', '\"', 'hold', 'down\"(regarding', 't_up', 'both', 'sexes', ')', 'out', 'of', 'self', ',', 't_up', 'common', 'gratification!?.typically', 'the', 'movie', 'gives', 'an', 'extreme', 't_up', 'criminal', 'case(that', 'unfortunately', 'did', ',', 'is', 'and', 'will', 'likely', 'happen', 'again', 'sometime', ',', 'somewhere', ')', 't_up', 'but', 'fingers', 'everyone', 'else', 'indirectly', 'as', 'well', 'as', '\"', 'you', 'could', 'become', 'that', '\"', ',', 'etc', '.', 'anyone', 'that', 'is', 'familiar', 'with', 'sigmund', 'freud', 'and', 'jung', 'will', 'know', 'very', 'well', 'that', 'sexuality', 'is', 'not', 'something', 'to', 'be', 'judged', 'let', 'alone', '\"', 'asses', '\"', ',', 'by', 'such', 'fanatical', '\"', 'hero', '\"', 'here', '.', 't_up', 'safe', 'sex', 'in', 'its', 'many', 'forms', 'is', 'healthy', 'and', 'not', 'some', 'evil', 'that', 'apparently', 'richard', 'gere', 'character', 'is', 'obsessed', 'with', ',', 'on', 'his', 'way', 'for', 'some', 'sexual', '\"', 'crusade', '\"', '.', 'have', 'we', 'not', 'learned', 'anything', 'from', 'the', 'abundant', 'recent', 'scandals', 'involving', 'priests', 'and', 'young', 'boys', '!', '?', 'or', 'for', 'how', 'long', 'an', 'american', 'teenager', 'can', 'see', 'extreme', 'violence', 'on', '\"', 'pg-13', '\"', 'but', 'he', 'can', 'not', 'even', 'see', 'a', 'woman', 'breast', 'until', '\"', 'r-18', '\"', '!', '?', '!', '?', '(', 'yet', 'the', 'industry', 'targets', 'them', 'with', 'this', 't_up', 'very', 't_up', 'same', 'sexual', 'perversions', 'like', '\"', 'american', 'pie', '\"', 'series', 'for', 'example).raise', 'the', 'kids', 'tester', '-', 'one', 'levels', 'but', 'frustrate', 'them', 'and', 'drive', 'them', 'underground', 'in', 'developing', 'fetishes', 'to', 'unhealthy', 't_up', 'extremes', '!', '?', 'all', 'sexual', 'activities(upon', 't_up', 'mutual', 'acceptance', ')', 'integrates', 'individuals', 'better', 'then', 'some', '\"', 'rightous', '\"', 'nut', '-', 'case', ',', 't_up', 'that', 'blames', 'his', 'misfortunes', 'and', 'shortcomings', 'on', '\"', 'the', 'lives', 'of', 'others', '\"', '(', 'a', 'new', 'german', 'movie', 'that', 'would', 'work', 'great', 'in', 'comparing', 'this', '2', 'distinct', 'and', 'world', 'apart', 'features', 'on', 'the', 'very', 'same', 'subject).here', ',', 'like', 'in', 'that', 'movie', ',', 'you', 'will', 'probably', 'appreciate', 'the', 'actors', 'for', 'well', 'portraying', 'the', 'opposite', 'of', 'what', 'they', 'should', 'have', 'been', '.', '\\n\\n', 'i', 'am', 'very', 'disappointed', 'with', 'richard', 'gere', 'especially', 'after', 'the', 'recent', '\"', 'hunting', 'party', '\"', ',', 'a', 'feature', 'where', 'he', 'really', 'shines', 'and', 'about', 'a', 'more', 'realistic', '\"', 'hero', '\"', '(', 'after', 'real', 'facts', 'as', 'well).but', 'then', 'it', 'just', 'reminds', 'me', 'that', 'all', 'those', 'people', 'are', 'only', 'actors', 'that', 'get', 'paid', 'to', 'play', 'someone', \"'s\", 'political', 'and', 'social', 'agenda', '.', '\"', 'the', 'flock', '\"', 'and', '\"', 'untraceable', '\"', '2', 'heads', 'of', 'the', 'same', 'hidden', 'beast)))it', 'just', 'reminds', 'you', ',', 'if', 'know', 'anyone', 'with', 'similar', 'views', 'on', 'the', 'subject', 'as', 'a', 't_up', 'whole', ',', 'as', 'erroll', 'babbage', 'has', 'those', 'here', ',', 'to', 'stay', 'clear', 'of', 'them', 'for', 't_up', 'their', 'own', 'safety.they', 'would', 'kill', 'my', 'family', 'faster', 'then', 'any', '0', '.', 'tk_rep', '4', '0', '1', 'chances', 'of', 'paul', 'jerrod', 'in', 'anyone', \"'s\", 'life', 'would', '...', '\\n\\n', 'in', 'the', 'end', 'i', 'recommend', 'this', 'to', 'anyone', 'thinking', 'negative', 'here', 'about', 'my', '\"', 'assesment', '\"', 'of', 'this', 'particular', 'movie', '(', 'and', '\"', 'untraceable', '\"', 'actually', ')', ',', 'so', 'you', 'can', 'likely', 'have', 'similar', 'thoughts', 'as', 'i', 'did', '.', 'nothing', 'sweeter', 'then', 'a', 'propagandistic', 'movie', 'shooting', 'itself', 'in', 'the', '\"', 'foot', '\"', '.', 'tk_rep', '4', ')', 'for', 'once', 'i', 'agree', 'with', 'the', 'rating', ',', 'this', 'is', 'not', 'a', 'feature', 'for', 'teenagers', 'or', 'kids', ';', 'simply', 'because', 'at', 'best', 'would', 'confuse', 'them', 'even', 'more', 'then', 'the', '\"', 'common', '\"', 'belief', 'of', '\"', 'money+fame+fashion', '\"', 'and', 'how', 'that', 'relates', 'to', 'sexuality', '.', '\"', 'scream', '\"', 'series', 'and', 'movies', 'as', 'such', 'at', 't_up', 'least', 'have', 'a', 'defined', 'entertainment', 'value(even', 'if', 'a', 'dumb', 'one', 'in', 'my', 'opinion', ')', '.', 'but', 'this', 'one', 'is', 'just', 'another', '\"', 'trust', 'me', 'i', 'know', 'what', 'is', 'good', 'for', 'you', '\"', 'deeply', '(', 'not', 'so', 'well', 'done', 'i', 'might', 'add', ')', 'subliminal', 'messages', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'a', 'bum', 'gives', 'a', 'secret', 'serviceman', 'a', 'tip', 'about', 'a', 'secret', 'service', 'man', 'in', 'the', 'presidential', 'detail', 'who', 'plans', 'to', 'kill', 'the', 'president', '.', 'baloney', '.', 'how', 'did', 'the', 'bum', 'know', '?', 'the', 'script', 'then', 'turns', 'to', 'a', 'most', 'detailed', 'examination', 'of', 'how', 'the', 'secret', 'service', 'works', ',', 'but', 'who', 'cares', '.', 'most', 'of', 'this', 'just', 'slows', 'down', 'the', 'movie', '.', 'all', 'the', 'chases', 'that', 'follow', 'are', 'this', 'film', \"'s\", 'version', 'of', 'the', 'tiresome', 'car', 'chases', 'of', 'many', 'movies', '.', 'then', ',', 'after', 'a', 'lot', 'of', 'impossible', 'athleticism', 'in', 'which', 'our', 'hero', 'outruns', 'and', 'out', '-', 'guns', 'all', 'his', 'buddies', ',', 'we', 'have', 'a', 'shootout', 'in', 'the', 'toronto', 'city', 'hall', '.', 'the', 'canadians', 'are', 'clearly', 'marked', 'with', 'maple', 'leafs', ',', 'but', 'how', 'did', 'they', 'get', 'into', 'this', '?', 'finally', ',', 'all', 'is', 'worked', 'out', '.', 'but', 'it', 'still', 'makes', 'no', 'sense', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'there', 'were', 'times', 'during', 'the', 'movie', 'i', 'wish', 'i', 'had', 'been', 'beat', 'to', 'death', '.', 'the', 'only', 'reason', 'i', 'endured', 'the', 'entirety', 'of', 'the', 'movie', 'was', 'because', 'i', 'could', \"n't\", 'believe', 'how', 'bad', 'it', 'really', 'was', 'and', 'thought', 'it', 'must', 'get', 'better', '.', 'this', 'truly', 'was', 'a', 'horror', 'film', '.', 'i', 'was', 'horrified', 'that', 'i', 'wasted', 'what', 'seemed', 'like', '4', 'hours', 'of', 'my', 'life', 'that', 'i', 'will', 'never', 'get', 'back', '.', 'the', 'other', 'two', 'hours', 'i', 'spent', 'mourning', 'at', 'the', 'loss', '.', 'please', 'recommend', 'this', 'movie', 'to', 'whomever', 'you', 'wish', 'to', 'torture', 'and', 'tell', 'them', 'the', 'suspense', 'will', 'kill', 'them', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'this', 'is', 'the', 'kind', 'of', 'film', 'that', 'everyone', 'involved', 'with', 'should', 'be', 'embarrassed', 'over', '.', 'poor', 'directing', ',', 'over', 'the', 'top', 'acting', 'and', 'a', 'plot', 'that', 'rambles', 'on', 'with', 'no', 'point', 'other', 'than', 'to', 'show', 'violence', '.', 'i', 'thought', 'when', 'i', 'first', 'saw', 'it', 'that', 'it', 'would', 'be', 'perhaps', 'a', 'satire', 'of', 'the', 'media', 'and', 'how', 'it', 'shows', 'violence', 'but', 'it', \"'s\", 'not', '.', 'i', \"'m\", 'not', 'sure', 'what', 'makes', 'the', 'film', 'worse', '.', 'oliver', 'stone', 'does', 'his', 'worst', 'directing', 'ever', '.', 'from', 'scenes', 'where', 'woody', 'harrelson', \"'s\", 'face', 'morphs', 'for', 'no', 'reason', 'or', 'robert', 'downey', 'jr', \"'s\", 'dreadful', 'performance', 'as', 'wayne', 'gale', 'who', 'is', 'a', 'reporter', 'who', 'seems', 'totally', 'bonkers', ',', 'this', 'movie', 'is', 'simply', 'a', 'mess', '.']),\n",
              "        list(['\\n', 'xbos', 'xfld', '1', 'the', 'late', '80', \"'s\", 'saw', 'an', 'inexplicable', 'rash', 'of', 'supernatural', 'horror', 'films', 'set', 'in', 'gloomy', 'penitentiary', 'settings', '.', 'renny', 'harlin', \"'s\", 'superbly', 'gritty', 'and', 'moody', '\"', 'prison', '\"', 'got', 'the', 'whole', 'haunted', 'hoosegow', 'ball', 'rolling', ';', 'it', 'was', 'immediately', 'followed', 'by', 'the', 'markedly', 'inferior', '\"', 'the', 'chair', ',', '\"', 'john', 'saxon', \"'s\", 'enjoyably', 'trashy', '\"', 'death', 'house', ',', '\"', 'the', 'passable', 'psycho', 'picture', '\"', 'destroyer', ',', '\"', 'and', 'this', 'hideously', \"limp'n'lethargic\", 'exercise', 'in', 'hopelessly', 'comatose', 'tedium', '.', '\\n\\n', 'your', 'usual', 'annoying', 'collection', 'of', 'horribly', 'unsympathetic', 'college', 'student', 'chowderheads', 'lead', 'by', 'insufferably', 'spineless', 'tormented', 'twerp', 'alex', '(', 'the', 'hugely', 'unappealing', 'nicholas', 'celozzi', ')', 'go', 'to', 'alcatraz', 'island', 'to', 'investigate', 'the', 'bizarre', 'circumstances', 'surrounding', 'the', 'sudden', 'gruesome', 'death', 'of', 'up', '-', 'and', '-', 'coming', 'rock', 'star', 'sammy', 'mitchell', '(', 'blandly', 'played', 'by', 'toni', 'basil', 'of', '\"', 'hey', 'micky', '\"', 'fame', ')', '.', 'alex', \"'s\", 'brother', 'becomes', 'possessed', 'by', 'the', 'evil', 'demonic', 'spirit', 'of', 'a', 'vicious', 'cannibalistic', 'us', 'civil', 'war', 'cavalry', 'commandant', 'and', 'goes', 'on', 'the', 'expected', 'killing', 'spree', ',', 'thus', 'forcing', 'wimpy', 'alex', 'to', 'overcome', 'his', 'passivity', 'and', 'make', 'a', 'stand', 'against', 'this', 'ghoulish', 'specter', '.', '\\n\\n', 'although', 'slickly', 'photographed', 'by', 'nicholas', 'von', 'sternberg', ',', 'with', 'a', 'few', 'decent', 'gore', 'set', 'pieces', 'and', 'a', 'fair', 'amount', 'of', 'spooky', 'atmosphere', '(', 'the', 'film', 'was', 'shot', 'on', 'location', 'in', 'the', 'dismal', ',', 'rusty', ',', 'rundown', 'ruins', 'of', 'alcatraz', 'island', ')', ',', '\"', 'slaughterhouse', 'rock', '\"', 'nonetheless', 'just', 'does', \"n't\", 'cut', 'it', 'as', 'a', 'solid', ',', 'effective', 'fright', 'feature', '.', 'this', 'is', 'largely', 'due', 'to', 'the', 'uniformly', 'obnoxious', 'and', 'unlikeable', 'collegiate', 'smartaleck', 'characters', ',', 'a', 'tiresomely', 'smirky', 'bunch', 'whose', 'inane', 'comic', 'antics', 'prove', 'to', 'be', 'grating', 'rather', 'than', 'amusing', '.', 'the', 'flat', 'acting', 'from', 'a', 'noticeably', 'disinterested', 'cast', 'hurts', 'matters', 'all', 'the', 'more', ',', 'with', 'onetime', '\"', 'playboy', '\"', 'playmate', 'and', 'undeniable', 'blonde', 'cutie', 'pie', 'hottie', 'supreme', 'hope', 'marie', 'carlton', 'doing', 'an', 'especially', 'irritating', 'linnea', 'quigley', 'impersonation', 'as', 'the', 'token', 'oversexed', 'nympho', 'bimbo', '.', 'dimitri', 'logothetis', \"'\", 'direction', 'displays', 'a', 'modicum', 'of', 'flashy', 'visual', 'style', ',', 'but', 'the', 'tone', 'is', 'unevenly', 'pitched', 'between', 'grim', 'seriousness', 'and', 'goofy', ',', 'horrendously', 'sophomoric', 'silliness', ',', 'and', ',', 'most', 'damagingly', ',', 'ted', 'landon', \"'s\", 'sloppy', ',', 'inconsistent', ',', 'overly', 'complicated', 'and', 'finally', 'quite', 'confusing', 'script', 'miserably', 'fails', 'to', 'develop', 'the', 'necessary', 'internal', 'logic', 'to', 'make', 'the', 'far', '-', 'fetched', 'story', 'even', 'remotely', 'plausible', '.', 'in', 'other', 'words', ',', 'this', 'stinker', 'sadly', 'succeeds', 'in', 'making', 'a', 'scant', '90', 'minutes', 'seem', 'like', 'an', 'excruciatingly', 'drawn', '-', 'out', 'cinematic', 'jail', 'sentence', '.'])],\n",
              "       dtype=object), (9000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "n5wVLf_kMWeA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "db74ffe8-7546-4a3a-fa28-23cb8469bdfb"
      },
      "cell_type": "code",
      "source": [
        "freq = Counter(p for o in tok_trn for p in o)\n",
        "freq.most_common(25)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 117358),\n",
              " ('.', 100526),\n",
              " (',', 94349),\n",
              " ('a', 57149),\n",
              " ('and', 53207),\n",
              " ('of', 49821),\n",
              " ('to', 49705),\n",
              " ('is', 37024),\n",
              " ('it', 34454),\n",
              " ('i', 33728),\n",
              " ('in', 31582),\n",
              " ('this', 29502),\n",
              " ('that', 27175),\n",
              " ('\"', 24605),\n",
              " (\"'s\", 21607),\n",
              " ('was', 20242),\n",
              " ('-', 19722),\n",
              " ('\\n\\n', 18663),\n",
              " ('movie', 18068),\n",
              " ('for', 15701),\n",
              " ('but', 15556),\n",
              " ('with', 15078),\n",
              " ('as', 14893),\n",
              " (\"n't\", 14363),\n",
              " ('film', 13953)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Cx0ZYjSlMWeE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The *vocab* is the **unique set of all tokens** in our dataset. The vocab provides us a way for us to simply replace each word in our datasets with a unique integer called an index.\n",
        "\n",
        "In a large corpus of data one might find some rare words which are only used a few times in the whole dataset. We discard such rare words and avoid trying to learn meaningful patterns out of them.\n",
        "\n",
        "Here we have set a minimum frequency of occurence to 2 times. It has been observed by NLP practicioners that a maximum vocab of 60k usually yields good results for classification tasks. So we set maz_vocab to 60000."
      ]
    },
    {
      "metadata": {
        "id": "Du0W05vYMWeF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_vocab = 60000\n",
        "min_freq = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4BtZ471qMWeJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
        "itos.insert(0, '_pad_')\n",
        "itos.insert(0, '_unk_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p6VlXH2mf9kK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPawBklfMWeK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We create a reverse mapping called stoi which is useful to lookup the index of a given token. stoi also has the same number of elements as itos. We use a high performance container called [collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) to store our stoi mapping."
      ]
    },
    {
      "metadata": {
        "id": "K1ZG2GZFMWeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a6b942cb-d9c7-45be-a548-84e375f32be9"
      },
      "cell_type": "code",
      "source": [
        "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
        "len(itos)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "HNE4IvY2MWeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
        "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qb5n3_GegV1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "c5f83a57-4926-4a92-fb29-4f2c89810aae"
      },
      "cell_type": "code",
      "source": [
        "trn_lm[:10], trn_lm.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([list([40, 41, 42, 36, 62, 80, 11, 141, 3, 5, 5930, 14909, 20, 128, 347, 3, 37, 1314, 84, 108, 4, 22, 10, 9, 5, 347, 93, 4, 430, 23, 347, 449, 3, 12, 82, 241, 704, 4, 2, 168, 16729, 0, 237, 218, 71, 794, 3, 50, 9, 5, 209, 7, 2595, 570, 2, 20, 3, 957, 57, 14, 4, 38, 80, 51, 30, 266, 101, 398, 75, 171, 2354, 3059, 3, 50, 17, 64, 19209, 12, 2, 20, 3, 16729, 9, 51, 549, 60, 7, 637, 3, 22, 316, 5930, 14909, 6, 0, 451, 76, 108, 3, 2, 1934, 172, 110, 1062, 4, 197, 91, 365, 17, 30, 69, 3, 11, 53, 30, 121, 13, 9, 5, 3642, 2679, 20, 47, 0, 85, 28, 80, 88, 23, 2, 303, 3, 28, 113, 30, 95, 1275, 356, 13, 20, 48, 48, 226, 4, 2339, 0, 214, 81, 5, 157, 426, 4, 6, 14, 9, 124, 11, 33, 358, 13, 20, 191, 60, 7, 202, 3, 44, 811, 61, 0, 0, 0, 61, 9, 0, 6, 16730, 3, 957, 57, 14, 4, 157, 747, 3, 29, 2, 220, 4, 13, 9, 51, 5, 69, 4, 69, 20, 3, 5930, 14909, 4, 11, 121, 4, 140, 33, 5252, 13, 20, 3]),\n",
              "        list([40, 41, 42, 36, 13, 20, 17, 564, 253, 3, 10, 140, 194, 30, 74, 92, 981, 189, 3, 2, 1659, 7, 545, 6, 1357, 128, 495, 75, 139, 285, 1263, 3, 19, 612, 11, 53, 25, 662, 763, 22, 13, 38, 17, 46, 69, 286, 46, 148, 70, 6, 765, 763, 3, 11, 121, 12, 13, 420, 89, 34, 38, 1588, 2885, 8, 1536, 19210, 7, 13, 413, 3, 19, 62, 74, 80, 11, 141, 49, 11, 775, 1579, 353, 13, 20, 310, 267, 3, 10, 17, 59, 191, 542, 118, 11, 78, 19211, 71, 57, 1175, 542, 222, 2490, 924, 3, 11, 121, 10, 9, 2, 210, 424, 3, 19, 50, 9, 64, 641, 269, 122, 452, 264, 208, 4585, 43, 2, 84, 145, 3, 19, 73, 28, 775, 1579, 346, 156, 10, 53, 30, 335, 8, 9974, 6, 1469, 71, 98, 28, 113, 775, 1579, 214, 3]),\n",
              "        list([40, 41, 42, 36, 11, 17, 38, 7, 234, 5, 180, 2162, 12, 13, 229, 1652, 3, 11, 51, 558, 8, 35, 12, 2, 231, 321, 895, 4278, 21, 2, 1631, 151, 43, 0, 3, 24, 10, 17, 131, 24, 166, 0, 3342, 82, 149, 12, 12, 2, 107, 180, 189, 7, 2, 20, 6, 11, 53, 25, 33, 8, 693, 159, 2, 220, 147, 3, 10, 17, 74, 7, 5, 229, 1204, 92, 5, 20, 304, 22, 1161, 4, 2, 829, 17, 0, 8, 2144, 17, 30, 5, 933, 210, 21, 13, 38, 4, 22, 56, 17, 169, 8, 0, 170, 147, 17, 356, 2, 1759, 12, 2, 1383, 43, 2, 76, 507, 2117, 6, 102, 12, 2, 20, 13509, 71, 8, 2, 62, 17, 552, 8, 1442, 0, 209, 7, 2, 151, 75, 1228, 24, 39, 75, 854, 11, 1069, 8, 10643, 2225, 6, 0, 187, 38, 17, 286, 158, 5, 70, 79, 56, 3848, 48]),\n",
              "        list([40, 41, 42, 36, 571, 8, 153, 487, 2, 2886, 22, 11, 212, 13, 26, 17, 1589, 4, 253, 6, 114, 110, 222, 3, 11, 200, 1162, 7, 156, 9975, 10644, 222, 14910, 1122, 23, 925, 6, 2, 4010, 77, 17, 7710, 3, 264, 2, 26, 66, 63, 1318, 964, 55, 5087, 54, 860, 1588, 21, 2, 168, 22, 21, 1140, 743, 964, 11, 680, 11, 67, 33, 6349, 10, 3]),\n",
              "        list([40, 41, 42, 36, 11, 212, 10, 67, 43, 194, 35, 12333, 547, 3, 10, 17, 507, 4, 1328, 4, 6, 253, 3, 11, 239, 1353, 1579, 3, 50, 34, 63, 419, 812, 4, 22, 50, 9, 13, 38, 811, 43, 2, 145, 85, 9, 51, 63, 201, 3015, 60, 15, 0, 190, 191, 2834, 48, 15, 167, 242, 12334, 3458, 29, 5, 1113, 3583, 3, 14, 128, 291, 4, 50, 34, 63, 183, 812, 4, 22, 10, 16, 30, 349, 356, 0, 20, 132, 3, 153, 29, 19212, 32, 39, 33, 2, 5931, 31, 4, 4485, 10, 4, 6, 2192, 2, 70, 699, 3, 19, 280, 2, 20, 9, 63, 201, 223, 3286, 3, 108, 4, 14, 16, 5, 3705, 8459, 3, 22, 28, 248, 88, 62, 11, 319, 58, 28, 88, 10, 3, 14, 128, 291, 94, 27, 53, 25, 27, 88, 10, 48]),\n",
              "        list([40, 41, 42, 36, 107, 13, 1127, 59, 331, 422, 732, 8, 115, 32, 63, 85, 67, 218, 87, 5, 129, 12335, 704, 6, 27, 30, 54, 4711, 38, 24, 10, 140, 52, 683, 13, 38, 4, 27, 108, 27, 2118, 4, 360, 31, 22, 102, 11, 131, 14, 171, 2193, 34, 366, 21, 2, 0, 31, 27, 1234, 8, 8460, 2, 600, 7, 146, 47, 13, 86, 19, 11, 53, 33, 5, 376, 23, 158, 2559, 142, 300, 174, 464, 32, 51, 47, 15, 19213, 15, 31, 7, 5, 19214, 19215, 865, 6554, 1264, 14911, 29, 137, 2835, 32, 101, 224, 14, 10, 298, 43, 5, 627, 73, 27, 0, 0, 252, 8, 15, 0, 15, 2526, 27, 16731, 1900, 4, 6, 2, 1525, 6, 12336, 34, 985, 27, 487, 14, 43, 13, 84, 461, 31, 3, 13, 79, 9, 30, 52, 19216, 19217, 5253, 13510, 24, 428, 32, 14, 38, 17, 1290, 8, 2970, 28, 7, 158, 616, 1733, 28, 4586, 8461, 29, 2, 6812, 31, 4, 22, 52, 1155, 2410, 12, 2163, 5, 830, 3706, 3643, 24, 5, 220, 3, 27, 199, 27, 47, 27, 1097, 27, 8913, 9, 27, 407, 16, 27, 5564, 27, 13, 27, 566, 4, 364, 73, 629, 8, 5088, 85, 9, 2, 116, 15, 29, 4824, 15, 1241, 534, 643, 21, 621, 208, 3459, 55, 46, 2526, 116, 2680, 4, 192, 114, 8, 335, 3016, 2, 1276, 24, 5, 220, 3, 158, 2527, 7, 583, 34, 2706, 12, 13, 208, 1017, 7, 5755, 6, 15, 16732, 15, 99, 4, 14, 10, 591, 5, 216, 97, 815, 1198, 8, 15, 1084, 18, 1916, 15, 3644, 3, 100, 64, 1042, 4, 13, 9, 27, 30, 15, 27, 8462, 15, 85, 17, 873, 8, 35, 327, 18, 450, 743, 3, 27, 518, 27, 3849, 15, 27, 1097, 15, 488, 4, 2, 263, 67, 35, 5, 129, 321, 238, 10, 6, 2, 2016, 103, 7, 10, 3, 19, 2, 664, 149, 6, 1128, 2, 107, 202, 189, 76, 218, 5, 19218, 534, 7, 54, 7711, 12337, 14, 9, 27, 0, 2054, 7, 830, 4712, 3, 2, 114, 37, 6350, 2, 344, 823, 9, 84, 1263, 58, 30, 5254, 0, 255, 5, 15, 3396, 15, 43, 194, 31, 32, 12, 179, 165, 242, 67, 256, 95, 5, 3189, 21, 10, 4, 28, 113, 88, 62, 11, 319, 31, 3, 2, 361, 149, 32, 23, 3343, 5565, 16, 126, 1163, 31, 9, 68, 74, 1459, 3, 43, 14, 210, 11, 1604, 4, 12, 82, 704, 14, 7711, 12337, 9, 5, 84, 1953, 2836, 8, 99, 204, 0, 148, 99, 4, 14, 33, 135, 55, 113, 88, 13, 20, 4, 33, 133, 96, 15, 1194, 0, 27, 316, 9976, 31, 60, 7, 550, 4, 27, 1141, 0, 2, 20, 591, 54, 1459, 27, 2075, 0, 384, 81, 4, 9, 6, 113, 1364, 581, 214, 6555, 4, 942, 31, 27, 22, 4368, 348, 311, 10645, 24, 108, 24, 15, 28, 83, 515, 14, 15, 4, 497, 3, 257, 14, 9, 1393, 23, 0, 14912, 6, 0, 113, 131, 84, 108, 14, 4939, 9, 30, 146, 8, 35, 6135, 272, 597, 15, 13511, 15, 4, 52, 158, 12338, 15, 595, 15, 143, 3, 27, 2017, 338, 12, 125, 148, 5932, 9, 5398, 6, 30, 63, 428, 14, 517, 847, 5566, 126, 9, 2119, 23, 4, 29, 44, 114, 21, 63, 830, 15, 13512, 15, 3, 33, 89, 30, 2437, 211, 57, 2, 9422, 1336, 16733, 1176, 12339, 6, 281, 1123, 48, 49, 55, 21, 101, 222, 54, 367, 2837, 80, 88, 1459, 583, 29, 15, 4104, 15, 22, 37, 80, 30, 68, 88, 5, 270, 5567, 421, 15, 0, 15, 48, 49, 48, 49, 32, 300, 2, 1480, 6556, 112, 23, 13, 27, 84, 27, 188, 830, 16734, 47, 15, 367, 2470, 15, 288, 21, 0, 2, 357, 0, 18, 38, 2527, 22, 19219, 112, 6, 1235, 112, 2971, 12, 4105, 14913, 8, 11414, 27, 8463, 48, 49, 45, 830, 0, 27, 7712, 8073, 31, 0, 4279, 129, 102, 63, 15, 0, 15, 4011, 18, 420, 4, 27, 14, 7713, 44, 0, 6, 5399, 29, 15, 2, 630, 7, 485, 15, 32, 5, 216, 1277, 20, 14, 67, 198, 157, 12, 3850, 13, 208, 5568, 6, 263, 957, 1017, 29, 2, 84, 188, 0, 4, 47, 12, 14, 20, 4, 28, 113, 256, 1481, 2, 164, 21, 108, 3344, 2, 2210, 7, 62, 39, 140, 33, 96, 3, 19, 11, 246, 84, 553, 23, 847, 5566, 364, 118, 2, 1336, 15, 3238, 1204, 15, 4, 5, 865, 134, 37, 76, 6351, 6, 59, 5, 74, 1308, 15, 595, 15, 32, 118, 179, 2193, 24, 0, 102, 10, 51, 2164, 87, 14, 45, 171, 99, 34, 72, 164, 14, 95, 1171, 8, 352, 242, 16, 1085, 6, 1278, 4940, 3, 15, 2, 7368, 15, 6, 15, 19213, 15, 208, 1504, 7, 2, 188, 1786, 0, 51, 2164, 28, 4, 58, 131, 257, 23, 802, 3017, 29, 2, 920, 24, 5, 27, 220, 4, 24, 7711, 12337, 66, 171, 143, 4, 8, 682, 785, 7, 112, 21, 27, 91, 274, 0, 67, 469, 82, 303, 3460, 102, 104, 1668, 3, 190, 191, 1668, 36, 3345, 7, 998, 0, 12, 257, 16, 165, 67, 86, 19, 12, 2, 145, 11, 477, 13, 8, 257, 446, 1669, 143, 59, 82, 15, 0, 15, 7, 13, 994, 20, 32, 6, 15, 19213, 15, 161, 31, 4, 46, 28, 80, 1364, 33, 802, 2596, 24, 11, 81, 3, 144, 19220, 102, 5, 19215, 20, 1156, 424, 12, 2, 15, 1935, 15, 3, 190, 191, 31, 21, 346, 11, 965, 23, 2, 600, 4, 13, 9, 30, 5, 865, 21, 2528, 55, 357, 142, 320, 98, 43, 192, 67, 6136, 112, 68, 74, 102, 2, 15, 1141, 15, 2411, 7, 15, 0, 15, 6, 101, 14, 12340, 8, 4939, 3, 15, 1605, 15, 288, 6, 111, 24, 158, 43, 27, 194, 33, 5, 5569, 743, 0, 58, 5, 626, 38, 12, 82, 704, 31, 3, 22, 13, 38, 9, 51, 174, 15, 1760, 87, 11, 131, 62, 9, 70, 21, 28, 15, 2707, 32, 30, 46, 108, 251, 11, 227, 703, 31, 11415, 4106, 3]),\n",
              "        list([40, 41, 42, 36, 5, 11416, 591, 5, 1049, 0, 5, 4587, 59, 5, 1049, 2529, 160, 12, 2, 8914, 2144, 56, 2438, 8, 469, 2, 2194, 3, 11417, 3, 101, 81, 2, 11416, 131, 49, 2, 193, 102, 576, 8, 5, 116, 4012, 7369, 7, 101, 2, 1049, 2529, 741, 4, 22, 56, 2055, 3, 116, 7, 13, 51, 8464, 195, 2, 20, 3, 45, 2, 2919, 14, 913, 34, 13, 26, 16, 362, 7, 2, 3018, 463, 2919, 7, 148, 111, 3, 102, 4, 118, 5, 209, 7, 1086, 0, 12, 85, 323, 595, 0, 6, 60, 18, 1537, 45, 44, 4013, 4, 89, 33, 5, 6137, 12, 2, 5933, 733, 2708, 3, 2, 12336, 34, 635, 8074, 23, 0, 0, 4, 22, 101, 81, 39, 95, 105, 13, 49, 473, 4, 45, 9, 876, 60, 3, 22, 10, 175, 219, 64, 279, 3]),\n",
              "        list([40, 41, 42, 36, 50, 75, 267, 353, 2, 20, 11, 680, 11, 78, 96, 1496, 8, 359, 3, 2, 72, 243, 11, 8075, 2, 5570, 7, 2, 20, 17, 98, 11, 83, 25, 266, 101, 69, 10, 76, 17, 6, 212, 10, 237, 95, 129, 3, 13, 460, 17, 5, 181, 26, 3, 11, 17, 5255, 14, 11, 670, 62, 401, 47, 191, 542, 7, 82, 165, 14, 11, 113, 133, 95, 166, 3, 2, 106, 136, 542, 11, 840, 9423, 43, 2, 2056, 3, 488, 477, 13, 20, 8, 8915, 28, 680, 8, 1346, 6, 354, 112, 2, 825, 113, 469, 112, 3]),\n",
              "        list([40, 41, 42, 36, 13, 9, 2, 241, 7, 26, 14, 348, 573, 23, 140, 35, 1812, 132, 3, 249, 794, 4, 132, 2, 438, 115, 6, 5, 109, 14, 12341, 29, 23, 64, 210, 106, 92, 8, 152, 583, 3, 11, 212, 73, 11, 107, 244, 10, 14, 10, 67, 35, 435, 5, 2092, 7, 2, 1936, 6, 101, 10, 403, 583, 22, 10, 16, 30, 3, 11, 150, 30, 255, 62, 219, 2, 26, 292, 3, 2471, 1709, 90, 44, 163, 794, 130, 3, 57, 151, 134, 1937, 11418, 16, 442, 12342, 21, 64, 243, 55, 736, 7091, 2709, 16, 1255, 365, 24, 2057, 9424, 56, 9, 5, 2120, 56, 199, 443, 16735, 4, 13, 20, 9, 320, 5, 584, 3]),\n",
              "        list([40, 41, 42, 36, 2, 657, 902, 16, 244, 54, 4107, 14914, 7, 2385, 181, 138, 304, 12, 9977, 0, 3397, 3, 12343, 10646, 16, 10647, 4713, 6, 5400, 15, 1229, 15, 200, 2, 220, 2355, 0, 2076, 2033, 142, 10, 17, 1265, 1384, 52, 2, 0, 4369, 15, 2, 2972, 4, 15, 394, 7370, 16, 11419, 3060, 15, 359, 334, 4, 15, 2, 4014, 1831, 534, 15, 14915, 4, 15, 6, 13, 6813, 0, 2439, 12, 4108, 8916, 5571, 3, 19, 137, 697, 427, 1882, 7, 1470, 4714, 1026, 1219, 0, 480, 52, 14916, 14917, 7371, 16736, 1787, 32, 2, 6814, 4941, 3777, 0, 31, 153, 8, 10648, 945, 8, 3461, 2, 1020, 2530, 4015, 2, 2165, 2838, 359, 7, 71, 18, 6, 18, 629, 799, 360, 8465, 3584, 32, 10649, 341, 52, 7092, 10650, 7, 15, 1161, 14918, 15, 2440, 31, 3, 1787, 16, 652, 501, 3518, 52, 2, 428, 4588, 1337, 7, 5, 3851, 8076, 232, 4191, 445, 10651, 0, 6, 294, 29, 2, 790, 677, 4370, 4, 1482, 5256, 8917, 1787, 8, 4016, 44, 0, 6, 100, 5, 766, 487, 13, 16737, 0, 3, 19, 336, 16738, 4486, 52, 3777, 5089, 0, 4, 23, 5, 180, 419, 433, 304, 1358, 6, 5, 1147, 1117, 7, 3778, 1195, 32, 2, 26, 17, 322, 29, 1590, 12, 2, 4825, 4, 7093, 4, 14919, 4280, 7, 10648, 945, 31, 4, 15, 9425, 799, 15, 3645, 51, 90, 25, 543, 10, 24, 5, 1749, 4, 1553, 5934, 865, 3, 13, 9, 2166, 732, 8, 2, 6352, 2093, 6, 3346, 0, 0, 122, 4, 5, 0, 0, 559, 725, 2803, 776, 4589, 1722, 8, 35, 5572, 265, 92, 1066, 3, 2, 767, 115, 57, 5, 8466, 9978, 228, 3646, 2121, 45, 2, 74, 4, 23, 0, 15, 5401, 15, 0, 6, 11420, 1591, 0, 2470, 10652, 8467, 474, 3707, 12344, 374, 54, 364, 1483, 0, 0, 7372, 24, 2, 3779, 12345, 0, 5257, 3, 14920, 0, 61, 449, 4017, 5, 8468, 7, 5090, 1315, 486, 4, 22, 2, 1425, 9, 19221, 6138, 269, 4826, 8469, 6, 2491, 4, 8470, 8077, 4371, 4, 6, 4, 116, 0, 4, 3585, 11421, 16, 2973, 4, 3708, 4, 2018, 3398, 6, 473, 234, 1152, 193, 2094, 671, 8, 2261, 2, 2058, 5402, 1526, 8, 100, 2, 230, 18, 3586, 93, 68, 1606, 4192, 3, 12, 106, 687, 4, 13, 2531, 850, 3519, 12, 223, 5, 16739, 927, 189, 326, 47, 54, 4942, 1560, 18, 60, 1318, 3019, 3190, 3])],\n",
              "       dtype=object), (9000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "mXWgHHuLMWeQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
        "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
        "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qQKs2EvMWeS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
        "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
        "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8q33ej8WMWeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7199071-b82a-462d-a48f-5343336874e5"
      },
      "cell_type": "code",
      "source": [
        "vs=len(itos)\n",
        "vs,len(trn_lm)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23074, 9000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "b_g2lka0MWeW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## wikitext103 conversion"
      ]
    },
    {
      "metadata": {
        "id": "YfwfB4DRMWeW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are now going to build an english language model for the IMDB corpus. We could start from scratch and try to learn the structure of the english language. But we use a technique called transfer learning to make this process easier. In transfer learning (a fairly recent idea for NLP) a pre-trained LM that has been trained on a large generic corpus(_like wikipedia articles_) can be used to transfer it's knowledge to a target LM and the weights can be fine-tuned.\n",
        "\n",
        "Our source LM is the wikitext103 LM created by Stephen Merity @ Salesforce research. [Link to dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
        "The language model for wikitext103 (AWD LSTM) has been pre-trained and the weights can be downloaded here: [Link](http://files.fast.ai/models/wt103/). Our target LM is the IMDB LM. "
      ]
    },
    {
      "metadata": {
        "id": "IxGyZ9gfMWeW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! wget -nH -r -np -P {PATH} http://files.fast.ai/models/wt103/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8G67GTITMWed",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The pre-trained LM weights have an embedding size of 400, 1150 hidden units and just 3 layers. We need to match these values  with the target IMDB LM so that the weights can be loaded up."
      ]
    },
    {
      "metadata": {
        "id": "AHuq7UvPMWed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "em_sz,nh,nl = 400,1150,3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yv07tk5lMWef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PRE_PATH = PATH/'models'/'wt103'\n",
        "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "10gs2T02MWeh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vj8Qm3TVMWen",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We calculate the mean of the layer0 encoder weights. This can be used to assign weights to unknown tokens when we transfer to target IMDB LM."
      ]
    },
    {
      "metadata": {
        "id": "O9GNMYh2MWeo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
        "row_m = enc_wgts.mean(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hkZQvETAMWer",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
        "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iIj_QS4CMWew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before we try to transfer the knowledge from wikitext to the IMDB LM, we match up the vocab words and their indexes. \n",
        "We use the defaultdict container once again, to assign mean weights to unknown IMDB tokens that do not exist in wikitext103."
      ]
    },
    {
      "metadata": {
        "id": "y547u_gZMWez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
        "for i,w in enumerate(itos):\n",
        "    r = stoi2[w]\n",
        "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RopA5fUjMWe2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now overwrite the weights into the wgts odict.\n",
        "The decoder module, which we will explore in detail is also loaded with the same weights due to an idea called weight tying."
      ]
    },
    {
      "metadata": {
        "id": "QaBajLUPMWe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wgts['0.encoder.weight'] = T(new_w)\n",
        "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
        "wgts['1.decoder.weight'] = T(np.copy(new_w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ckG6HjllMWe7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have the weights prepared, we are ready to create and start training our new IMDB language pytorch model!"
      ]
    },
    {
      "metadata": {
        "id": "mNG4uTaPMWe8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Language model"
      ]
    },
    {
      "metadata": {
        "id": "i2-3FkVFMWe9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is fairly straightforward to create a new language model using the fastai library. Like every other lesson, our model will have a backbone and a custom head. The backbone in our case is the IMDB LM pre-trained with wikitext and the custom head is a linear classifier. In this section we will focus on the backbone LM and the next section will talk about the classifier custom head.\n",
        "\n",
        "bptt (*also known traditionally in NLP LM as ngrams*) in fastai LMs is approximated to a std. deviation around 70, by perturbing the sequence length on a per-batch basis. This is akin to shuffling our data in computer vision, only that in NLP we cannot shuffle inputs and we have to maintain statefulness. \n",
        "\n",
        "Since we are predicting words using ngrams, we want our next batch to line up with the end-points of the previous mini-batch's items. batch-size is constant and but the fastai library expands and contracts bptt each mini-batch using a clever stochastic implementation of a batch. (original credits attributed to [Smerity](https://twitter.com/jeremyphoward/status/980227258395770882))"
      ]
    },
    {
      "metadata": {
        "id": "e7IecerFMWe-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wd=1e-7\n",
        "bptt=70\n",
        "bs=52\n",
        "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otVoW9EyMWfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the LM is to learn to predict a word/token given a preceeding set of words(tokens). We take all the movie reviews in both the 90k training set and 10k validation set and concatenate them to form long strings of tokens. In fastai, we use the `LanguageModelLoader` to create a data loader which makes it easy to create and use bptt sized mini batches. The  `LanguageModelLoader` takes a concatenated string of tokens and returns a loader.\n",
        "\n",
        "We have a special modeldata object class for LMs called `LanguageModelData` to which we can pass the training and validation loaders and get in return the model itself."
      ]
    },
    {
      "metadata": {
        "id": "_XpTDfniMWfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
        "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
        "\n",
        "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OzSKZlasMWfF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We setup the dropouts for the model - these values have been chosen after experimentation. If you need to update them for custom LMs, you can change the weighting factor (0.7 here) based on the amount of data you have. For more data, you can reduce dropout factor and for small datasets, you can reduce overfitting by choosing a higher dropout factor. *No other dropout value requires tuning*"
      ]
    },
    {
      "metadata": {
        "id": "Z2rXe03eMWfJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCv4uQykMWfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We first tune the last embedding layer so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer.\n",
        "\n",
        "We also keep track of the *accuracy* metric."
      ]
    },
    {
      "metadata": {
        "id": "fdvG06UgMWfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
        "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
        "\n",
        "learner.metrics = [accuracy]\n",
        "learner.freeze_to(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQBT6gdQMWfO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.model.load_state_dict(wgts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ow19E6VOMWfS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We set learning rates and fit our IMDB LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the wikitext103 learn better weights."
      ]
    },
    {
      "metadata": {
        "id": "2ngvfuUpMWfS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=1e-3\n",
        "lrs = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Txylyd_FMWfV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c461dfb4-56d3-4f18-f778-56d6d63b2774"
      },
      "cell_type": "code",
      "source": [
        "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2f2b5931c6d4702802dd1a4c161c89b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      4.917014   4.63381    0.237947  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([4.63381]), 0.23794723416750246]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "dtphT3CQMWfX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we print out accuracy and keep track of how often we end up predicting the target word correctly. While this is a good metric to check, it is not part of our loss function as it can get quite bumpy. We only minimize cross-entropy loss in the LM.\n",
        "\n",
        "The exponent of the cross-entropy loss is called the perplexity of the LM. (low perplexity is better)."
      ]
    },
    {
      "metadata": {
        "id": "K0FfVoDIMWfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.save('lm_last_ft')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9R4tSIYEMWfb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.load('lm_last_ft')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cpbnd8FYMWfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDFm0VbvMWff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "39e1200d-0855-4ad6-c61a-2536bddc67bc"
      },
      "cell_type": "code",
      "source": [
        "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e57dd9043d6d4e17bb6dbb823cdae22b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      4.711651   4.501925   0.238624  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CeR1mFsWMWfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "collapsed": true,
        "outputId": "64fedfc2-a2c6-43a5-f8a7-5c49d2fabe8d"
      },
      "cell_type": "code",
      "source": [
        "learner.sched.plot()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFcCAYAAADRWyc3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7efd6ccf8518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "OnQDHt2eMWfj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "327f8dff-e923-400f-aae9-904cdc682d1b"
      },
      "cell_type": "code",
      "source": [
        "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=1)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b764c896d214dca9f328f32b7ba0c43",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      4.472973   4.210691   0.269823  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([4.21069]), 0.2698230965015216]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "ThDxFGt0MWfm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We save the trained model weights and separately save the encoder part of the LM model as well. This will serve as our backbone in the classification task model."
      ]
    },
    {
      "metadata": {
        "id": "OBMEI5OVMWfo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.save('lm1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-nqlyHYMWfp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learner.save_encoder('lm1_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XVqJcXrDMWfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "faf9e218-33d2-4149-f755-4bb6840fe1bf"
      },
      "cell_type": "code",
      "source": [
        "learner.sched.plot_loss()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAFKCAYAAADWhMzpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEfoHTLL94BKX5isAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7eff4d2eef60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uYV22a0PMWfu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classifier tokens"
      ]
    },
    {
      "metadata": {
        "id": "x1eRfsDEMWfv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The classifier model is basically a linear layer custom head on top of the LM backbone. Setting up the classifier data is similar to the LM data setup except that we cannot use the unsup movie reviews this time."
      ]
    },
    {
      "metadata": {
        "id": "O0FgoveHMWfv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
        "df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aw9xS_zxMWfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e95cbdae-3ce4-4ba7-eefd-91bd87d8de13"
      },
      "cell_type": "code",
      "source": [
        "tok_trn, trn_labels = get_all(df_trn, 1)\n",
        "tok_val, val_labels = get_all(df_val, 1)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-tP7O6LXMnSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27629e46-b021-4f35-fc51-2fb51a74336d"
      },
      "cell_type": "code",
      "source": [
        "len(tok_trn), len(tok_trn[0])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "oEZeAZOaMWfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
        "\n",
        "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
        "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
        "\n",
        "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
        "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdGpaH7SMWf1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
        "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4awvH4zSMWf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b40fbb56-cd60-4b9c-a52e-4d0e032fe748"
      },
      "cell_type": "code",
      "source": [
        "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
        "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
        "len(itos)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23074"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "s4yVZIpGiq08",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "417b8f44-ca18-479b-8002-cedb825b7903"
      },
      "cell_type": "code",
      "source": [
        "stoi[\"the\"]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "yYJ2Svt9MWf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
        "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYhvwkBtjA1H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "c47774c7-b9c9-4d48-aff8-53d48a31c51a"
      },
      "cell_type": "code",
      "source": [
        "trn_clas[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([40, 41, 42, 36, 11, 406, 681, 13, 11625, 4, 62, 241, 7, 99, 693, 6, 123, 13, 774, 49, 49, 462, 82, 1199, 6, 6859, 182, 10, 4747, 22, 11, 100, 255, 11, 150, 108, 60, 7, 2, 655, 186, 10, 298, 29, 3, 125, 46, 2114, 6, 3513, 22, 2, 163, 147, 59, 10, 9, 2, 115, 11, 178, 1056, 766, 45, 1539, 16104, 158, 24, 13, 98, 2, 5456, 34, 46, 1113, 6, 9444, 3, 62, 558, 8, 1539, 16104, 23, 179, 813, 49, 49, 49, 11, 319, 56, 527, 8, 131, 62, 558, 8, 2841, 122, 89, 131, 144, 59, 14, 1257, 132, 772, 221, 715, 49, 49, 49, 11, 680, 2, 2979, 67, 290, 74, 247, 29, 0, 8828, 177, 23, 2, 0, 7, 0, 1581, 50, 9, 74, 655, 21, 378, 47, 13, 3]),\n",
              "       list([40, 41, 42, 36, 11358, 776, 0, 59, 5, 0, 0, 4, 23, 1098, 4235, 8, 2408, 10610, 4, 549, 105, 5, 1911, 7, 2408, 20018, 167, 1289, 43, 7770, 12, 10367, 86, 6, 2110, 677, 385, 38, 7, 112, 159, 139, 1771, 7, 65, 274, 3, 3109, 3719, 4, 5, 175, 18, 1322, 555, 7, 4975, 2980, 4, 1217, 8, 1167, 3278, 111, 8, 352, 12, 4, 22, 13, 1255, 931, 32, 52, 3584, 0, 6, 2138, 18, 602, 22224, 31, 66, 25, 54, 14222, 7, 70, 589, 3, 2, 1515, 6, 309, 18, 2076, 1744, 34, 30, 873, 8, 35, 2, 483, 7, 523, 247, 4, 22, 68, 29, 5, 13185, 4, 5790, 636, 4, 2, 534, 9, 2370, 6, 2973, 3, 58, 28, 53, 123, 4, 88, 58, 28, 80, 1283, 101, 97, 9398, 604, 50, 34, 7, 3719, 498, 2, 6254, 7, 65, 3997, 21441, 4, 975, 302, 12, 2, 188, 3367, 6, 5, 606, 18, 21049, 172, 29, 65, 442, 3, 2232, 316, 77, 6, 2408, 75, 108, 1171, 3, 64, 27, 422, 57, 190, 191, 162]),\n",
              "       list([40, 41, 42, 36, 9451, 94, 2367, 9, 59, 8, 2630, 4593, 3, 39, 34, 2707, 6, 182, 6, 932, 39, 34, 866, 21, 385, 106, 68, 197, 39, 2215, 51, 5, 180, 2174, 715, 3, 5580, 4, 2367, 16, 652, 12, 1293, 8, 35, 9, 30, 46, 835, 3, 37, 9, 1359, 2, 1853, 9, 5, 4201, 8, 44, 0, 426, 12, 2, 303, 1236, 6, 1106, 8, 14973, 2367, 16, 5951, 1204, 3, 22, 44, 179, 1253, 9, 8, 290, 2367, 12, 5, 16791, 988, 4, 95, 1892, 6, 928, 2367, 6, 4593, 71, 3, 19, 763, 94, 295, 8, 35, 5, 614, 8, 5, 247, 523, 22, 10, 9, 25, 170, 43, 45, 3, 10, 9, 665, 5, 0, 152, 6, 5, 2933, 855, 8, 152, 8105, 5110, 373, 3, 161, 4, 12, 5, 114, 4, 10, 9, 239, 1531, 33, 148, 28, 80, 290, 12, 50, 4, 98, 39, 34, 2446, 3, 384, 14, 9, 119, 38, 7, 2, 3781, 7, 5, 20, 14, 178, 25, 1674, 424, 3, 10, 320, 9, 25, 70, 203, 3, 19, 10, 66, 337, 1015, 734, 197, 4, 55, 161, 337, 164, 14, 9, 349, 5, 129, 193, 92, 13, 3, 10, 9, 480, 297, 3860, 0, 56, 161, 1124, 8, 218, 54, 1262, 7, 63, 1141, 279, 3, 11455, 2934, 11, 131, 66, 74, 618, 92, 8, 53, 111, 47, 13, 4, 6, 19275, 19276, 326, 8, 33, 5, 209, 74, 618, 92, 13, 20, 3, 19, 62, 9, 8106, 4125, 34, 70, 537, 3, 161, 4, 69, 537, 34, 265, 11456, 110, 3, 10, 51, 9, 25, 170, 3, 19, 310, 127, 202]),\n",
              "       list([40, 41, 42, 36, 11, 313, 13, 20, 43, 5, 4603, 4485, 2765, 6, 11, 150, 1491, 11, 81, 25, 829, 21, 10, 3, 13, 20, 9, 51, 1571, 3, 125, 454, 7, 2229, 6, 5197, 537, 6, 372, 64, 3630, 12, 2, 240, 0, 24, 2, 6137, 12, 15, 139, 3037, 15, 31, 3, 11, 103, 5, 139, 917, 7, 215, 11, 803, 12, 2, 20, 350, 6, 5, 209, 7, 85, 11, 81, 25, 965, 7, 3, 19, 36, 3, 5188, 8930, 16, 5772, 3, 208, 3, 2, 5197, 537, 3, 310, 3, 2, 7677, 537, 3, 191, 3, 2, 1643, 17, 5, 10107, 3, 331, 3, 64, 2039, 7318, 3, 822, 3, 2, 0, 1060, 3, 214, 223, 340, 7, 2458, 350, 89, 27, 95, 10, 37, 16, 54, 27, 1800, 350, 880, 29, 3, 1175, 3, 2, 1643, 66, 1591, 999, 3, 1183, 3, 2, 109, 3, 202, 3, 2, 677, 7, 17261, 1982, 3, 2380, 1932, 17, 12, 10, 3, 1549, 3, 116, 7, 2, 228, 75, 51, 18233, 6, 60, 50, 3, 19, 177, 2, 32, 180, 31, 70, 699, 19, 36, 3, 2, 1643, 1247, 5, 1009, 24, 5, 21386, 47, 12, 2, 585, 3, 208, 3, 757, 7, 240, 3, 310, 3, 0, 103, 5, 1169, 32, 6, 5, 1856, 7, 2, 2331, 7, 12071, 31, 191, 3, 18101, 350, 11, 81, 25, 33, 8, 829, 21, 10, 3, 331, 3, 50, 34, 5, 180, 15, 62, 2, 0, 15, 461, 19, 1932, 81, 10, 214, 3, 37, 103, 174, 1325, 585, 105, 20, 5706, 3, 5635, 8, 28, 4, 530, 1932, 3, 208, 127, 202]),\n",
              "       list([40, 41, 42, 36, 11, 745, 5222, 17, 2222, 68, 43, 2, 79, 4, 2, 220, 27, 8713, 949, 1280, 8, 5, 724, 813, 128, 5, 9155, 475, 464, 8, 3267, 5, 281, 305, 7, 2, 1338, 238, 12, 2, 194, 460, 868, 104, 2139, 7, 2, 5720, 19962, 3, 2, 2321, 1203, 1131, 4, 5222, 1985, 57, 148, 713, 4, 783, 5777, 115, 4, 532, 6, 2950, 371, 4, 27, 8713, 1920, 14, 153, 29, 19526, 222, 68, 118, 2, 210, 66, 96, 11203, 405, 12, 2, 107, 1979, 1036, 4, 5, 1660, 8, 1045, 104, 398, 825, 68, 197, 2, 686, 109, 9, 4, 29, 1565, 4, 5, 157, 1956, 8, 53, 51, 14, 4, 6, 54, 301, 14, 9, 46, 1995, 6, 554, 32, 30, 8, 673, 3503, 7, 5, 209, 7, 69, 769, 403, 31, 14, 2, 1311, 9, 161, 54, 1084, 18, 1311, 3, 58, 10, 17, 5, 129, 20, 4, 89, 227, 35, 617, 8, 6507, 2266, 29, 5, 180, 215, 134, 10, 67, 389, 2814, 4, 22, 2, 8006, 34, 46, 5044, 39, 72, 2602, 8, 2809, 2, 0, 960, 227, 762, 5276, 3, 11, 244, 5222, 29, 769, 6, 10, 9, 610, 657, 324, 268, 2328, 873, 8, 1704, 0, 6, 1107, 2, 79, 8, 469, 1416, 16, 4752, 265, 92, 211, 1449, 3530, 8, 9246, 2912, 60, 3, 43, 84, 192, 4, 5, 337, 60, 7, 202, 3]),\n",
              "       list([40, 41, 42, 36, 2, 1007, 2036, 21, 2, 207, 288, 17, 142, 217, 242, 4, 95, 2, 305, 8, 47, 112, 4, 102, 290, 112, 105, 9284, 2383, 3, 13, 2036, 876, 21, 2, 10921, 1077, 103, 269, 12105, 18, 14033, 3, 19, 177, 4, 89, 1540, 845, 1520, 221, 8, 3858, 350, 89, 34, 1711, 8, 1825, 4167, 4, 5, 729, 332, 18, 92, 18, 18028, 1026, 396, 481, 4, 23, 44, 510, 4, 20880, 4, 5, 281, 131, 18, 10, 18, 45, 3, 39, 34, 17878, 120, 52, 784, 7510, 12, 65, 3997, 2733, 11257, 8, 2, 945, 6407, 134, 2, 4167, 303, 539, 4, 21, 2, 396, 8853, 3, 239, 1265, 4, 39, 34, 318, 12, 2, 408, 7, 0, 6, 44, 590, 4, 10536, 18, 10536, 1890, 2, 1702, 153, 8, 1792, 394, 57, 11257, 331, 85, 66, 96, 6172, 52, 5, 3885, 1714, 3, 13, 9, 45, 206, 7, 2, 2641, 16, 3995, 8, 217, 132, 4167, 945, 46, 14, 37, 80, 1872, 2, 11257, 5602, 86, 0, 8, 3133, 5, 1963, 48, 19, 447, 3, 2, 109, 9, 24, 6960, 24, 14, 48, 19, 2, 371, 9, 3947, 4, 2, 115, 74, 1113, 92, 14, 7, 2, 32, 0, 31, 4687, 4, 2, 277, 4, 211, 22, 325, 6, 11704, 20881, 16, 749, 1865, 49, 62, 139, 50, 17, 7, 4002, 2482, 16, 6516, 949, 18029, 159, 20881, 16, 3526, 19434, 3, 2, 351, 7, 2, 749, 17, 9889, 1710, 3, 12, 213, 4, 206, 7, 2, 749, 17, 4552, 2, 1070, 1300, 29, 2, 2344, 6, 81, 25, 11258, 10, 48, 11, 81, 25, 68, 907, 8, 682, 8, 2937, 15840, 16, 1014, 2030, 23, 2, 145, 2756, 19, 8, 35, 1147, 4, 2367, 3951, 876, 234, 108, 24, 2551, 4, 37, 6, 8727, 11193, 24, 7510, 401, 670, 3, 23, 2, 231, 714, 4, 39, 83, 33, 96, 152, 0, 3, 2, 27, 1187, 198, 17, 62, 11, 67, 33, 432, 1055, 1700, 18, 331, 221, 715, 3, 19, 2, 9745, 7, 2, 293, 3535, 75, 51, 306, 142, 2, 207, 288, 3295, 43, 194, 2185, 24, 58, 39, 78, 2946, 19, 174, 7256, 210, 9, 14, 2, 220, 342, 401, 8, 35, 38, 222, 304, 7, 2272, 0, 4, 57, 187, 1956, 128, 2087, 52, 2733, 8, 2, 383, 1370, 7, 2, 4167, 12702, 128, 1071, 52, 986, 185, 1638, 16, 3, 19, 82, 579, 32, 1183, 31, 803, 2, 26, 22, 13, 1824, 269, 3831, 357, 6, 61, 0, 61, 4, 3467, 9156, 43, 44, 758, 588, 4, 1222, 144, 8, 2, 3759, 1767, 3, 73, 360, 2525, 710, 2, 229, 299, 12, 5265, 23, 61, 2, 1241, 534, 61, 4, 5, 220, 216, 11259, 7, 165, 17, 19752, 105, 2, 2347, 85, 102, 3785, 21, 174, 772, 221, 55, 46, 3, 23, 13, 26, 4, 13116, 66, 1076, 5, 2948, 1390, 8, 53, 2, 188, 23, 2, 3759, 2347, 3, 19, 11, 6230, 14, 13, 26, 4, 47, 61, 2, 20882, 61, 6, 61, 2, 6335, 61, 186, 10, 4, 113, 4047, 105, 6818, 824, 822, 2174, 4, 1133, 2, 207, 288, 8, 125, 61, 523, 61, 2920, 3]),\n",
              "       list([40, 41, 42, 36, 28, 200, 2612, 182, 2, 708, 309, 312, 111, 3, 13, 38, 298, 514, 23, 69, 277, 4, 3256, 6, 69, 115, 32, 76, 69, 31, 3, 878, 4, 187, 79, 11, 88, 15657, 0, 32, 2, 863, 31, 11, 436, 446, 61, 123, 60, 48, 77, 16, 5, 0, 21, 171, 14, 131, 6017, 127, 2262, 3, 19, 5, 866, 466, 7, 62, 505, 73, 242, 23, 69, 1181, 6, 527, 8, 271, 235, 223, 5, 404, 4, 2, 139, 14, 17, 840, 7, 307, 3, 11, 53, 25, 131, 58, 11, 278, 74, 571, 21, 2, 519, 7, 2, 20, 55, 2, 1240, 56, 81, 25, 100, 166, 104, 235, 3, 19, 11, 283, 141, 10, 16, 70, 21, 139, 357, 12, 10, 16, 7321, 4, 22, 11, 53, 25, 131, 58, 11, 283, 184, 8, 920, 5, 481, 8, 10, 86, 19, 11640, 86, 36, 127, 202, 98, 14, 16, 2, 3599, 10, 113, 153, 3]),\n",
              "       list([40, 41, 42, 36, 11, 283, 2084, 13, 413, 981, 55, 772, 267, 167, 12, 2239, 4, 262, 21, 146, 2025, 419, 8, 123, 3, 45, 11, 80, 141, 9, 14, 39, 75, 45, 60, 2025, 419, 138, 2, 324, 11, 2108, 8, 644, 13, 3, 19, 11, 113, 218, 10, 1031, 21, 128, 7207, 6, 17710, 129, 92, 15, 2431, 3512, 15, 4, 22, 12, 11230, 14, 16, 183, 1051, 8, 141, 261, 13, 38, 27, 81, 25, 33, 7468, 1059, 8604, 12, 10, 3, 2, 106, 215, 10, 2820, 12, 14342, 75, 94, 54, 224, 228, 4, 224, 93, 4, 70, 641, 6, 2028, 4, 22, 11, 1069, 28, 178, 25, 33, 314, 3, 19, 162, 162, 162, 27, 821, 27, 1444, 162, 162, 162, 2, 12093, 1027, 7, 1016, 3598, 32, 38, 7, 85, 17, 5, 1016, 86, 153, 801, 31, 9410, 204, 57, 13176, 14184, 8, 13176, 14184, 252, 8, 7907, 60, 45, 2, 1261, 10, 83, 205, 3, 2, 1027, 2793, 7, 94, 2, 7242, 4, 20255, 18, 53, 18, 108, 1732, 32, 56, 1220, 499, 29, 31, 4, 44, 52, 18, 2, 18, 287, 4, 300, 7390, 107, 3392, 4, 2, 2942, 1016, 1016, 1829, 32, 30, 5, 18512, 31, 4, 5, 2800, 3391, 6, 5, 27, 76, 4, 27, 76, 5997, 1639, 8482, 4, 15, 1484, 201, 15, 586, 86, 10, 239, 782, 47, 2, 228, 21, 27, 3742, 16, 61, 2, 179, 263, 61, 3, 118, 2, 1732, 1220, 12, 5, 1210, 5599, 23, 5, 3031, 7, 12146, 32, 6, 24, 10, 576, 60, 4, 2871, 7, 2, 13650, 580, 7, 531, 9290, 31, 44, 107, 3392, 372, 132, 86, 1374, 4, 1374, 4, 1374, 86, 348, 4144, 117, 86, 1374, 4, 1374, 4, 1374, 86, 11, 83, 153, 29, 4, 22, 24, 11, 291, 10, 16, 2, 188, 675, 366, 12, 59, 5, 2878, 106, 61, 138, 61, 7, 2, 643, 3, 19, 2, 277, 75, 1886, 6, 124, 602, 7961, 17, 12, 13, 20, 9, 638, 87, 3, 2, 1016, 1016, 1829, 32, 175, 30, 5, 18512, 31, 17, 183, 846, 4, 22, 7, 307, 58, 28, 173, 1018, 21, 65, 8, 5786, 74, 92, 51, 65, 9955, 4, 172, 2768, 3, 19, 11, 178, 25, 141, 14, 10, 17, 2, 163, 26, 11, 154, 135, 4, 24, 11, 161, 1207, 61, 10017, 7993, 208, 61, 4, 22, 761, 21, 13, 38, 8, 236, 29, 2, 875, 18, 871, 1038, 3]),\n",
              "       list([40, 41, 42, 36, 59, 1684, 189, 105, 13, 20, 4, 11, 17, 441, 755, 3, 234, 320, 4, 155, 122, 75, 1008, 476, 3, 2343, 4, 146, 1090, 67, 581, 4, 22, 102, 215, 67, 507, 195, 214, 3, 3202, 4, 82, 4413, 17, 910, 9851, 4, 6, 2, 301, 8, 13, 20, 17, 25, 69, 43, 45, 3, 226, 4, 10, 17, 52, 64, 808, 70, 203, 8, 4024, 1073, 159, 2, 107, 4984, 189, 3, 46, 4, 11, 67, 141, 14, 2, 20, 17, 1014, 536, 4, 6, 1011, 45, 7, 2, 618, 12, 2, 228, 4, 11, 283, 572, 13, 5, 904, 3]),\n",
              "       list([40, 41, 42, 36, 5, 160, 1331, 44, 216, 381, 8, 44, 405, 134, 44, 1273, 381, 1257, 7, 54, 15, 1714, 15, 3, 44, 216, 381, 66, 51, 96, 716, 57, 54, 5145, 6, 9, 119, 27, 84, 1173, 48, 45, 7, 2, 2165, 77, 489, 2020, 3880, 6, 356, 9236, 45, 132, 2, 321, 3, 9, 77, 169, 884, 214, 55, 9, 2, 107, 381, 629, 166, 57, 2, 328, 49, 19, 28, 154, 256, 3325, 2, 301, 46, 11, 484, 25, 3859, 10, 60, 3, 11, 244, 13, 148, 267, 29, 2279, 2679, 268, 24, 5, 481, 3, 166, 102, 4, 11, 541, 10, 22, 11, 27, 17, 281, 3, 356, 10, 177, 11, 869, 101, 69, 10, 9, 3, 10, 16, 1470, 892, 4, 575, 399, 4, 84, 476, 32, 68, 43, 54, 453, 31, 6, 66, 5, 624, 228, 7, 27, 608, 99, 32, 38, 128, 2, 168, 31, 48, 175, 10, 90, 33, 63, 70, 215, 59, 10, 3, 19, 2, 282, 9, 1730, 954, 6, 2, 1022, 424, 23, 2, 624, 1641, 334, 6, 11530, 3944, 9, 2779, 3725, 3, 50, 119, 34, 5, 180, 524, 461, 32, 11, 3734, 5, 139, 73, 77, 244, 2, 107, 3770, 31, 6, 5, 729, 1553, 301, 3, 45, 12, 45, 10, 16, 610, 27, 30, 5, 70, 20, 86, 22, 30, 5, 676, 1260, 317, 3, 10, 90, 33, 5, 500, 1172, 1070, 3, 11, 218, 10, 5, 208, 3, 19, 119, 335, 8, 533, 2, 5677, 27, 345, 1235, 18, 12, 4853, 7, 10, 32, 10, 16, 9865, 23, 15, 1114, 7, 2, 1226, 22349, 15, 31, 3, 10, 16, 12, 27, 260, 3390, 23, 2539, 6, 13737, 45, 132, 3, 10, 81, 25, 68, 172, 13, 69, 29, 268, 48])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "gMxAl5L1MWf6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
        "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "beFvL2n1MWf7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Classifier"
      ]
    },
    {
      "metadata": {
        "id": "pkEBapZEMWf8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can create our final model, a classifier which is really a custom linear head over our trained IMDB backbone. The steps to create the classifier model are similar to the ones for the LM."
      ]
    },
    {
      "metadata": {
        "id": "_hCo4dB8MWf9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Don't need\n",
        "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
        "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfmY5gWkMWf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
        "#val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))\n",
        "trn_labels = np.squeeze(trn_labels)\n",
        "val_labels = np.squeeze(val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OrQ7OhJZhes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9d5f1675-8929-441f-c48e-617d23015cfa"
      },
      "cell_type": "code",
      "source": [
        "trn_labels[:10], trn_clas[:10]"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " array([list([40, 41, 42, 36, 11, 406, 681, 13, 11625, 4, 62, 241, 7, 99, 693, 6, 123, 13, 774, 49, 49, 462, 82, 1199, 6, 6859, 182, 10, 4747, 22, 11, 100, 255, 11, 150, 108, 60, 7, 2, 655, 186, 10, 298, 29, 3, 125, 46, 2114, 6, 3513, 22, 2, 163, 147, 59, 10, 9, 2, 115, 11, 178, 1056, 766, 45, 1539, 16104, 158, 24, 13, 98, 2, 5456, 34, 46, 1113, 6, 9444, 3, 62, 558, 8, 1539, 16104, 23, 179, 813, 49, 49, 49, 11, 319, 56, 527, 8, 131, 62, 558, 8, 2841, 122, 89, 131, 144, 59, 14, 1257, 132, 772, 221, 715, 49, 49, 49, 11, 680, 2, 2979, 67, 290, 74, 247, 29, 0, 8828, 177, 23, 2, 0, 7, 0, 1581, 50, 9, 74, 655, 21, 378, 47, 13, 3]),\n",
              "        list([40, 41, 42, 36, 11358, 776, 0, 59, 5, 0, 0, 4, 23, 1098, 4235, 8, 2408, 10610, 4, 549, 105, 5, 1911, 7, 2408, 20018, 167, 1289, 43, 7770, 12, 10367, 86, 6, 2110, 677, 385, 38, 7, 112, 159, 139, 1771, 7, 65, 274, 3, 3109, 3719, 4, 5, 175, 18, 1322, 555, 7, 4975, 2980, 4, 1217, 8, 1167, 3278, 111, 8, 352, 12, 4, 22, 13, 1255, 931, 32, 52, 3584, 0, 6, 2138, 18, 602, 22224, 31, 66, 25, 54, 14222, 7, 70, 589, 3, 2, 1515, 6, 309, 18, 2076, 1744, 34, 30, 873, 8, 35, 2, 483, 7, 523, 247, 4, 22, 68, 29, 5, 13185, 4, 5790, 636, 4, 2, 534, 9, 2370, 6, 2973, 3, 58, 28, 53, 123, 4, 88, 58, 28, 80, 1283, 101, 97, 9398, 604, 50, 34, 7, 3719, 498, 2, 6254, 7, 65, 3997, 21441, 4, 975, 302, 12, 2, 188, 3367, 6, 5, 606, 18, 21049, 172, 29, 65, 442, 3, 2232, 316, 77, 6, 2408, 75, 108, 1171, 3, 64, 27, 422, 57, 190, 191, 162]),\n",
              "        list([40, 41, 42, 36, 9451, 94, 2367, 9, 59, 8, 2630, 4593, 3, 39, 34, 2707, 6, 182, 6, 932, 39, 34, 866, 21, 385, 106, 68, 197, 39, 2215, 51, 5, 180, 2174, 715, 3, 5580, 4, 2367, 16, 652, 12, 1293, 8, 35, 9, 30, 46, 835, 3, 37, 9, 1359, 2, 1853, 9, 5, 4201, 8, 44, 0, 426, 12, 2, 303, 1236, 6, 1106, 8, 14973, 2367, 16, 5951, 1204, 3, 22, 44, 179, 1253, 9, 8, 290, 2367, 12, 5, 16791, 988, 4, 95, 1892, 6, 928, 2367, 6, 4593, 71, 3, 19, 763, 94, 295, 8, 35, 5, 614, 8, 5, 247, 523, 22, 10, 9, 25, 170, 43, 45, 3, 10, 9, 665, 5, 0, 152, 6, 5, 2933, 855, 8, 152, 8105, 5110, 373, 3, 161, 4, 12, 5, 114, 4, 10, 9, 239, 1531, 33, 148, 28, 80, 290, 12, 50, 4, 98, 39, 34, 2446, 3, 384, 14, 9, 119, 38, 7, 2, 3781, 7, 5, 20, 14, 178, 25, 1674, 424, 3, 10, 320, 9, 25, 70, 203, 3, 19, 10, 66, 337, 1015, 734, 197, 4, 55, 161, 337, 164, 14, 9, 349, 5, 129, 193, 92, 13, 3, 10, 9, 480, 297, 3860, 0, 56, 161, 1124, 8, 218, 54, 1262, 7, 63, 1141, 279, 3, 11455, 2934, 11, 131, 66, 74, 618, 92, 8, 53, 111, 47, 13, 4, 6, 19275, 19276, 326, 8, 33, 5, 209, 74, 618, 92, 13, 20, 3, 19, 62, 9, 8106, 4125, 34, 70, 537, 3, 161, 4, 69, 537, 34, 265, 11456, 110, 3, 10, 51, 9, 25, 170, 3, 19, 310, 127, 202]),\n",
              "        list([40, 41, 42, 36, 11, 313, 13, 20, 43, 5, 4603, 4485, 2765, 6, 11, 150, 1491, 11, 81, 25, 829, 21, 10, 3, 13, 20, 9, 51, 1571, 3, 125, 454, 7, 2229, 6, 5197, 537, 6, 372, 64, 3630, 12, 2, 240, 0, 24, 2, 6137, 12, 15, 139, 3037, 15, 31, 3, 11, 103, 5, 139, 917, 7, 215, 11, 803, 12, 2, 20, 350, 6, 5, 209, 7, 85, 11, 81, 25, 965, 7, 3, 19, 36, 3, 5188, 8930, 16, 5772, 3, 208, 3, 2, 5197, 537, 3, 310, 3, 2, 7677, 537, 3, 191, 3, 2, 1643, 17, 5, 10107, 3, 331, 3, 64, 2039, 7318, 3, 822, 3, 2, 0, 1060, 3, 214, 223, 340, 7, 2458, 350, 89, 27, 95, 10, 37, 16, 54, 27, 1800, 350, 880, 29, 3, 1175, 3, 2, 1643, 66, 1591, 999, 3, 1183, 3, 2, 109, 3, 202, 3, 2, 677, 7, 17261, 1982, 3, 2380, 1932, 17, 12, 10, 3, 1549, 3, 116, 7, 2, 228, 75, 51, 18233, 6, 60, 50, 3, 19, 177, 2, 32, 180, 31, 70, 699, 19, 36, 3, 2, 1643, 1247, 5, 1009, 24, 5, 21386, 47, 12, 2, 585, 3, 208, 3, 757, 7, 240, 3, 310, 3, 0, 103, 5, 1169, 32, 6, 5, 1856, 7, 2, 2331, 7, 12071, 31, 191, 3, 18101, 350, 11, 81, 25, 33, 8, 829, 21, 10, 3, 331, 3, 50, 34, 5, 180, 15, 62, 2, 0, 15, 461, 19, 1932, 81, 10, 214, 3, 37, 103, 174, 1325, 585, 105, 20, 5706, 3, 5635, 8, 28, 4, 530, 1932, 3, 208, 127, 202]),\n",
              "        list([40, 41, 42, 36, 11, 745, 5222, 17, 2222, 68, 43, 2, 79, 4, 2, 220, 27, 8713, 949, 1280, 8, 5, 724, 813, 128, 5, 9155, 475, 464, 8, 3267, 5, 281, 305, 7, 2, 1338, 238, 12, 2, 194, 460, 868, 104, 2139, 7, 2, 5720, 19962, 3, 2, 2321, 1203, 1131, 4, 5222, 1985, 57, 148, 713, 4, 783, 5777, 115, 4, 532, 6, 2950, 371, 4, 27, 8713, 1920, 14, 153, 29, 19526, 222, 68, 118, 2, 210, 66, 96, 11203, 405, 12, 2, 107, 1979, 1036, 4, 5, 1660, 8, 1045, 104, 398, 825, 68, 197, 2, 686, 109, 9, 4, 29, 1565, 4, 5, 157, 1956, 8, 53, 51, 14, 4, 6, 54, 301, 14, 9, 46, 1995, 6, 554, 32, 30, 8, 673, 3503, 7, 5, 209, 7, 69, 769, 403, 31, 14, 2, 1311, 9, 161, 54, 1084, 18, 1311, 3, 58, 10, 17, 5, 129, 20, 4, 89, 227, 35, 617, 8, 6507, 2266, 29, 5, 180, 215, 134, 10, 67, 389, 2814, 4, 22, 2, 8006, 34, 46, 5044, 39, 72, 2602, 8, 2809, 2, 0, 960, 227, 762, 5276, 3, 11, 244, 5222, 29, 769, 6, 10, 9, 610, 657, 324, 268, 2328, 873, 8, 1704, 0, 6, 1107, 2, 79, 8, 469, 1416, 16, 4752, 265, 92, 211, 1449, 3530, 8, 9246, 2912, 60, 3, 43, 84, 192, 4, 5, 337, 60, 7, 202, 3]),\n",
              "        list([40, 41, 42, 36, 2, 1007, 2036, 21, 2, 207, 288, 17, 142, 217, 242, 4, 95, 2, 305, 8, 47, 112, 4, 102, 290, 112, 105, 9284, 2383, 3, 13, 2036, 876, 21, 2, 10921, 1077, 103, 269, 12105, 18, 14033, 3, 19, 177, 4, 89, 1540, 845, 1520, 221, 8, 3858, 350, 89, 34, 1711, 8, 1825, 4167, 4, 5, 729, 332, 18, 92, 18, 18028, 1026, 396, 481, 4, 23, 44, 510, 4, 20880, 4, 5, 281, 131, 18, 10, 18, 45, 3, 39, 34, 17878, 120, 52, 784, 7510, 12, 65, 3997, 2733, 11257, 8, 2, 945, 6407, 134, 2, 4167, 303, 539, 4, 21, 2, 396, 8853, 3, 239, 1265, 4, 39, 34, 318, 12, 2, 408, 7, 0, 6, 44, 590, 4, 10536, 18, 10536, 1890, 2, 1702, 153, 8, 1792, 394, 57, 11257, 331, 85, 66, 96, 6172, 52, 5, 3885, 1714, 3, 13, 9, 45, 206, 7, 2, 2641, 16, 3995, 8, 217, 132, 4167, 945, 46, 14, 37, 80, 1872, 2, 11257, 5602, 86, 0, 8, 3133, 5, 1963, 48, 19, 447, 3, 2, 109, 9, 24, 6960, 24, 14, 48, 19, 2, 371, 9, 3947, 4, 2, 115, 74, 1113, 92, 14, 7, 2, 32, 0, 31, 4687, 4, 2, 277, 4, 211, 22, 325, 6, 11704, 20881, 16, 749, 1865, 49, 62, 139, 50, 17, 7, 4002, 2482, 16, 6516, 949, 18029, 159, 20881, 16, 3526, 19434, 3, 2, 351, 7, 2, 749, 17, 9889, 1710, 3, 12, 213, 4, 206, 7, 2, 749, 17, 4552, 2, 1070, 1300, 29, 2, 2344, 6, 81, 25, 11258, 10, 48, 11, 81, 25, 68, 907, 8, 682, 8, 2937, 15840, 16, 1014, 2030, 23, 2, 145, 2756, 19, 8, 35, 1147, 4, 2367, 3951, 876, 234, 108, 24, 2551, 4, 37, 6, 8727, 11193, 24, 7510, 401, 670, 3, 23, 2, 231, 714, 4, 39, 83, 33, 96, 152, 0, 3, 2, 27, 1187, 198, 17, 62, 11, 67, 33, 432, 1055, 1700, 18, 331, 221, 715, 3, 19, 2, 9745, 7, 2, 293, 3535, 75, 51, 306, 142, 2, 207, 288, 3295, 43, 194, 2185, 24, 58, 39, 78, 2946, 19, 174, 7256, 210, 9, 14, 2, 220, 342, 401, 8, 35, 38, 222, 304, 7, 2272, 0, 4, 57, 187, 1956, 128, 2087, 52, 2733, 8, 2, 383, 1370, 7, 2, 4167, 12702, 128, 1071, 52, 986, 185, 1638, 16, 3, 19, 82, 579, 32, 1183, 31, 803, 2, 26, 22, 13, 1824, 269, 3831, 357, 6, 61, 0, 61, 4, 3467, 9156, 43, 44, 758, 588, 4, 1222, 144, 8, 2, 3759, 1767, 3, 73, 360, 2525, 710, 2, 229, 299, 12, 5265, 23, 61, 2, 1241, 534, 61, 4, 5, 220, 216, 11259, 7, 165, 17, 19752, 105, 2, 2347, 85, 102, 3785, 21, 174, 772, 221, 55, 46, 3, 23, 13, 26, 4, 13116, 66, 1076, 5, 2948, 1390, 8, 53, 2, 188, 23, 2, 3759, 2347, 3, 19, 11, 6230, 14, 13, 26, 4, 47, 61, 2, 20882, 61, 6, 61, 2, 6335, 61, 186, 10, 4, 113, 4047, 105, 6818, 824, 822, 2174, 4, 1133, 2, 207, 288, 8, 125, 61, 523, 61, 2920, 3]),\n",
              "        list([40, 41, 42, 36, 28, 200, 2612, 182, 2, 708, 309, 312, 111, 3, 13, 38, 298, 514, 23, 69, 277, 4, 3256, 6, 69, 115, 32, 76, 69, 31, 3, 878, 4, 187, 79, 11, 88, 15657, 0, 32, 2, 863, 31, 11, 436, 446, 61, 123, 60, 48, 77, 16, 5, 0, 21, 171, 14, 131, 6017, 127, 2262, 3, 19, 5, 866, 466, 7, 62, 505, 73, 242, 23, 69, 1181, 6, 527, 8, 271, 235, 223, 5, 404, 4, 2, 139, 14, 17, 840, 7, 307, 3, 11, 53, 25, 131, 58, 11, 278, 74, 571, 21, 2, 519, 7, 2, 20, 55, 2, 1240, 56, 81, 25, 100, 166, 104, 235, 3, 19, 11, 283, 141, 10, 16, 70, 21, 139, 357, 12, 10, 16, 7321, 4, 22, 11, 53, 25, 131, 58, 11, 283, 184, 8, 920, 5, 481, 8, 10, 86, 19, 11640, 86, 36, 127, 202, 98, 14, 16, 2, 3599, 10, 113, 153, 3]),\n",
              "        list([40, 41, 42, 36, 11, 283, 2084, 13, 413, 981, 55, 772, 267, 167, 12, 2239, 4, 262, 21, 146, 2025, 419, 8, 123, 3, 45, 11, 80, 141, 9, 14, 39, 75, 45, 60, 2025, 419, 138, 2, 324, 11, 2108, 8, 644, 13, 3, 19, 11, 113, 218, 10, 1031, 21, 128, 7207, 6, 17710, 129, 92, 15, 2431, 3512, 15, 4, 22, 12, 11230, 14, 16, 183, 1051, 8, 141, 261, 13, 38, 27, 81, 25, 33, 7468, 1059, 8604, 12, 10, 3, 2, 106, 215, 10, 2820, 12, 14342, 75, 94, 54, 224, 228, 4, 224, 93, 4, 70, 641, 6, 2028, 4, 22, 11, 1069, 28, 178, 25, 33, 314, 3, 19, 162, 162, 162, 27, 821, 27, 1444, 162, 162, 162, 2, 12093, 1027, 7, 1016, 3598, 32, 38, 7, 85, 17, 5, 1016, 86, 153, 801, 31, 9410, 204, 57, 13176, 14184, 8, 13176, 14184, 252, 8, 7907, 60, 45, 2, 1261, 10, 83, 205, 3, 2, 1027, 2793, 7, 94, 2, 7242, 4, 20255, 18, 53, 18, 108, 1732, 32, 56, 1220, 499, 29, 31, 4, 44, 52, 18, 2, 18, 287, 4, 300, 7390, 107, 3392, 4, 2, 2942, 1016, 1016, 1829, 32, 30, 5, 18512, 31, 4, 5, 2800, 3391, 6, 5, 27, 76, 4, 27, 76, 5997, 1639, 8482, 4, 15, 1484, 201, 15, 586, 86, 10, 239, 782, 47, 2, 228, 21, 27, 3742, 16, 61, 2, 179, 263, 61, 3, 118, 2, 1732, 1220, 12, 5, 1210, 5599, 23, 5, 3031, 7, 12146, 32, 6, 24, 10, 576, 60, 4, 2871, 7, 2, 13650, 580, 7, 531, 9290, 31, 44, 107, 3392, 372, 132, 86, 1374, 4, 1374, 4, 1374, 86, 348, 4144, 117, 86, 1374, 4, 1374, 4, 1374, 86, 11, 83, 153, 29, 4, 22, 24, 11, 291, 10, 16, 2, 188, 675, 366, 12, 59, 5, 2878, 106, 61, 138, 61, 7, 2, 643, 3, 19, 2, 277, 75, 1886, 6, 124, 602, 7961, 17, 12, 13, 20, 9, 638, 87, 3, 2, 1016, 1016, 1829, 32, 175, 30, 5, 18512, 31, 17, 183, 846, 4, 22, 7, 307, 58, 28, 173, 1018, 21, 65, 8, 5786, 74, 92, 51, 65, 9955, 4, 172, 2768, 3, 19, 11, 178, 25, 141, 14, 10, 17, 2, 163, 26, 11, 154, 135, 4, 24, 11, 161, 1207, 61, 10017, 7993, 208, 61, 4, 22, 761, 21, 13, 38, 8, 236, 29, 2, 875, 18, 871, 1038, 3]),\n",
              "        list([40, 41, 42, 36, 59, 1684, 189, 105, 13, 20, 4, 11, 17, 441, 755, 3, 234, 320, 4, 155, 122, 75, 1008, 476, 3, 2343, 4, 146, 1090, 67, 581, 4, 22, 102, 215, 67, 507, 195, 214, 3, 3202, 4, 82, 4413, 17, 910, 9851, 4, 6, 2, 301, 8, 13, 20, 17, 25, 69, 43, 45, 3, 226, 4, 10, 17, 52, 64, 808, 70, 203, 8, 4024, 1073, 159, 2, 107, 4984, 189, 3, 46, 4, 11, 67, 141, 14, 2, 20, 17, 1014, 536, 4, 6, 1011, 45, 7, 2, 618, 12, 2, 228, 4, 11, 283, 572, 13, 5, 904, 3]),\n",
              "        list([40, 41, 42, 36, 5, 160, 1331, 44, 216, 381, 8, 44, 405, 134, 44, 1273, 381, 1257, 7, 54, 15, 1714, 15, 3, 44, 216, 381, 66, 51, 96, 716, 57, 54, 5145, 6, 9, 119, 27, 84, 1173, 48, 45, 7, 2, 2165, 77, 489, 2020, 3880, 6, 356, 9236, 45, 132, 2, 321, 3, 9, 77, 169, 884, 214, 55, 9, 2, 107, 381, 629, 166, 57, 2, 328, 49, 19, 28, 154, 256, 3325, 2, 301, 46, 11, 484, 25, 3859, 10, 60, 3, 11, 244, 13, 148, 267, 29, 2279, 2679, 268, 24, 5, 481, 3, 166, 102, 4, 11, 541, 10, 22, 11, 27, 17, 281, 3, 356, 10, 177, 11, 869, 101, 69, 10, 9, 3, 10, 16, 1470, 892, 4, 575, 399, 4, 84, 476, 32, 68, 43, 54, 453, 31, 6, 66, 5, 624, 228, 7, 27, 608, 99, 32, 38, 128, 2, 168, 31, 48, 175, 10, 90, 33, 63, 70, 215, 59, 10, 3, 19, 2, 282, 9, 1730, 954, 6, 2, 1022, 424, 23, 2, 624, 1641, 334, 6, 11530, 3944, 9, 2779, 3725, 3, 50, 119, 34, 5, 180, 524, 461, 32, 11, 3734, 5, 139, 73, 77, 244, 2, 107, 3770, 31, 6, 5, 729, 1553, 301, 3, 45, 12, 45, 10, 16, 610, 27, 30, 5, 70, 20, 86, 22, 30, 5, 676, 1260, 317, 3, 10, 90, 33, 5, 500, 1172, 1070, 3, 11, 218, 10, 5, 208, 3, 19, 119, 335, 8, 533, 2, 5677, 27, 345, 1235, 18, 12, 4853, 7, 10, 32, 10, 16, 9865, 23, 15, 1114, 7, 2, 1226, 22349, 15, 31, 3, 10, 16, 12, 27, 260, 3390, 23, 2539, 6, 13737, 45, 132, 3, 10, 81, 25, 68, 172, 13, 69, 29, 268, 48])],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "id": "o5VenkmZMWf_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bptt,em_sz,nh,nl = 70,400,1150,3\n",
        "vs = len(itos)\n",
        "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
        "bs = 48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfDykNGoMWgC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "min_lbl = trn_labels.min()\n",
        "trn_labels -= min_lbl\n",
        "val_labels -= min_lbl\n",
        "c=int(trn_labels.max())+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbMlaFYvFCAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83227365-c895-441e-9616-c1e55c21edfc"
      },
      "cell_type": "code",
      "source": [
        "c"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "2lF6B6TvMWgD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the classifier, unlike LM, we need to read a movie review at a time and learn to predict the it's sentiment as pos/neg. We do not deal with equal bptt size batches, so we have to pad the sequences to the same length in each batch. To create batches of similar sized movie reviews, we use a sortish sampler method invented by [@Smerity](https://twitter.com/Smerity) and [@jekbradbury](https://twitter.com/jekbradbury)\n",
        "\n",
        "The sortishSampler cuts down the overall number of padding tokens the classifier ends up seeing."
      ]
    },
    {
      "metadata": {
        "id": "G5Ksss7aMWgG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bs = 10\n",
        "trn_ds = TextDataset(trn_clas, trn_labels)\n",
        "val_ds = TextDataset(val_clas, val_labels)\n",
        "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
        "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
        "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
        "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
        "md = ModelData(PATH, trn_dl, val_dl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5wY5U99bOHbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72c058f5-6f59-414d-f45c-8eae6f441d17"
      },
      "cell_type": "code",
      "source": [
        "trn_labels[:10]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "Z9oKxcG6-qrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5da9b51-2318-4a61-f04a-6e0c5e916334"
      },
      "cell_type": "code",
      "source": [
        "bs"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "metadata": {
        "id": "iB9sCWhfDhmv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#sample = next(iter(trn_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woy0hzC9DwQG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#sample.size(), sample[2500] # as always w pytorch rnn, data comes one at a time from each batch, side by side "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fK9z_asUMWgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# part 1\n",
        "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLbgEdvyMWgP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bs9H0OvMF9g3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MlKBpEy4MWgR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Was getting error here in normal pip installed version. Have to get latest from github, then pip install as above\n",
        "m = get_rnn_classifier(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
        "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
        "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6DRtWR_wFVuo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pX1MSel-MWgT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHhDFY7gMWgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
        "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
        "learn.clip=25.\n",
        "learn.metrics = [accuracy]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYPA2RF3MWgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=3e-3\n",
        "lrm = 2.6\n",
        "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2I9KNvAMWga",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wK9LjadMWgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wd = 1e-7\n",
        "wd = 0\n",
        "learn.load_encoder('lm1_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hXoWGYoDMWge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yd0SyD0hMWgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1996
        },
        "outputId": "566ba249-9325-444a-d6cf-8d6ee108c765"
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(lrs/1000)\n",
        "learn.sched.plot()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "451a002bd1dd4fd080455e6094a41650",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/2000 [00:00<?, ?it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-9b045eb09223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, wds, linear, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR_Finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxtra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/lm_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mraw_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbptt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/lm_rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                     \u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mnew_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/rnn_reg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mtensor\u001b[0m \u001b[0mobtained\u001b[0m \u001b[0mby\u001b[0m \u001b[0mrunning\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mwrapped\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setweights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai/rnn_reg.py\u001b[0m in \u001b[0;36m_setweights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname_w\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mraw_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_w\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_raw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, input, p, train, inplace)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/_functions/dropout.py\u001b[0m in \u001b[0;36m_make_noise\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /pytorch/torch/lib/THC/generic/THCStorage.cu:58"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "wf6d53jFMWgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "53086198-8a4a-430b-9c08-8b68489a14b0"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c48837600cbe401ca8311e7c0a607d5b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      0.0        0.0        1.0       \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.]), 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "metadata": {
        "id": "TzLTDEOXMWgl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('clas_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vK_OcushMWgm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('clas_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e6NW8SweMWgn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uxg3XdBrMWgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6c9cb078-56df-49e5-8408-8a909892b088"
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49697c7c5ff44ec2942fb06c49a35622",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "epoch      trn_loss   val_loss   accuracy   \n",
            "    0      0.0        0.0        1.0       \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.]), 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "EjgOHbH_MWgp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('clas_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AmXoo7QjMWgq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('clas_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w6SSyGhtMWgu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "had3dZdLMWgv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))\n",
        "learn.fit(lrs, 1, wds=wd, cycle_len=5, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Rj9tTcYMWgx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "0e04413b-6b52-4c04-d81b-20f8e1775ba8"
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot_loss()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAArxv9AvYI593ATdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff3b00576a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "owAGLTa5GzbU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Predicting\n",
        "learn.data.test_dl = val_dl\n",
        "log_preds = learn.predict(is_test=True)\n",
        "\n",
        "preds = np.argmax(log_preds, axis=1) # from log probabilities to 0 or 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yj3vQ-FyMWg1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('clas_2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QDmSR3oMWg2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The previous state of the art result was 94.1% accuracy (5.9% error). With bidir we get 95.4% accuracy (4.6% error)."
      ]
    },
    {
      "metadata": {
        "id": "UKcNfxE8Ts6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "# forcing upstream repo to take this new model file, without having to fetch and merge\n",
        "\"\"\"\n",
        "!git init\n",
        "!git config --global user.email \"rudygilman@gmail.com\"\n",
        "!git config --global user.name \"Rudy Gilman\n",
        "!git add imdb_data/aclImdb/models/clas_2.h5\n",
        "!git commit -m \"a commit\"\n",
        "!git push -f --set-upstream https://rgilman33:Q!w2e3r4@github.com/rgilman33/imdb_sync.git master\"\"\"\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"imdb_data/aclImdb/models/clas_2.h5\") # too big! times out, connection reset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqgYMLn5Byb5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WZ1OFAsaMWg2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fin"
      ]
    },
    {
      "metadata": {
        "id": "Uqeysp4vMWg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "63906bed-1698-444a-e111-459b93ef81d9"
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot_loss()"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFKCAYAAAAwrQetAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAArxv9AvYI593ATdAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7ff3af6b0240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}