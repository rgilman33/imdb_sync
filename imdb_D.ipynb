{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtzJO_iVMWcm"
   },
   "source": [
    "\n",
    "## IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "loEJj5O7J0Ex"
   },
   "source": [
    "\n",
    "\n",
    "figure out how to save model. \n",
    "upload data from deloitte,  process test data in same way as other data. \n",
    "get a good pred, upload\n",
    "\n",
    "data in. rationalize data structure. had mismatch with max 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9jMDrgPMWcn"
   },
   "source": [
    "At Fast.ai we have introduced a new module called fastai.text which replaces the torchtext library that was used in our 2018 dl1 course. The fastai.text module also supersedes the fastai.nlp library but retains many of the key functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3733
    },
    "colab_type": "code",
    "id": "CGv--rGmMxbT",
    "outputId": "60015313-1b3b-4846-bc08-3503eb8b0699"
   },
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/fastai/fastai.git # grabbing latest version\n",
    "#!pip install spacy\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qGNYbbAHMWcp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g86Ey53PMWcv"
   },
   "source": [
    "The Fastai.text module introduces several custom tokens.\n",
    "\n",
    "We need to download the IMDB large movie reviews from this site: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "Direct link : [Link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) and untar it into the PATH location. We use pathlib which makes directory traveral a breeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqqb_xRRMWcw"
   },
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "PATH=Path('imdb_data/aclImdb/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eva7LVasSRWI"
   },
   "outputs": [],
   "source": [
    "#!mkdir \"imdb_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNbwDW_UMWc0"
   },
   "source": [
    "## Standardize format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kz3P4RXaMWc1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CLAS_PATH=Path('imdb_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH=Path('imdb_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cEeU74qNMWc5"
   },
   "source": [
    "The imdb dataset has 3 classes. positive, negative and unsupervised(sentiment is unknown). \n",
    "There are 75k training reviews(12.5k pos, 12.5k neg, 50k unsup)\n",
    "There are 25k validation reviews(12.5k pos, 12.5k neg & no unsup)\n",
    "\n",
    "Refer to the README file in the imdb corpus for further information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vodLUCvlMWdD"
   },
   "outputs": [],
   "source": [
    "col_names = ['labels','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "Ypq-v2ynRJtt",
    "outputId": "82c6a7c6-83a4-46d2-9a33-ee2a571c3cfa"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Grabbing D data\n",
    "#!git clone https://github.com/rgilman33/imdb_sync.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "8xt3kmJOZXOA",
    "outputId": "731c7b8c-9d2b-4f9a-f92d-15917bfdf086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>2592</td>\n",
       "      <td>0</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>18359</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>17262</td>\n",
       "      <td>1</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>9908</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset     id  labels                                               text\n",
       "0   train   2592       0  Un-bleeping-believable! Meg Ryan doesn't even ...\n",
       "1   train  18359       1  This is a extremely well-made film. The acting...\n",
       "2   train   1040       0  Every once in a long while a movie will come a...\n",
       "3   train  17262       1  Name just says it all. I watched this movie wi...\n",
       "4   train   9908       0  This movie succeeds at being one of the most u..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the train set and the test set. Creating single df w everthing.\n",
    "\n",
    "df_trn = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_trn[\"dataset\"] = \"train\"; df_test[\"dataset\"] = \"test\"\n",
    "df_test[\"labels\"] = 3\n",
    "\n",
    "df = pd.concat([df_trn, df_test], axis=0); print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('This film is the freshman effort of Stephanie Beaton and her new production company. While it suffers from a few problems, as every low budget production does, it is a good start for Ms. Beaton and her company.<br /><br />The story is not terribly new having been done in films like The Burning and every Friday the 13th since part 2. But, the performances are heartfelt. So many big budget movies just have the actors going through the motions, its always nice to see actors really trying to hone their craft.<br /><br />The story deals with the murder(and possible return) of a disfigured classmate. The others are sworn to secrecy, but the trauma of the event sends each person in different directions in their lifes. Ten years later, the friends are murdered one by one by a gruesome stalker known as \"The Bagman\". Who will survive? You have to watch.<br /><br />If you are Roger Ebert or any number of arrogant critics, you probably shouldn\\'t bother. But if your taste run more towards Joe Bob Briggs and you want to see a group of people honing their craft, then check out \"The Bagman\".',\n",
       " \"Have wanted to see this for a while: I never thought I'd be watching it in a damp Trafalgar Square, London with 15,000 other people and all to a new score by the Pet Shop Boys.<br /><br />Quickly, that experience specifically. A new departure from PSB, it seemed to suffer from the same problem the miniaturist Hugo Wolf had when he wrote his opera Der Corregidor: the long structure was a chain of short ones, i.e. songs. PSB produced a more fluid, integrated score although it was quite static on its own terms. Neither could they resist song: a setting of the subtitled text worked in this respect a free standing meditation on the action of the Odessa steps massacre during the action of that sequence itself was, I'd go so far to say, counterproductive. Overall it was very exciting though, which is surely what Eisenstein was trying to achieve.<br /><br />It is a very exciting film with choppier editing taking the place of acceleration of tension or action. In fact the film, though beautifully shot and passionately acted (it has a silent film melodrama, but not in the excess of the Hollywood comic style) breathes through its careful editing pacing specific shots with a sense of the rate at which the audience will take them in. And there's a huge range of perspective too; either he had a lot of cameras or the sequences on the harbor and steps took a great deal of time.<br /><br />Super film, which can be assessed irrespective of sound, as that's how the finished product would have been conceived. 8/10\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 8\n",
    "df_trn.text.iloc[i], df_test.text.iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1325.31292, 1294.0274)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.text.str.len().mean(), df_test.text.str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpoOrPz-X0ou"
   },
   "outputs": [],
   "source": [
    "# For dev, use sample\n",
    "\n",
    "\n",
    "#df = df.sample(3000, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bww08L1bStmw"
   },
   "outputs": [],
   "source": [
    "# Saving to csv to open again with chunks\n",
    "\n",
    "df.to_csv(LM_PATH/'df.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjMG9rxiO9-3"
   },
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QWoYYt0MWdj"
   },
   "source": [
    "In this section, we start cleaning up the messy text. There are 2 main activities we need to perform:\n",
    "\n",
    "1. Clean up extra spaces, tab chars, new ln chars and other characters and replace them with standard ones\n",
    "2. Use the awesome [spacy](http://spacy.io) library to tokenize the data. Since spacy does not provide a parallel/multicore version of the tokenizer, the fastai library adds this functionality. This parallel version uses all the cores of your CPUs and runs much faster than the serial version of the spacy tokenizer.\n",
    "\n",
    "Tokenization is the process of splitting the text into separate tokens so that each token can be assigned a unique index. This means we can convert the text into integer indexes our models can use.\n",
    "\n",
    "We use an appropriate chunksize as the tokenization process is memory intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qLPT5QtMWdk"
   },
   "outputs": [],
   "source": [
    "chunksize= 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URPNdSmqMWdn"
   },
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrAqnwZiMWdq"
   },
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    #labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fELR8np1MWdu"
   },
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok = []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_SDTbi6MWdw"
   },
   "outputs": [],
   "source": [
    "# Reading back in with chunks\n",
    "\n",
    "df_chunks = pd.read_csv(LM_PATH/'df.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "U5hg58Q7MWdy",
    "outputId": "25b120a7-b4fd-46fa-bb44-1de80ba88c9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting list of tokenized lists\n",
    "\n",
    "tok_text = get_all(df_chunks, 1)\n",
    "len(tok_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "smXWTQAviMAE"
   },
   "outputs": [],
   "source": [
    "# adding back to df\n",
    "df[\"tokenized_text\"] = tok_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create symlink to spacy en model\n",
    "\n",
    "mklink C:\\Users\\rudyg\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\spacy\\data\\en C:\\Users\\rudyg\\AppData\\Local\\conda\\conda\\envs\\fastai\\lib\\site-packages\\en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "qD4exjCsMWd1",
    "outputId": "c1781f88-9810-4e5e-b715-4c6116025f61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'xbos',\n",
       " 'xfld',\n",
       " '1',\n",
       " '2592',\n",
       " 'xfld',\n",
       " '1',\n",
       " '0',\n",
       " 'xfld',\n",
       " '2',\n",
       " 'un',\n",
       " '-',\n",
       " 'bleeping',\n",
       " '-',\n",
       " 'believable',\n",
       " '!',\n",
       " 'meg',\n",
       " 'ryan',\n",
       " 'does',\n",
       " \"n't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tokenized_text.iloc[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "n5wVLf_kMWeA",
    "outputId": "94eae392-b273-4dda-cc4b-e8718e790be1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 666238),\n",
       " ('.', 549276),\n",
       " (',', 542898),\n",
       " ('and', 323667),\n",
       " ('a', 321663),\n",
       " ('of', 289313),\n",
       " ('to', 267950),\n",
       " ('is', 217126),\n",
       " ('it', 189546),\n",
       " ('in', 186509),\n",
       " ('i', 173646),\n",
       " ('this', 150480),\n",
       " ('xfld', 150000),\n",
       " ('that', 144270),\n",
       " ('\"', 130201),\n",
       " (\"'s\", 121976),\n",
       " ('1', 116114),\n",
       " ('-', 103672),\n",
       " ('was', 100025),\n",
       " ('\\n\\n', 98729),\n",
       " ('as', 91576),\n",
       " ('movie', 87553),\n",
       " ('for', 87334),\n",
       " ('with', 87262),\n",
       " ('but', 83204)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in df.tokenized_text for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cx0ZYjSlMWeE"
   },
   "source": [
    "The *vocab* is the **unique set of all tokens** in our dataset. The vocab provides us a way for us to simply replace each word in our datasets with a unique integer called an index.\n",
    "\n",
    "In a large corpus of data one might find some rare words which are only used a few times in the whole dataset. We discard such rare words and avoid trying to learn meaningful patterns out of them.\n",
    "\n",
    "Here we have set a minimum frequency of occurence to 2 times. It has been observed by NLP practicioners that a maximum vocab of 60k usually yields good results for classification tasks. So we set maz_vocab to 60000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Du0W05vYMWeF"
   },
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4BtZ471qMWeJ"
   },
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bPawBklfMWeK"
   },
   "source": [
    "We create a reverse mapping called stoi which is useful to lookup the index of a given token. stoi also has the same number of elements as itos. We use a high performance container called [collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) to store our stoi mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K1ZG2GZFMWeL",
    "outputId": "50812ddd-1ff9-4dfa-9105-4c06f114536b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52315"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-W8I_gjIUtOp",
    "outputId": "f376b359-162f-4b45-fe82-f19811eb9ec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1182)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi[\"the\"], stoi[\"awesome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HNE4IvY2MWeN"
   },
   "outputs": [],
   "source": [
    "numerized_tokens = [[stoi[o] for o in p] for p in df.tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mXWgHHuLMWeQ",
    "outputId": "d38398b5-6923-4100-9a5a-c89d342ec09b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 97)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerized_tokens), len(numerized_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qQKs2EvMWeS"
   },
   "outputs": [],
   "source": [
    "df[\"numerized_tokens\"] = numerized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "colab_type": "code",
    "id": "Me-x0LiCVtEG",
    "outputId": "a689dacf-bb0b-49e6-cdac-bc81fdc81b99",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42,\n",
       " 43,\n",
       " 14,\n",
       " 18,\n",
       " 0,\n",
       " 14,\n",
       " 18,\n",
       " 136,\n",
       " 14,\n",
       " 39,\n",
       " 2774,\n",
       " 19,\n",
       " 36953,\n",
       " 19,\n",
       " 840,\n",
       " 48,\n",
       " 4952,\n",
       " 1667,\n",
       " 92,\n",
       " 31]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"numerized_tokens\"].iloc[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8q33ej8WMWeU",
    "outputId": "9af2c086-a780-48c6-b795-6d6cdb4c0dca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos); vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"prepped_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Grabbing prepped data\n",
    "\n",
    "df = pd.read_csv(\"prepped_data.csv\"); print(len(df))\n",
    "vs = 52315 # manually set this to match above\n",
    "\n",
    "import ast\n",
    "df[\"numerized_tokens\"] = df[\"numerized_tokens\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>numerized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>2592</td>\n",
       "      <td>0</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 2592, xfld, 1, 0, xfld, 2,...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 2774,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>18359</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 18359, xfld, 1, 1, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 1040, xfld, 1, 0, xfld, 2,...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 192, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>17262</td>\n",
       "      <td>1</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 17262, xfld, 1, 1, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 411, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>9908</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 9908, xfld, 1, 0, xfld, 2,...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 13, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset     id  labels                                               text  \\\n",
       "0   train   2592       0  Un-bleeping-believable! Meg Ryan doesn't even ...   \n",
       "1   train  18359       1  This is a extremely well-made film. The acting...   \n",
       "2   train   1040       0  Every once in a long while a movie will come a...   \n",
       "3   train  17262       1  Name just says it all. I watched this movie wi...   \n",
       "4   train   9908       0  This movie succeeds at being one of the most u...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [\\n, xbos, xfld, 1, 2592, xfld, 1, 0, xfld, 2,...   \n",
       "1  [\\n, xbos, xfld, 1, 18359, xfld, 1, 1, xfld, 2...   \n",
       "2  [\\n, xbos, xfld, 1, 1040, xfld, 1, 0, xfld, 2,...   \n",
       "3  [\\n, xbos, xfld, 1, 17262, xfld, 1, 1, xfld, 2...   \n",
       "4  [\\n, xbos, xfld, 1, 9908, xfld, 1, 0, xfld, 2,...   \n",
       "\n",
       "                                    numerized_tokens  \n",
       "0  [42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 2774,...  \n",
       "1  [42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 13, 9,...  \n",
       "2  [42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 192, ...  \n",
       "3  [42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 411, 5...  \n",
       "4  [42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 13, 2...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_g2lka0MWeW"
   },
   "source": [
    "## wikitext103 conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfwfB4DRMWeW"
   },
   "source": [
    "We are now going to build an english language model for the IMDB corpus. We could start from scratch and try to learn the structure of the english language. But we use a technique called transfer learning to make this process easier. In transfer learning (a fairly recent idea for NLP) a pre-trained LM that has been trained on a large generic corpus(_like wikipedia articles_) can be used to transfer it's knowledge to a target LM and the weights can be fine-tuned.\n",
    "\n",
    "Our source LM is the wikitext103 LM created by Stephen Merity @ Salesforce research. [Link to dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
    "The language model for wikitext103 (AWD LSTM) has been pre-trained and the weights can be downloaded here: [Link](http://files.fast.ai/models/wt103/). Our target LM is the IMDB LM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2537
    },
    "colab_type": "code",
    "id": "IxGyZ9gfMWeW",
    "outputId": "3c0b62cc-3694-4b32-be6d-161ed9325f4d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-08-23 20:33:47--  http://files.fast.ai/models/wt103/\n",
      "Resolving files.fast.ai (files.fast.ai)... 67.205.15.147\n",
      "Connecting to files.fast.ai (files.fast.ai)|67.205.15.147|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:33:47 (150 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html’ saved [857/857]\n",
      "\n",
      "Loading robots.txt; please ignore errors.\n",
      "--2018-08-23 20:33:47--  http://files.fast.ai/robots.txt\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2018-08-23 20:33:47 ERROR 404: Not Found.\n",
      "\n",
      "--2018-08-23 20:33:47--  http://files.fast.ai/models/wt103/?C=N;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=N;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:33:47 (165 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=N;O=D’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:33:47--  http://files.fast.ai/models/wt103/?C=M;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=M;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:33:47 (161 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=M;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:33:47--  http://files.fast.ai/models/wt103/?C=S;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=S;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:33:47 (169 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=S;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:33:47--  http://files.fast.ai/models/wt103/?C=D;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=D;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:33:47 (173 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=D;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:33:47--  http://files.fast.ai/models/wt103/bwd_wt103.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387687 (441M) [text/plain]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/bwd_wt103.h5’\n",
      "\n",
      "models/wt103/bwd_wt 100%[===================>] 440.97M   113MB/s    in 3.9s    \n",
      "\n",
      "2018-08-23 20:33:51 (112 MB/s) - ‘imdb_data/aclImdb/models/wt103/bwd_wt103.h5’ saved [462387687/462387687]\n",
      "\n",
      "--2018-08-23 20:33:51--  http://files.fast.ai/models/wt103/bwd_wt103_enc.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387634 (441M) [text/plain]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/bwd_wt103_enc.h5’\n",
      "\n",
      "models/wt103/bwd_wt 100%[===================>] 440.97M   113MB/s    in 3.9s    \n",
      "\n",
      "2018-08-23 20:33:55 (113 MB/s) - ‘imdb_data/aclImdb/models/wt103/bwd_wt103_enc.h5’ saved [462387634/462387634]\n",
      "\n",
      "--2018-08-23 20:33:55--  http://files.fast.ai/models/wt103/fwd_wt103.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387687 (441M) [text/plain]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/fwd_wt103.h5’\n",
      "\n",
      "models/wt103/fwd_wt 100%[===================>] 440.97M   112MB/s    in 3.9s    \n",
      "\n",
      "2018-08-23 20:33:59 (112 MB/s) - ‘imdb_data/aclImdb/models/wt103/fwd_wt103.h5’ saved [462387687/462387687]\n",
      "\n",
      "--2018-08-23 20:33:59--  http://files.fast.ai/models/wt103/fwd_wt103_enc.h5\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 462387634 (441M) [text/plain]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/fwd_wt103_enc.h5’\n",
      "\n",
      "models/wt103/fwd_wt 100%[===================>] 440.97M   113MB/s    in 3.9s    \n",
      "\n",
      "2018-08-23 20:34:03 (113 MB/s) - ‘imdb_data/aclImdb/models/wt103/fwd_wt103_enc.h5’ saved [462387634/462387634]\n",
      "\n",
      "--2018-08-23 20:34:03--  http://files.fast.ai/models/wt103/itos_wt103.pkl\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4161252 (4.0M) [text/plain]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/itos_wt103.pkl’\n",
      "\n",
      "models/wt103/itos_w 100%[===================>]   3.97M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2018-08-23 20:34:03 (113 MB/s) - ‘imdb_data/aclImdb/models/wt103/itos_wt103.pkl’ saved [4161252/4161252]\n",
      "\n",
      "--2018-08-23 20:34:03--  http://files.fast.ai/models/wt103/?C=N;O=A\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=N;O=A’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:34:03 (160 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=N;O=A’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:34:03--  http://files.fast.ai/models/wt103/?C=M;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=M;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:34:03 (170 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=M;O=D’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:34:03--  http://files.fast.ai/models/wt103/?C=S;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=S;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:34:03 (168 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=S;O=D’ saved [857/857]\n",
      "\n",
      "--2018-08-23 20:34:03--  http://files.fast.ai/models/wt103/?C=D;O=D\n",
      "Reusing existing connection to files.fast.ai:80.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 857 [text/html]\n",
      "Saving to: ‘imdb_data/aclImdb/models/wt103/index.html?C=D;O=D’\n",
      "\n",
      "models/wt103/index. 100%[===================>]     857  --.-KB/s    in 0s      \n",
      "\n",
      "2018-08-23 20:34:03 (177 MB/s) - ‘imdb_data/aclImdb/models/wt103/index.html?C=D;O=D’ saved [857/857]\n",
      "\n",
      "FINISHED --2018-08-23 20:34:03--\n",
      "Total wall clock time: 16s\n",
      "Downloaded: 14 files, 1.7G in 16s (113 MB/s)\n"
     ]
    }
   ],
   "source": [
    "#! wget -nH -r -np -P {PATH} http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8G67GTITMWed"
   },
   "source": [
    "The pre-trained LM weights have an embedding size of 400, 1150 hidden units and just 3 layers. We need to match these values  with the target IMDB LM so that the weights can be loaded up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHuq7UvPMWed"
   },
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yv07tk5lMWef"
   },
   "outputs": [],
   "source": [
    "# Grabbing the files from the download \n",
    "\n",
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "10gs2T02MWeh"
   },
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vj8Qm3TVMWen"
   },
   "source": [
    "We calculate the mean of the layer0 encoder weights. This can be used to assign weights to unknown tokens when we transfer to target IMDB LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O9GNMYh2MWeo"
   },
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkZQvETAMWer"
   },
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iIj_QS4CMWew"
   },
   "source": [
    "Before we try to transfer the knowledge from wikitext to the IMDB LM, we match up the vocab words and their indexes. \n",
    "We use the defaultdict container once again, to assign mean weights to unknown IMDB tokens that do not exist in wikitext103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y547u_gZMWez"
   },
   "outputs": [],
   "source": [
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopA5fUjMWe2"
   },
   "source": [
    "We now overwrite the weights into the wgts odict.\n",
    "The decoder module, which we will explore in detail is also loaded with the same weights due to an idea called weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaBajLUPMWe2"
   },
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ckG6HjllMWe7"
   },
   "source": [
    "Now that we have the weights prepared, we are ready to create and start training our new IMDB language pytorch model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mNG4uTaPMWe8"
   },
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2-3FkVFMWe9"
   },
   "source": [
    "It is fairly straightforward to create a new language model using the fastai library. Like every other lesson, our model will have a backbone and a custom head. The backbone in our case is the IMDB LM pre-trained with wikitext and the custom head is a linear classifier. In this section we will focus on the backbone LM and the next section will talk about the classifier custom head.\n",
    "\n",
    "bptt (*also known traditionally in NLP LM as ngrams*) in fastai LMs is approximated to a std. deviation around 70, by perturbing the sequence length on a per-batch basis. This is akin to shuffling our data in computer vision, only that in NLP we cannot shuffle inputs and we have to maintain statefulness. \n",
    "\n",
    "Since we are predicting words using ngrams, we want our next batch to line up with the end-points of the previous mini-batch's items. batch-size is constant and but the fastai library expands and contracts bptt each mini-batch using a clever stochastic implementation of a batch. (original credits attributed to [Smerity](https://twitter.com/jeremyphoward/status/980227258395770882))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7IecerFMWe-"
   },
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt= 70\n",
    "bs= 52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otVoW9EyMWfA"
   },
   "source": [
    "The goal of the LM is to learn to predict a word/token given a preceeding set of words(tokens). We take all the movie reviews in both the 90k training set and 10k validation set and concatenate them to form long strings of tokens. In fastai, we use the `LanguageModelLoader` to create a data loader which makes it easy to create and use bptt sized mini batches. The  `LanguageModelLoader` takes a concatenated string of tokens and returns a loader.\n",
    "\n",
    "We have a special modeldata object class for LMs called `LanguageModelData` to which we can pass the training and validation loaders and get in return the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MVUrNXhhMWdY",
    "outputId": "47a1eeda-b3b7-4860-b901-3a5e5cb6b91c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting train and test\n",
    "\n",
    "trn_lm, val_lm = sklearn.model_selection.train_test_split(np.array(df[\"numerized_tokens\"]), test_size=0.1)\n",
    "len(trn_lm), len(val_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AoH_pAUoS2n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "8i4OzsrlWuH0",
    "outputId": "8e95153f-c13f-42dd-c1d2-71ec3b5d381d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9, 6, 228, 126, 895, 23, 539, 47, 2023, 13525, 4, 1219, 103, 1382, 4, 3937, 9486, 5, 1633, 621, 3, 21, 10, 9, 60, 6, 1648, 4307, 850, 0, 1382, 19, 568, 22, 61, 3999, 61, 50, 1530, 360, 8, 1373, 5612, 25, 2, 386, 46, 35, 929, 11, 3, 36, 9, 3749, 2879, 6, 21709, 4, 4064, 2322, 50, 9, 2308, 25, 6, 71, 974, 4, 828, 5, 995, 271, 459, 16968, 3, 45, 2, 189, 76, 4, 3999, 63, 451, 929, 11, 6, 8827, 15948, 4, 5596, 4, 19, 3937, 9486, 19, 50, 63, 100, 5096, 8, 908, 60, 16968, 3, 69, 2, 141, 960, 7, 5596, 63, 6, 134, 27663, 25, 6, 147, 15, 5596, 1265, 15, 9, 6, 8124, 7, 3999, 4, 72, 1670, 6, 1178, 471, 3999, 5, 2, 12575, 847, 2, 128, 4455, 8, 6, 0, 883, 13, 27, 9, 34, 40, 15, 360, 158, 84, 22, 10, 63, 6, 190, 7, 916, 19, 6534, 5, 221, 1294, 5, 4139, 916, 19, 7332, 3, 54, 35, 105, 1441, 1612, 15, 28, 73, 38, 8, 41, 1990, 34, 8, 1502, 3, 3999, 5, 5596, 35, 221, 71, 12618, 211, 2, 1828, 398, 4, 3999, 153, 1190, 386, 487, 37, 3173, 52, 115, 11, 2, 527, 5, 9, 4255, 360, 8, 116, 115, 685, 3, 26, 7, 288, 5596, 4, 9, 6, 7843, 17449, 50, 184, 4610, 7843, 798, 363, 2, 433, 7, 16, 360, 205, 8, 38, 398, 25, 256, 15, 2302, 3, 16, 72, 607, 563, 19, 2308, 5, 691, 72, 310, 53, 6, 9484, 5, 691, 54, 35, 75, 61, 166, 360, 61, 59, 54, 3, 64, 3331, 88, 111, 7, 44, 20, 2, 61, 99, 61, 234, 50, 480, 6, 1557, 26568, 25, 5596, 17, 141, 447, 50, 9, 2, 382, 491, 7, 6, 45175, 61, 1337, 61, 5, 78, 121, 131, 675, 199, 3150, 47, 3999, 4, 5008, 22, 2301, 8, 2, 11370, 52, 5596, 4, 121, 80, 72, 564, 16, 169, 12, 168, 4149, 3, 16, 741, 8, 15, 2, 16, 386, 35, 153, 13499, 16, 18305, 28, 98, 52, 16968, 34, 131, 1582, 8, 1169, 58, 225, 315, 121, 2203, 10728, 52, 6, 2377, 7, 360, 3, 11, 2763, 7, 44, 2, 1921, 11896, 5, 0, 19, 386, 79, 237, 400, 69, 28, 2438, 31, 131, 731, 25, 115, 65, 19, 13, 23, 92, 38, 2, 2261, 244, 15, 11, 851, 4, 134, 353, 92, 31, 1879, 3, 54, 35, 66, 174, 536, 11, 13, 27, 4, 162, 22, 2322, 5, 37, 1104, 9310, 26, 13, 27, 466, 4, 81, 3725, 2, 2081, 27, 7705, 47, 6, 13288, 1129, 3]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 12, 449, 812, 44, 2, 119, 11, 2, 1592, 1374, 229, 25, 2, 1490, 7, 2, 40, 12, 123, 9, 3776, 16, 13802, 16, 3, 16, 42620, 16, 20, 6, 249, 852, 11, 3658, 118, 4, 26, 12, 153, 529, 10, 3, 13, 40, 9, 40, 7, 77, 2537, 7, 2, 229, 4, 62, 183, 347, 24, 2, 104, 369, 7, 16, 163, 1455, 4, 116, 77, 275, 16, 3, 13, 40, 105, 928, 49, 243, 2988, 1085, 135, 7, 306, 864, 167, 15, 38, 245, 58, 383, 3, 56, 123, 16, 12676, 1101, 16, 25, 362, 800, 60, 50, 9, 532, 2, 3536, 5, 28, 38, 148, 135, 3, 2479, 54, 9, 6, 249, 70, 94, 15, 22, 13, 40, 92, 795, 6, 71, 354, 489, 5006, 45, 49, 5721, 1248, 3, 10, 105, 928, 1592, 1374, 404, 6, 15483, 22, 6, 3750, 5, 10, 12810, 74, 3274, 8271, 11, 6, 273, 1969, 152, 3, 2, 81, 920, 15, 1299, 9, 156, 3373, 2590, 86, 8, 38, 2, 273, 1572, 551, 3274, 8271, 11, 51, 129, 7, 37, 119, 3, 72, 994, 2, 585, 199, 6, 244, 192, 76, 78, 69, 466, 2, 23, 9, 753, 8, 88, 3, 2479, 72, 9, 34, 8, 99, 151, 4, 26, 58, 125, 97, 38, 100, 51, 95, 149, 47, 306, 347, 3, 178, 469, 25, 13, 23, 5, 101, 1592, 1374, 119, 4, 45, 236, 46, 241, 331, 8, 41, 14927, 24, 1972, 3, 12, 53, 1972, 22, 95, 22, 2, 390, 414, 4, 26, 57, 90, 82, 376, 157, 7, 110, 4021, 44, 2, 302, 5924, 7, 37, 11376, 3046, 5, 108, 129, 3998, 10, 1743, 65, 153, 4, 71, 354, 2922, 106, 2, 1592, 1374, 229, 7, 119, 3]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 13, 9, 187, 8, 41, 2, 111, 3177, 938, 12, 38, 146, 292, 199, 4, 26, 267, 12, 227, 57, 10, 8, 3197, 28, 60, 2, 8231, 8, 456, 15, 16, 2764, 17, 367, 16, 9, 3, 10, 9, 34, 81, 2, 71, 270, 4717, 7, 2, 2021, 229, 4, 26, 9, 230, 74, 54, 25, 2, 270, 209, 766, 7, 44, 76, 48, 10, 20, 374, 4, 1160, 4, 5, 812, 349, 890, 3, 2, 510, 8873, 295, 5, 144, 19, 2, 19, 364, 33, 2105, 1174, 35, 219, 8, 1335, 13, 16, 27, 16, 106, 2, 1507, 3, 217, 4, 10, 92, 31, 562, 54, 4, 56, 741, 99, 138, 4, 6, 406, 250, 4, 5, 6, 640, 7, 922, 3456, 5, 28, 161, 208, 655, 13, 22740, 2625, 7, 32989, 48, 10, 17, 75, 599, 156, 2764, 4, 22, 237, 278, 47, 627, 9789, 4, 63, 112, 128, 50497, 3148, 3, 12, 73, 118, 62, 12, 438, 59, 53, 15, 3, 13, 9, 6, 3786, 476, 81, 23, 4, 57, 31, 5786, 45, 280, 884, 3]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 53, 51, 129, 101, 2073, 30, 151, 4, 77, 1824, 7, 13, 140, 35, 10193, 2340, 3, 11, 218, 4, 51, 4287, 35, 326, 12791, 1824, 4, 15, 12, 1033, 4802, 2, 33, 286, 882, 290, 11, 656, 8, 11279, 15, 685, 5, 10575, 838, 7, 1655, 4, 13239, 12, 351, 8, 854, 1317, 24142, 4, 22, 12, 314, 2, 9063, 2898, 7, 3087, 4, 44321, 4, 5672, 4, 29997, 5, 328, 13060, 12435, 6, 1665, 126, 2992, 126, 147, 32, 28, 262, 82, 376, 8, 124, 10, 8, 408, 29, 4, 69, 2, 95, 454, 140, 2783, 3132, 30, 33, 2276, 39, 30, 2424, 16130, 4, 22, 12, 2214, 3, 21, 91, 4, 12, 168, 3687, 8, 154, 15, 78, 121, 44, 155, 175, 5, 169, 816, 13, 25, 1232, 2323, 70, 3076, 32, 48, 29, 540, 4, 2, 140, 63, 448, 636, 7, 113, 15606, 1449, 3, 21, 353, 417, 735, 4, 52, 2, 2668, 122, 5, 85, 2868, 5408, 25, 40, 178, 8, 2, 409, 34, 51, 330, 312, 32, 80, 181, 2749, 8, 18267, 2, 268, 29, 5, 7, 288, 4, 34, 7496, 2, 5979, 912, 631, 441, 723, 52, 2, 109, 888, 4, 2, 2757, 7, 76, 63, 34, 11, 120, 117, 4, 3117, 55, 833, 12350, 120, 7, 3087, 17, 14933, 1449, 3, 21, 22, 3087, 336, 73, 261, 154, 4, 61, 44247, 48, 28, 54, 48, 163, 59, 5, 4096, 655, 66, 4679, 268, 3, 61]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 136, 14, 39, 737, 4, 5482, 210, 875, 431, 3, 12588, 12, 23649, 162, 6, 5441, 200, 73, 34, 41, 587, 906, 10, 86, 3660, 3, 12, 493, 3344, 2843, 172, 9, 51, 1559, 155, 503, 32, 5, 103, 81, 98, 453, 29, 15, 40, 79, 34, 1191, 5, 2154, 95, 120, 70, 3, 430, 30, 90, 87, 381, 49, 15905, 50, 20, 20, 11917, 11, 2, 5375, 5, 90, 86, 10, 16453, 199, 280, 9251, 146, 258, 3, 2, 23, 3297, 4058, 4, 754, 203, 143, 2627, 106, 2, 1337, 5, 81, 40, 639, 6102, 24, 2, 604, 3, 66, 7, 2, 16834, 20, 4, 1993, 4, 2260, 48, 10, 17, 274, 8, 282, 269, 73, 78, 1185, 4, 300, 635, 3542, 8, 4, 2, 3308, 7, 12216, 7, 3126, 7, 2251, 8, 116, 13, 4612, 3]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 1743, 13581, 9, 6, 23, 15, 158, 11, 75, 117, 146, 41, 623, 630, 3, 10, 1696, 3857, 22, 6, 611, 23, 3, 185, 45, 10, 70, 11, 2, 117, 15, 28, 158, 1332, 829, 52, 3282, 738, 3, 46, 35, 40, 11, 2, 189, 11, 15, 46, 35, 221, 51, 99, 46, 35, 174, 3, 2, 174, 410, 11, 75, 1743, 13581, 35, 645, 2, 687, 15, 35, 31, 462, 8, 41, 3, 69, 1576, 32, 278, 47, 5906, 5494, 22, 81, 36, 79, 311, 115, 29, 5540, 2, 14669, 2196, 59, 7, 2, 993, 121, 37, 109, 2182, 25, 51496, 32, 4108, 5897, 29, 5620, 4693, 5, 10, 9, 40, 194, 7, 2, 23, 15, 192, 414, 158, 84, 3, 10, 254, 41, 2, 1542, 152, 146, 4, 12, 3794, 3, 21, 576, 4, 108, 306, 216, 13, 23, 73, 116, 315, 12, 262, 133, 142, 5, 15, 414, 158, 261, 41, 3596, 106, 11728, 3, 12, 458, 46, 45, 247, 208, 3879, 3, 13, 23, 9014, 6, 18, 59, 7, 370, 30, 77, 2303, 5, 15, 40, 9, 56, 24, 2, 3529, 174, 536, 3]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 12, 227, 154, 4, 13, 23, 63, 381, 88, 6, 11117, 1611, 3, 12, 161, 100, 582, 195, 5, 195, 8, 33, 2890, 74, 5, 397, 1399, 53, 6, 1246, 414, 3, 26, 4, 10, 17, 71, 274, 93, 75, 34, 2, 6818, 3, 89, 28, 186, 15, 2208, 5, 13739, 65, 91, 4, 98, 11, 2, 1255, 24, 6, 190, 70, 3, 13, 23, 9, 56, 6752, 48, 10, 17, 34, 6, 27, 8, 140, 148, 1769, 19, 786, 4, 26, 28, 158, 140, 10, 8, 6, 2162, 55, 66, 6072, 234, 45, 148, 15465, 3, 576, 4, 165, 8, 2, 565, 6337, 3, 3032, 13, 2060, 63, 66, 2082, 147, 32, 89, 269, 45, 2, 1150, 1430, 15, 54, 17, 462, 8, 41, 6, 0, 32, 65, 29, 226, 2, 1747, 5, 607, 65, 29, 51, 28, 79, 237, 38, 6, 506, 143, 160, 8, 154, 8, 148, 1427, 55, 2, 1514, 3, 12, 38, 6, 10661, 11, 77, 11209, 3]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 16, 349, 654, 68, 16, 9, 2, 23, 4810, 7, 6, 1218, 7958, 3, 44, 2, 122, 32, 1003, 52, 4409, 17, 836, 11195, 4, 7, 288, 29, 1879, 1581, 8, 41, 552, 4, 371, 22, 16, 16305, 16, 32, 2, 67, 463, 29, 55, 22, 16, 12830, 16, 32, 2, 1964, 29, 3, 2, 173, 353, 14447, 30, 2, 3008, 586, 32, 102, 78, 98, 3793, 1136, 5, 2581, 74, 29, 4, 1618, 13, 106, 49, 2594, 342, 7, 16, 9760, 16, 32, 5, 1312, 4, 53, 3232, 4, 1709, 7865, 8, 2989, 336, 52, 2, 2164, 12331, 29, 3, 476, 7, 13, 356, 7, 171, 32, 5, 4, 696, 4, 54, 35, 129, 29, 103, 379, 10, 4, 422, 201, 222, 3, 5125, 3, 32, 196, 18, 126, 39, 29]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 11554, 6741, 9, 49, 238, 5, 9, 31, 53, 167, 101, 99, 957, 27, 4, 196, 196, 196, 1356, 196, 196, 196, 6, 425, 785, 11191, 1131, 8, 6, 188, 515, 5, 63, 1117, 45, 387, 4, 36, 9, 67, 5651, 3, 6, 266, 11, 2, 2907, 17, 1090, 25, 58, 1330, 4, 69, 85, 534, 20, 8189, 145, 6, 3200, 3, 11554, 32, 4024, 6356, 2464, 29, 52, 2, 664, 5953, 19, 3671, 0, 9, 2879, 11191, 22, 6, 1341, 8, 98, 6, 14176, 363, 2, 117, 36, 227, 1266, 8, 37, 769, 60, 58, 1341, 4, 5, 439, 404, 13, 14176, 4, 11554, 1644, 8, 2, 3200, 72, 1090, 30, 5, 114, 72, 242, 11, 2, 9049, 534, 7, 58, 1330, 5, 46, 10695, 74, 3, 328, 22, 36, 4034, 58, 36, 704, 6, 266, 50, 310, 56, 53, 58, 3, 32, 57, 28, 282, 11, 0, 6741, 9, 6, 67, 23, 8, 84, 169, 5, 114, 26, 46, 1192, 223, 107, 957, 770, 8, 2167, 289, 74, 25, 388, 119, 5, 298, 12, 223, 10, 6, 21, 708, 126, 182]),\n",
       "       list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 186, 10, 638, 15, 56, 107, 2419, 7219, 89, 34, 205, 8, 41, 11, 2, 27, 55, 38, 256, 8, 57, 25, 10, 4, 102, 6177, 123, 2, 23, 1696, 233, 78, 170, 10, 55, 754, 10, 6, 590, 3, 12, 82, 458, 7219, 89, 34, 57, 13, 3, 36, 9, 6, 506, 303, 5, 44, 26, 36, 1833, 102, 265, 52, 6, 557, 23, 3, 21, 12, 277, 10, 455, 3, 10, 20, 31, 348, 3723, 55, 256, 25, 952, 330, 312, 4, 26, 10, 20, 34, 6, 99, 3, 10, 20, 268, 8, 124, 3, 26, 10263, 4, 432, 34, 6, 99, 126, 510, 23, 3, 21, 708, 126, 182])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_lm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XpTDfniMWfB"
   },
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKZlasMWfF"
   },
   "source": [
    "We setup the dropouts for the model - these values have been chosen after experimentation. If you need to update them for custom LMs, you can change the weighting factor (0.7 here) based on the amount of data you have. For more data, you can reduce dropout factor and for small datasets, you can reduce overfitting by choosing a higher dropout factor. *No other dropout value requires tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2rXe03eMWfJ"
   },
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SCv4uQykMWfL"
   },
   "source": [
    "We first tune the last embedding layer so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer.\n",
    "\n",
    "We also keep track of the *accuracy* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdvG06UgMWfM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1) # why are we unfreezing this one? Don't we want to unfreeze FIRST layer?\n",
    "#learner.freeze_all_but(0) # unfreezing embedding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQBT6gdQMWfO"
   },
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ow19E6VOMWfS"
   },
   "source": [
    "We set learning rates and fit our IMDB LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the wikitext103 learn better weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ngvfuUpMWfS"
   },
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "Txylyd_FMWfV",
    "outputId": "505ca1cc-9ae2-4089-fc38-a3bb2728637f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc26b94c1dbd4b33b6f5cfd3b4354960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.640735   4.403062   0.267446  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.40306]), 0.2674456997421952]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train for one epoch, just the embedding layer\n",
    "\n",
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dtphT3CQMWfX"
   },
   "source": [
    "Note that we print out accuracy and keep track of how often we end up predicting the target word correctly. While this is a good metric to check, it is not part of our loss function as it can get quite bumpy. We only minimize cross-entropy loss in the LM.\n",
    "\n",
    "The exponent of the cross-entropy loss is called the perplexity of the LM. (low perplexity is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cpbnd8FYMWfd"
   },
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDFm0VbvMWff"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc4eb4c491045df8a4332a9dc3f7b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                                                                              \n",
      "    0      5.318755   5.140305   0.217942  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CeR1mFsWMWfg"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "OnQDHt2eMWfj",
    "outputId": "0c28d6fe-fccc-4060-f3ed-8334bf5e82b6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5761341cc54f89949f5c53f87b1d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.327969   4.138392   0.292662  \n",
      "    1      4.157868   4.040663   0.302013                     \n",
      "    2      4.066738   3.993988   0.306433                     \n",
      "    3      4.011778   3.970213   0.309139                     \n",
      "    4      3.924371   3.955714   0.311199                     \n",
      "  0%|          | 16/3489 [00:11<41:40,  1.39it/s, loss=3.93]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-7d4903a96952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_clr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#JH did 15 here. Trying 10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/imdb_sync/fastai/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/imdb_sync/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/imdb_sync/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/imdb_sync/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/imdb_sync/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=10) #JH did 15 here. Trying 10. RESULT: 4 is ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ThDxFGt0MWfm"
   },
   "source": [
    "We save the trained model weights and separately save the encoder part of the LM model as well. This will serve as our backbone in the classification task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OBMEI5OVMWfo"
   },
   "outputs": [],
   "source": [
    "learner.save('lm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-nqlyHYMWfp"
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('lm1_enc') # We've got a good one saved. 8.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVqJcXrDMWfq",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for c in learner.children:\n",
    "    for p in c.parameters():\n",
    "        del p\n",
    "    del c\n",
    "        \n",
    "del learner\n",
    "        \n",
    "torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beFvL2n1MWf7"
   },
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkEBapZEMWf8"
   },
   "source": [
    "Now we can create our final model, a classifier which is really a custom linear head over our trained IMDB backbone. The steps to create the classifier model are similar to the ones for the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PrNBcnJ1YYYu",
    "outputId": "66c2038f-01f3-46a2-b511-51d6245e18b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 50000, 22500, 2500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only using data with labels\n",
    "no_test_df = df[df[\"dataset\"]==\"train\"] #.drop_duplicates(subset=\"text\") actually can't do this w out changing vocab\n",
    "\n",
    "# Splitting that subset into train and val\n",
    "trn_df, val_df = sklearn.model_selection.train_test_split(no_test_df, test_size=0.1)\n",
    "\n",
    "len(no_test_df), len(df), len(trn_df), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df[df[\"dataset\"]==\"test\"]; test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>numerized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>98481</td>\n",
       "      <td>3</td>\n",
       "      <td>Bud Abbott and Lou Costello always had a good ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '98481', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>88606</td>\n",
       "      <td>3</td>\n",
       "      <td>This film is not your typical Hollywood fare, ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88606', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>88639</td>\n",
       "      <td>3</td>\n",
       "      <td>Henry Thomas, and Robin Tunny, are a couple of...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88639', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1636, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>76170</td>\n",
       "      <td>3</td>\n",
       "      <td>This digital horror film brings us into the Mi...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '76170', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>81803</td>\n",
       "      <td>3</td>\n",
       "      <td>I just saw this on a local independent station...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '81803', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 56...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 dataset     id  labels  \\\n",
       "25000           0    test  98481       3   \n",
       "25001           1    test  88606       3   \n",
       "25002           2    test  88639       3   \n",
       "25003           3    test  76170       3   \n",
       "25004           4    test  81803       3   \n",
       "\n",
       "                                                    text  \\\n",
       "25000  Bud Abbott and Lou Costello always had a good ...   \n",
       "25001  This film is not your typical Hollywood fare, ...   \n",
       "25002  Henry Thomas, and Robin Tunny, are a couple of...   \n",
       "25003  This digital horror film brings us into the Mi...   \n",
       "25004  I just saw this on a local independent station...   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "25000  ['\\n', 'xbos', 'xfld', '1', '98481', 'xfld', '...   \n",
       "25001  ['\\n', 'xbos', 'xfld', '1', '88606', 'xfld', '...   \n",
       "25002  ['\\n', 'xbos', 'xfld', '1', '88639', 'xfld', '...   \n",
       "25003  ['\\n', 'xbos', 'xfld', '1', '76170', 'xfld', '...   \n",
       "25004  ['\\n', 'xbos', 'xfld', '1', '81803', 'xfld', '...   \n",
       "\n",
       "                                        numerized_tokens  \n",
       "25000  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, ...  \n",
       "25001  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 27...  \n",
       "25002  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1636, ...  \n",
       "25003  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 36...  \n",
       "25004  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 56...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2lF6B6TvMWgD"
   },
   "source": [
    "In the classifier, unlike LM, we need to read a movie review at a time and learn to predict the it's sentiment as pos/neg. We do not deal with equal bptt size batches, so we have to pad the sequences to the same length in each batch. To create batches of similar sized movie reviews, we use a sortish sampler method invented by [@Smerity](https://twitter.com/Smerity) and [@jekbradbury](https://twitter.com/jekbradbury)\n",
    "\n",
    "The sortishSampler cuts down the overall number of padding tokens the classifier ends up seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkrx6upuaSof",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_clas = np.array(trn_df[\"numerized_tokens\"])\n",
    "val_clas = np.array(val_df[\"numerized_tokens\"])\n",
    "#test_clas = np.array(test_df[\"numerized_tokens\"])\n",
    "\n",
    "trn_labels = np.squeeze(np.array(trn_df[\"labels\"]))\n",
    "val_labels = np.squeeze(np.array(val_df[\"labels\"]))\n",
    "#test_labels = np.squeeze(np.array(test_df[\"labels\"])) # placeholder. meaningless\n",
    "\n",
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "#test_ds = TextDataset(test_clas, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([list([42, 43, 14, 18, 0, 14, 18, 18, 14, 39, 28, 142, 64, 46, 154, 60, 2, 35113, 401, 62, 28, 79, 405, 115, 28, 87, 31, 54, 3, 40, 7, 2, 193, 204, 12, 57, 405, 60, 2, 1403, 17, 20, 2, 71, 109, 4820, 5, 2925, 1100, 2066, 22, 130, 52, 6, 477, 61, 0, 4794, 19, 1164, 2128, 401, 2, 8344, 5874, 3, 62, 2, 482, 212, 7267, 55, 10196, 169, 8, 66, 811, 10, 79, 81, 41, 107, 6, 190, 63, 614, 11, 2, 259, 1089, 175, 5, 2, 228, 9, 31, 61, 1459, 61, 1554, 401, 26, 1339, 48, 69, 13, 23, 407, 59, 10, 20, 6, 109, 401, 5, 66, 7, 155, 5809, 87, 131, 245, 24, 2, 71, 109, 76, 93, 45, 6, 76, 69, 10204, 20, 11, 1050, 4, 2, 2423, 319, 20, 6907, 4, 2, 901, 2949, 20, 11, 385, 6174, 401, 5, 0, 11860, 20, 153, 11, 2772, 7, 2, 33, 2802, 3, 13, 9, 6, 27, 112, 180, 22626, 3253, 5, 22, 162, 10, 20, 40, 7, 2, 109, 8, 214, 6, 215, 24416, 45, 2, 6946, 401, 8, 116, 268, 7, 10, 5, 2, 6331, 45, 2, 189, 76, 3, 5, 1993, 4, 66, 5809, 35, 153, 367, 174, 3, 62, 28, 449, 10228, 5, 9348, 17, 16, 74, 11, 0, 401, 28, 103, 33, 134, 13, 27, 3, 21, 62, 28, 205, 8, 142, 64, 2, 1403, 17, 87, 82, 53, 401, 824, 59, 2, 8344, 5874, 401, 62, 28, 449, 2, 805, 1729, 16, 2229, 16, 52, 60, 2, 189, 344, 5, 216, 10, 20, 230, 30, 2, 961, 11, 113, 3675, 185, 45, 260, 4, 28, 103, 3576, 2, 8344, 5874, 401, 80, 2986, 74, 30, 2, 784, 26, 322, 52, 2, 2742, 7, 2, 811, 93, 2, 213, 811, 50, 87, 1618, 145, 2, 260, 11, 2018, 7, 101, 23825, 201, 222, 3, 90, 86, 100, 2677, 30, 21415, 210, 8459, 16, 581, 10, 8, 11042, 16, 4, 352, 691, 141, 4, 77, 299, 3562, 401, 685, 503, 93, 51, 826, 280, 10917, 69, 167, 7, 203, 50, 87, 12134, 25, 2, 188, 137, 19, 4201, 208, 8, 84, 6, 2220, 74, 7, 2, 882, 22, 130, 52, 280, 2128, 48, 2, 3527, 47, 2, 35631, 6613, 635, 35, 4522, 401, 0, 204, 239, 52, 35631, 16, 201, 222, 3, 5, 2, 2282, 1020, 52, 731, 27, 106, 7356, 2, 1145, 19, 421, 846, 69, 2, 6331, 1948, 2, 10112, 9, 153, 40, 7, 2, 141, 20407, 11, 5, 59, 7, 7089, 12, 38, 146, 130, 30, 27, 3, 21, 62, 28, 449, 2, 10418, 7875, 23, 4, 28, 103, 33, 134, 13, 27, 3, 5, 62, 28, 146, 3743, 156, 148, 946, 1782, 4529, 153, 242, 6, 3534, 33701, 11, 37, 762, 69, 553, 165, 8, 37, 1123, 503, 401, 13, 73, 41, 2, 424, 27, 8, 124, 3, 21, 214, 10, 24, 64, 10, 9, 401, 6, 9401, 7, 2, 236, 93, 5, 6, 7884, 143, 27, 15, 103, 366, 44, 7, 203, 50, 89, 843, 2, 1403, 17, 8, 405, 115, 20114, 3])],\n",
       "       dtype=object),\n",
       " array([list([42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, 7046, 5, 3741, 6010, 237, 86, 6, 67, 983, 787, 434, 4, 26, 11, 85, 3887, 12, 123, 28, 97, 154, 15, 46, 81, 112, 40, 27, 15, 97, 41, 22242, 24, 372, 3, 683, 5, 2, 19169, 20, 15, 40, 27, 3, 21, 10, 20, 194, 7, 6, 128, 457, 1720, 804, 52, 2828, 1135, 4, 2, 359, 27, 131, 7046, 5, 6010, 918, 1566, 23249, 3, 155, 87, 2, 81, 128, 127, 2, 878, 112, 11, 1460, 3, 21, 2, 128, 7, 115, 4, 59, 7, 179, 22, 679, 4, 214, 6, 317, 24, 6, 71, 12754, 5, 2902, 213, 612, 39950, 22, 6, 10099, 3, 283, 10, 555, 59, 25, 6010, 1690, 8, 361, 2, 541, 4, 683, 5, 2, 19169, 22, 6, 17244, 83, 4, 2, 213, 9091, 4103, 74, 914, 10, 8, 6010, 3, 3741, 765, 2406, 5, 11, 37, 1469, 36, 29720, 36, 17, 879, 683, 2, 1334, 499, 3, 21, 1759, 19654, 50, 18290, 2, 878, 11, 2566, 3946, 322, 2, 1334, 5, 36, 17, 208, 6, 1334, 3277, 3681, 1652, 22, 37, 10491, 3, 3681, 20, 6, 215, 266, 4, 50678, 16, 4, 5, 28, 79, 826, 72, 86, 66, 5919, 131, 200, 574, 69, 58, 6025, 20, 351, 22, 6, 981, 3, 40, 7, 2, 81, 1870, 50, 146, 601, 199, 45, 58, 20, 335, 1957, 11, 299, 36499, 45, 0, 16, 3, 1636, 3817, 5, 621, 1458, 11, 30, 280, 7833, 117, 105, 3471, 1192, 744, 58, 4, 26, 195, 58, 6025, 20, 194, 7, 6, 3156, 3, 21, 30421, 41528, 5, 621, 3474, 87, 2, 2732, 5, 2244, 7, 2, 1041, 5, 46, 6339, 1289, 4, 26, 97, 31, 517, 301, 256, 3, 13, 20, 2, 259, 27, 7, 1019, 50679, 50, 17, 641, 2043, 52, 2, 430, 1288, 281, 503, 5, 78, 8, 2, 492, 7, 2, 259, 1058, 30, 933, 3, 36, 278, 2732, 30421, 17, 352, 2, 720, 3, 21, 66, 34, 1980, 912, 706, 1575, 407, 52, 683, 5, 2, 19169, 4, 598, 2, 441, 620, 3, 12, 91, 405, 22, 6, 541, 285, 2, 14891, 1881, 7, 5284, 5, 3741, 1199, 2, 620, 5, 11922, 2, 83, 3, 12, 20, 11, 77, 430, 701, 28094, 175, 4, 26, 909, 6, 10868, 350, 7, 85, 17, 164, 15, 5, 85, 705, 229, 3, 21, 683, 5, 2, 19169, 9, 153, 6, 67, 434, 17, 457, 24, 2, 71, 213, 4, 176, 12, 73, 3197, 786, 8, 3197, 85, 143, 39828, 34, 8, 8484, 213, 1161, 39950, 3])],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_clas[:1], test_clas[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5Ksss7aMWgG"
   },
   "outputs": [],
   "source": [
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "#test_samp = SortSampler(test_clas, key=lambda x: len(test_clas[x]))\n",
    "\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "#test_dl = DataLoader(test_ds, bs, transpose=True, num_workers=1, pad_idx=1) # for ease of submission, don't sort out of order\n",
    "\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fK9z_asUMWgL"
   },
   "outputs": [],
   "source": [
    "# part 1\n",
    "#dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1]) # trying this one second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from imdb script. USING THESE.\n",
    "\n",
    "dropmult = 1.5\n",
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*dropmult\n",
    "\n",
    "lrm = 2.6\n",
    "lr=0.01\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])\n",
    "\n",
    "wd = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are taken from arxiv paper JH.\n",
    "\n",
    "lrs = [0.0001, 0.0001, 0.0001, 0.0001, .001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLbgEdvyMWgP"
   },
   "outputs": [],
   "source": [
    "#dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5 # trying this one first! who knows! training breaks as before. Trying above version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MlKBpEy4MWgR"
   },
   "outputs": [],
   "source": [
    "c = 2 # NUMBER OF CLASSES\n",
    "\n",
    "\n",
    "m = get_rnn_classifier(bptt, 20*bptt, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])\n",
    "\n",
    "# Was getting error here in normal pip installed version. Have to get latest from github, then pip install as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pX1MSel-MWgT"
   },
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99)) # changing down to 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHhDFY7gMWgV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wK9LjadMWgb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.load_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXoWGYoDMWge"
   },
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yd0SyD0hMWgh"
   },
   "outputs": [],
   "source": [
    "#learn.lr_find(lrs/1000)\n",
    "#learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wf6d53jFMWgi",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ef89379c1940e7893cf6151ad3390c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.615408   0.262996   0.91      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.263]), 0.9099999976158142]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem here was val loss way too small. Accuracy way to high. Bad sign. Redid w JH parameters from imdb scripts folder in \n",
    "# same repo. damn. still too high a bit!\n",
    "\n",
    "# using an even higher multiplier for dropout. 1.3 instead of 1.0. See if this gets us more in line w JH's results at this point.\n",
    "# RESULT: perhaps closer. val loss is about right, but accuracy is too high. Let's move to next cell.\n",
    "\n",
    "# 8.24 redoing w elim dups train data. drop mult of 1.2. Had to put dup back in bc of vocab sz. Just pushing though\n",
    "# even though accuracy too high\n",
    "\n",
    "# Trying we df fresh from prep, not from saved csv. Hypothesis is something breaks at that step. Loss still too low\n",
    "# Accuracy too high. Tested pred on 1000 rows, avg looked good. Now training 2 layers, try pred again: same! Problem is\n",
    "# not at the csv load stage. \n",
    "\n",
    "# Tried new prediction apparatus, same! Results still strongly skewed. Val set predicted perfectly well. Train set perfectly well\n",
    "# test set abysmal!!\n",
    "\n",
    "# Trying w drop mult of 1.5: first epoch, mean .6, second epoch, .5, third epoch unfrozen .53. Interesting, why is it hovering around .5 now?\n",
    "# Did prep and saved. Doing three epochs full unfreeze, lowered lr to match paper. Train now blows up :(\n",
    "\n",
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"clas_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6NW8SweMWgn",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a721103656495dafbdb327a3bbc934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.547673   0.178846   0.9332    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.17885]), 0.9331999968528748]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "Uxg3XdBrMWgo",
    "outputId": "de1625d2-ae27-405e-bb14-f725febe016a"
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "had3dZdLMWgv",
    "outputId": "cfa922b0-2d97-49d9-aa54-bd6de57068ea",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6452633b164d168b35538bb209011d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.513662   0.141099   0.9448    \n",
      "    1      0.517169   0.137728   0.9452                      \n",
      "    2      0.499543   0.137621   0.9448                      \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.13762]), 0.9447999915122985]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=3, use_clr=(32,10)) # JH uses 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Rj9tTcYMWgx",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using different pred apparatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchRNN(\n",
       "    (encoder): Embedding(52315, 400, padding_idx=1)\n",
       "    (encoder_with_dropout): EmbeddingDropout(\n",
       "      (embed): Embedding(52315, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDrop(\n",
       "        (module): LSTM(400, 1150)\n",
       "      )\n",
       "      (1): WeightDrop(\n",
       "        (module): LSTM(1150, 1150)\n",
       "      )\n",
       "      (2): WeightDrop(\n",
       "        (module): LSTM(1150, 400)\n",
       "      )\n",
       "    )\n",
       "    (dropouti): LockedDropout(\n",
       "    )\n",
       "    (dropouths): ModuleList(\n",
       "      (0): LockedDropout(\n",
       "      )\n",
       "      (1): LockedDropout(\n",
       "      )\n",
       "      (2): LockedDropout(\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): ModuleList(\n",
       "      (0): LinearBlock(\n",
       "        (lin): Linear(in_features=1200, out_features=50, bias=True)\n",
       "        (drop): Dropout(p=0.6000000000000001)\n",
       "        (bn): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "      (1): LinearBlock(\n",
       "        (lin): Linear(in_features=50, out_features=2, bias=True)\n",
       "        (drop): Dropout(p=0.1)\n",
       "        (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = learn.model\n",
    "model.reset()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.reset()\n",
    "model.eval()\n",
    "\n",
    "probs = []\n",
    "LEN = len(test_clas)\n",
    "\n",
    "for i in range(LEN):\n",
    "    test_txt = test_clas[i]; #print(test_df.text.iloc[i])\n",
    "\n",
    "    ary = np.reshape(np.array(test_txt),(-1,1))\n",
    "\n",
    "    # turn this array into a tensor\n",
    "    tensor = torch.LongTensor(ary)\n",
    "\n",
    "    # wrap in a torch Variable\n",
    "    variable = Variable(tensor).cuda()\n",
    "\n",
    "    # do the predictions\n",
    "    predictions = model(variable)\n",
    "\n",
    "    # convert back to numpy\n",
    "    numpy_preds = predictions[0].data.cpu().numpy()\n",
    "\n",
    "    prob = softmax(numpy_preds[0])[0]; \n",
    "    \n",
    "    probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>numerized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>98481</td>\n",
       "      <td>0.861524</td>\n",
       "      <td>Bud Abbott and Lou Costello always had a good ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '98481', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25001</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>88606</td>\n",
       "      <td>0.856081</td>\n",
       "      <td>This film is not your typical Hollywood fare, ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88606', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25002</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>88639</td>\n",
       "      <td>0.908245</td>\n",
       "      <td>Henry Thomas, and Robin Tunny, are a couple of...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88639', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1636, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>76170</td>\n",
       "      <td>0.066361</td>\n",
       "      <td>This digital horror film brings us into the Mi...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '76170', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25004</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>81803</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>I just saw this on a local independent station...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '81803', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25005</th>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "      <td>93371</td>\n",
       "      <td>0.999545</td>\n",
       "      <td>Those wishing to see film noir remakes, should...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '93371', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 167, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25006</th>\n",
       "      <td>6</td>\n",
       "      <td>test</td>\n",
       "      <td>87360</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>I never read the book. Now I don't really want...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '87360', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25007</th>\n",
       "      <td>7</td>\n",
       "      <td>test</td>\n",
       "      <td>88547</td>\n",
       "      <td>0.732679</td>\n",
       "      <td>I think that there was too much action in the ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88547', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25008</th>\n",
       "      <td>8</td>\n",
       "      <td>test</td>\n",
       "      <td>88215</td>\n",
       "      <td>0.936093</td>\n",
       "      <td>Have wanted to see this for a while: I never t...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88215', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 38, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25009</th>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>96187</td>\n",
       "      <td>0.974977</td>\n",
       "      <td>This is an interesting, hard to find movie fro...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '96187', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "      <td>81251</td>\n",
       "      <td>0.038988</td>\n",
       "      <td>Well, the Hero and the Terror is slightly belo...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '81251', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 91, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>98086</td>\n",
       "      <td>0.999673</td>\n",
       "      <td>I have been an avid chipmunk fan since the lat...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '98086', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>12</td>\n",
       "      <td>test</td>\n",
       "      <td>79688</td>\n",
       "      <td>0.016312</td>\n",
       "      <td>42/100. Often referred as \"Tarzan with clothes...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '79688', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12066,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25013</th>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>90580</td>\n",
       "      <td>0.938153</td>\n",
       "      <td>I caught this movie late one night and never k...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '90580', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25014</th>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>86756</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>Tyrone Power was cast in the lead as Solomon. ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '86756', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12081,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25015</th>\n",
       "      <td>15</td>\n",
       "      <td>test</td>\n",
       "      <td>77906</td>\n",
       "      <td>0.010963</td>\n",
       "      <td>This is one of those religious horror films wh...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '77906', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25016</th>\n",
       "      <td>16</td>\n",
       "      <td>test</td>\n",
       "      <td>95742</td>\n",
       "      <td>0.984693</td>\n",
       "      <td>Being advertised as the most expensive movie e...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '95742', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 131, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25017</th>\n",
       "      <td>17</td>\n",
       "      <td>test</td>\n",
       "      <td>77455</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>The Jaws rip off is the trashiest of the all t...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '77455', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25018</th>\n",
       "      <td>18</td>\n",
       "      <td>test</td>\n",
       "      <td>76454</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>After seeing this film I felt sick to my stoma...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '76454', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25019</th>\n",
       "      <td>19</td>\n",
       "      <td>test</td>\n",
       "      <td>92650</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>I first saw this mini-series as a child and th...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '92650', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25020</th>\n",
       "      <td>20</td>\n",
       "      <td>test</td>\n",
       "      <td>98042</td>\n",
       "      <td>0.998681</td>\n",
       "      <td>The beautiful, charming, supremely versatile a...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '98042', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25021</th>\n",
       "      <td>21</td>\n",
       "      <td>test</td>\n",
       "      <td>81107</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>Everyone I know loves this movie, but I am afr...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '81107', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 316, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25022</th>\n",
       "      <td>22</td>\n",
       "      <td>test</td>\n",
       "      <td>83839</td>\n",
       "      <td>0.747667</td>\n",
       "      <td>CORRIDORS OF BLOOD &lt;br /&gt;&lt;br /&gt;Aspect ratio: 1...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '83839', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 33, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25023</th>\n",
       "      <td>23</td>\n",
       "      <td>test</td>\n",
       "      <td>87324</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>If this movie had been directed by a man, he w...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '87324', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 62, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25024</th>\n",
       "      <td>24</td>\n",
       "      <td>test</td>\n",
       "      <td>84526</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>I like Kevin Bacon and Cathy Moriarty, and I l...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '84526', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25025</th>\n",
       "      <td>25</td>\n",
       "      <td>test</td>\n",
       "      <td>93868</td>\n",
       "      <td>0.985835</td>\n",
       "      <td>Passion In The Desert exemplifies spatial gran...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '93868', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1649, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25026</th>\n",
       "      <td>26</td>\n",
       "      <td>test</td>\n",
       "      <td>88605</td>\n",
       "      <td>0.991546</td>\n",
       "      <td>I would recommend this film to anyone who is s...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88605', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25027</th>\n",
       "      <td>27</td>\n",
       "      <td>test</td>\n",
       "      <td>84436</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>No budget direct to video tale of aliens in Ar...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '84436', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25028</th>\n",
       "      <td>28</td>\n",
       "      <td>test</td>\n",
       "      <td>91698</td>\n",
       "      <td>0.757044</td>\n",
       "      <td>Film about the failure of government and the s...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '91698', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 27, 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25029</th>\n",
       "      <td>29</td>\n",
       "      <td>test</td>\n",
       "      <td>82413</td>\n",
       "      <td>0.037486</td>\n",
       "      <td>I bought this movie for a couple of dollars at...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '82413', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25470</th>\n",
       "      <td>470</td>\n",
       "      <td>test</td>\n",
       "      <td>76042</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>You may not believe this, but when the credits...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '76042', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 28, 22...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>471</td>\n",
       "      <td>test</td>\n",
       "      <td>75985</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>This movie has to rank with \"Welcome to the Ju...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '75985', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25472</th>\n",
       "      <td>472</td>\n",
       "      <td>test</td>\n",
       "      <td>79137</td>\n",
       "      <td>0.028353</td>\n",
       "      <td>No, *Hitch* is decidedly NOT a romantic-comedy...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '79137', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>473</td>\n",
       "      <td>test</td>\n",
       "      <td>88508</td>\n",
       "      <td>0.980741</td>\n",
       "      <td>The first, and far better, of Kevin Kline's tw...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88508', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25474</th>\n",
       "      <td>474</td>\n",
       "      <td>test</td>\n",
       "      <td>85297</td>\n",
       "      <td>0.085712</td>\n",
       "      <td>Thomas Hardy is one of my favorite authors. So...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '85297', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1661, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>475</td>\n",
       "      <td>test</td>\n",
       "      <td>75767</td>\n",
       "      <td>0.011432</td>\n",
       "      <td>never before have i seen such a tale of such t...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '75767', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 133, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25476</th>\n",
       "      <td>476</td>\n",
       "      <td>test</td>\n",
       "      <td>96277</td>\n",
       "      <td>0.986423</td>\n",
       "      <td>I really enjoyed this Minghella epic, thought ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '96277', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25477</th>\n",
       "      <td>477</td>\n",
       "      <td>test</td>\n",
       "      <td>91122</td>\n",
       "      <td>0.957721</td>\n",
       "      <td>I had long wanted to watch this romantic drama...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '91122', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25478</th>\n",
       "      <td>478</td>\n",
       "      <td>test</td>\n",
       "      <td>91143</td>\n",
       "      <td>0.666835</td>\n",
       "      <td>What to say about a movie like Rock Star? A lo...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '91143', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 64, 8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25479</th>\n",
       "      <td>479</td>\n",
       "      <td>test</td>\n",
       "      <td>76134</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>After seeing the TV commercials for this film ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '76134', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25480</th>\n",
       "      <td>480</td>\n",
       "      <td>test</td>\n",
       "      <td>98870</td>\n",
       "      <td>0.999570</td>\n",
       "      <td>Peter Lorre turns in one of his finest perform...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '98870', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 813, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25481</th>\n",
       "      <td>481</td>\n",
       "      <td>test</td>\n",
       "      <td>85397</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>No spoiler needed to steer you clear of this.....</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '85397', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>482</td>\n",
       "      <td>test</td>\n",
       "      <td>92781</td>\n",
       "      <td>0.982929</td>\n",
       "      <td>Sacha Baron Cohen is a genius. And this movie ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '92781', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 22145,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25483</th>\n",
       "      <td>483</td>\n",
       "      <td>test</td>\n",
       "      <td>83306</td>\n",
       "      <td>0.075484</td>\n",
       "      <td>This is a new approach to comedy. It isn't fun...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '83306', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25484</th>\n",
       "      <td>484</td>\n",
       "      <td>test</td>\n",
       "      <td>80803</td>\n",
       "      <td>0.115318</td>\n",
       "      <td>...in a TV-movie 70's kind of way. It's one of...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '80803', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 93, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25485</th>\n",
       "      <td>485</td>\n",
       "      <td>test</td>\n",
       "      <td>91386</td>\n",
       "      <td>0.673554</td>\n",
       "      <td>Before you watch this movie - clean your ears,...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '91386', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 180, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25486</th>\n",
       "      <td>486</td>\n",
       "      <td>test</td>\n",
       "      <td>99850</td>\n",
       "      <td>0.999509</td>\n",
       "      <td>I personally LOVE this film amidst the Hallowe...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '99850', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25487</th>\n",
       "      <td>487</td>\n",
       "      <td>test</td>\n",
       "      <td>89095</td>\n",
       "      <td>0.967033</td>\n",
       "      <td>This is a wonderful new movie currently still ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '89095', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25488</th>\n",
       "      <td>488</td>\n",
       "      <td>test</td>\n",
       "      <td>80272</td>\n",
       "      <td>0.187558</td>\n",
       "      <td>Through its 2-hour running length, Crash chart...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '80272', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 164, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25489</th>\n",
       "      <td>489</td>\n",
       "      <td>test</td>\n",
       "      <td>84021</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>There really is very little positive that can ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '84021', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 54, 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25490</th>\n",
       "      <td>490</td>\n",
       "      <td>test</td>\n",
       "      <td>96836</td>\n",
       "      <td>0.977947</td>\n",
       "      <td>It's always a pleasure to see characters in a ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '96836', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 10, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25491</th>\n",
       "      <td>491</td>\n",
       "      <td>test</td>\n",
       "      <td>91120</td>\n",
       "      <td>0.999296</td>\n",
       "      <td>This young filmmaker has a talent for capturin...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '91120', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25492</th>\n",
       "      <td>492</td>\n",
       "      <td>test</td>\n",
       "      <td>90712</td>\n",
       "      <td>0.997958</td>\n",
       "      <td>This was truly a tense and dark episode. Excel...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '90712', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25493</th>\n",
       "      <td>493</td>\n",
       "      <td>test</td>\n",
       "      <td>85722</td>\n",
       "      <td>0.030087</td>\n",
       "      <td>I really wanted to like this film, especially ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '85722', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25494</th>\n",
       "      <td>494</td>\n",
       "      <td>test</td>\n",
       "      <td>98654</td>\n",
       "      <td>0.986472</td>\n",
       "      <td>Hitchcock made at least 11 films about the ord...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '98654', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1465, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25495</th>\n",
       "      <td>495</td>\n",
       "      <td>test</td>\n",
       "      <td>86034</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;Very dull, laborious adaptation of...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '86034', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 21, 71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25496</th>\n",
       "      <td>496</td>\n",
       "      <td>test</td>\n",
       "      <td>95350</td>\n",
       "      <td>0.996393</td>\n",
       "      <td>real love. true love. mad love. beautiful love...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '95350', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 166, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25497</th>\n",
       "      <td>497</td>\n",
       "      <td>test</td>\n",
       "      <td>88584</td>\n",
       "      <td>0.971911</td>\n",
       "      <td>Its a feel-good movie that made me feel good. ...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '88584', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 113, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>498</td>\n",
       "      <td>test</td>\n",
       "      <td>82217</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>Christopher Lambert attracted me to this movie...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '82217', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1472, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25499</th>\n",
       "      <td>499</td>\n",
       "      <td>test</td>\n",
       "      <td>92141</td>\n",
       "      <td>0.509379</td>\n",
       "      <td>La Petit Tourette is a pretty funny South Park...</td>\n",
       "      <td>['\\n', 'xbos', 'xfld', '1', '92141', 'xfld', '...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1110, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 dataset     id    labels  \\\n",
       "25000           0    test  98481  0.861524   \n",
       "25001           1    test  88606  0.856081   \n",
       "25002           2    test  88639  0.908245   \n",
       "25003           3    test  76170  0.066361   \n",
       "25004           4    test  81803  0.007510   \n",
       "25005           5    test  93371  0.999545   \n",
       "25006           6    test  87360  0.002328   \n",
       "25007           7    test  88547  0.732679   \n",
       "25008           8    test  88215  0.936093   \n",
       "25009           9    test  96187  0.974977   \n",
       "25010          10    test  81251  0.038988   \n",
       "25011          11    test  98086  0.999673   \n",
       "25012          12    test  79688  0.016312   \n",
       "25013          13    test  90580  0.938153   \n",
       "25014          14    test  86756  0.002146   \n",
       "25015          15    test  77906  0.010963   \n",
       "25016          16    test  95742  0.984693   \n",
       "25017          17    test  77455  0.001599   \n",
       "25018          18    test  76454  0.002289   \n",
       "25019          19    test  92650  0.999220   \n",
       "25020          20    test  98042  0.998681   \n",
       "25021          21    test  81107  0.005361   \n",
       "25022          22    test  83839  0.747667   \n",
       "25023          23    test  87324  0.005912   \n",
       "25024          24    test  84526  0.002335   \n",
       "25025          25    test  93868  0.985835   \n",
       "25026          26    test  88605  0.991546   \n",
       "25027          27    test  84436  0.001227   \n",
       "25028          28    test  91698  0.757044   \n",
       "25029          29    test  82413  0.037486   \n",
       "...           ...     ...    ...       ...   \n",
       "25470         470    test  76042  0.001042   \n",
       "25471         471    test  75985  0.003930   \n",
       "25472         472    test  79137  0.028353   \n",
       "25473         473    test  88508  0.980741   \n",
       "25474         474    test  85297  0.085712   \n",
       "25475         475    test  75767  0.011432   \n",
       "25476         476    test  96277  0.986423   \n",
       "25477         477    test  91122  0.957721   \n",
       "25478         478    test  91143  0.666835   \n",
       "25479         479    test  76134  0.009788   \n",
       "25480         480    test  98870  0.999570   \n",
       "25481         481    test  85397  0.003792   \n",
       "25482         482    test  92781  0.982929   \n",
       "25483         483    test  83306  0.075484   \n",
       "25484         484    test  80803  0.115318   \n",
       "25485         485    test  91386  0.673554   \n",
       "25486         486    test  99850  0.999509   \n",
       "25487         487    test  89095  0.967033   \n",
       "25488         488    test  80272  0.187558   \n",
       "25489         489    test  84021  0.005871   \n",
       "25490         490    test  96836  0.977947   \n",
       "25491         491    test  91120  0.999296   \n",
       "25492         492    test  90712  0.997958   \n",
       "25493         493    test  85722  0.030087   \n",
       "25494         494    test  98654  0.986472   \n",
       "25495         495    test  86034  0.013636   \n",
       "25496         496    test  95350  0.996393   \n",
       "25497         497    test  88584  0.971911   \n",
       "25498         498    test  82217  0.011830   \n",
       "25499         499    test  92141  0.509379   \n",
       "\n",
       "                                                    text  \\\n",
       "25000  Bud Abbott and Lou Costello always had a good ...   \n",
       "25001  This film is not your typical Hollywood fare, ...   \n",
       "25002  Henry Thomas, and Robin Tunny, are a couple of...   \n",
       "25003  This digital horror film brings us into the Mi...   \n",
       "25004  I just saw this on a local independent station...   \n",
       "25005  Those wishing to see film noir remakes, should...   \n",
       "25006  I never read the book. Now I don't really want...   \n",
       "25007  I think that there was too much action in the ...   \n",
       "25008  Have wanted to see this for a while: I never t...   \n",
       "25009  This is an interesting, hard to find movie fro...   \n",
       "25010  Well, the Hero and the Terror is slightly belo...   \n",
       "25011  I have been an avid chipmunk fan since the lat...   \n",
       "25012  42/100. Often referred as \"Tarzan with clothes...   \n",
       "25013  I caught this movie late one night and never k...   \n",
       "25014  Tyrone Power was cast in the lead as Solomon. ...   \n",
       "25015  This is one of those religious horror films wh...   \n",
       "25016  Being advertised as the most expensive movie e...   \n",
       "25017  The Jaws rip off is the trashiest of the all t...   \n",
       "25018  After seeing this film I felt sick to my stoma...   \n",
       "25019  I first saw this mini-series as a child and th...   \n",
       "25020  The beautiful, charming, supremely versatile a...   \n",
       "25021  Everyone I know loves this movie, but I am afr...   \n",
       "25022  CORRIDORS OF BLOOD <br /><br />Aspect ratio: 1...   \n",
       "25023  If this movie had been directed by a man, he w...   \n",
       "25024  I like Kevin Bacon and Cathy Moriarty, and I l...   \n",
       "25025  Passion In The Desert exemplifies spatial gran...   \n",
       "25026  I would recommend this film to anyone who is s...   \n",
       "25027  No budget direct to video tale of aliens in Ar...   \n",
       "25028  Film about the failure of government and the s...   \n",
       "25029  I bought this movie for a couple of dollars at...   \n",
       "...                                                  ...   \n",
       "25470  You may not believe this, but when the credits...   \n",
       "25471  This movie has to rank with \"Welcome to the Ju...   \n",
       "25472  No, *Hitch* is decidedly NOT a romantic-comedy...   \n",
       "25473  The first, and far better, of Kevin Kline's tw...   \n",
       "25474  Thomas Hardy is one of my favorite authors. So...   \n",
       "25475  never before have i seen such a tale of such t...   \n",
       "25476  I really enjoyed this Minghella epic, thought ...   \n",
       "25477  I had long wanted to watch this romantic drama...   \n",
       "25478  What to say about a movie like Rock Star? A lo...   \n",
       "25479  After seeing the TV commercials for this film ...   \n",
       "25480  Peter Lorre turns in one of his finest perform...   \n",
       "25481  No spoiler needed to steer you clear of this.....   \n",
       "25482  Sacha Baron Cohen is a genius. And this movie ...   \n",
       "25483  This is a new approach to comedy. It isn't fun...   \n",
       "25484  ...in a TV-movie 70's kind of way. It's one of...   \n",
       "25485  Before you watch this movie - clean your ears,...   \n",
       "25486  I personally LOVE this film amidst the Hallowe...   \n",
       "25487  This is a wonderful new movie currently still ...   \n",
       "25488  Through its 2-hour running length, Crash chart...   \n",
       "25489  There really is very little positive that can ...   \n",
       "25490  It's always a pleasure to see characters in a ...   \n",
       "25491  This young filmmaker has a talent for capturin...   \n",
       "25492  This was truly a tense and dark episode. Excel...   \n",
       "25493  I really wanted to like this film, especially ...   \n",
       "25494  Hitchcock made at least 11 films about the ord...   \n",
       "25495  <br /><br />Very dull, laborious adaptation of...   \n",
       "25496  real love. true love. mad love. beautiful love...   \n",
       "25497  Its a feel-good movie that made me feel good. ...   \n",
       "25498  Christopher Lambert attracted me to this movie...   \n",
       "25499  La Petit Tourette is a pretty funny South Park...   \n",
       "\n",
       "                                          tokenized_text  \\\n",
       "25000  ['\\n', 'xbos', 'xfld', '1', '98481', 'xfld', '...   \n",
       "25001  ['\\n', 'xbos', 'xfld', '1', '88606', 'xfld', '...   \n",
       "25002  ['\\n', 'xbos', 'xfld', '1', '88639', 'xfld', '...   \n",
       "25003  ['\\n', 'xbos', 'xfld', '1', '76170', 'xfld', '...   \n",
       "25004  ['\\n', 'xbos', 'xfld', '1', '81803', 'xfld', '...   \n",
       "25005  ['\\n', 'xbos', 'xfld', '1', '93371', 'xfld', '...   \n",
       "25006  ['\\n', 'xbos', 'xfld', '1', '87360', 'xfld', '...   \n",
       "25007  ['\\n', 'xbos', 'xfld', '1', '88547', 'xfld', '...   \n",
       "25008  ['\\n', 'xbos', 'xfld', '1', '88215', 'xfld', '...   \n",
       "25009  ['\\n', 'xbos', 'xfld', '1', '96187', 'xfld', '...   \n",
       "25010  ['\\n', 'xbos', 'xfld', '1', '81251', 'xfld', '...   \n",
       "25011  ['\\n', 'xbos', 'xfld', '1', '98086', 'xfld', '...   \n",
       "25012  ['\\n', 'xbos', 'xfld', '1', '79688', 'xfld', '...   \n",
       "25013  ['\\n', 'xbos', 'xfld', '1', '90580', 'xfld', '...   \n",
       "25014  ['\\n', 'xbos', 'xfld', '1', '86756', 'xfld', '...   \n",
       "25015  ['\\n', 'xbos', 'xfld', '1', '77906', 'xfld', '...   \n",
       "25016  ['\\n', 'xbos', 'xfld', '1', '95742', 'xfld', '...   \n",
       "25017  ['\\n', 'xbos', 'xfld', '1', '77455', 'xfld', '...   \n",
       "25018  ['\\n', 'xbos', 'xfld', '1', '76454', 'xfld', '...   \n",
       "25019  ['\\n', 'xbos', 'xfld', '1', '92650', 'xfld', '...   \n",
       "25020  ['\\n', 'xbos', 'xfld', '1', '98042', 'xfld', '...   \n",
       "25021  ['\\n', 'xbos', 'xfld', '1', '81107', 'xfld', '...   \n",
       "25022  ['\\n', 'xbos', 'xfld', '1', '83839', 'xfld', '...   \n",
       "25023  ['\\n', 'xbos', 'xfld', '1', '87324', 'xfld', '...   \n",
       "25024  ['\\n', 'xbos', 'xfld', '1', '84526', 'xfld', '...   \n",
       "25025  ['\\n', 'xbos', 'xfld', '1', '93868', 'xfld', '...   \n",
       "25026  ['\\n', 'xbos', 'xfld', '1', '88605', 'xfld', '...   \n",
       "25027  ['\\n', 'xbos', 'xfld', '1', '84436', 'xfld', '...   \n",
       "25028  ['\\n', 'xbos', 'xfld', '1', '91698', 'xfld', '...   \n",
       "25029  ['\\n', 'xbos', 'xfld', '1', '82413', 'xfld', '...   \n",
       "...                                                  ...   \n",
       "25470  ['\\n', 'xbos', 'xfld', '1', '76042', 'xfld', '...   \n",
       "25471  ['\\n', 'xbos', 'xfld', '1', '75985', 'xfld', '...   \n",
       "25472  ['\\n', 'xbos', 'xfld', '1', '79137', 'xfld', '...   \n",
       "25473  ['\\n', 'xbos', 'xfld', '1', '88508', 'xfld', '...   \n",
       "25474  ['\\n', 'xbos', 'xfld', '1', '85297', 'xfld', '...   \n",
       "25475  ['\\n', 'xbos', 'xfld', '1', '75767', 'xfld', '...   \n",
       "25476  ['\\n', 'xbos', 'xfld', '1', '96277', 'xfld', '...   \n",
       "25477  ['\\n', 'xbos', 'xfld', '1', '91122', 'xfld', '...   \n",
       "25478  ['\\n', 'xbos', 'xfld', '1', '91143', 'xfld', '...   \n",
       "25479  ['\\n', 'xbos', 'xfld', '1', '76134', 'xfld', '...   \n",
       "25480  ['\\n', 'xbos', 'xfld', '1', '98870', 'xfld', '...   \n",
       "25481  ['\\n', 'xbos', 'xfld', '1', '85397', 'xfld', '...   \n",
       "25482  ['\\n', 'xbos', 'xfld', '1', '92781', 'xfld', '...   \n",
       "25483  ['\\n', 'xbos', 'xfld', '1', '83306', 'xfld', '...   \n",
       "25484  ['\\n', 'xbos', 'xfld', '1', '80803', 'xfld', '...   \n",
       "25485  ['\\n', 'xbos', 'xfld', '1', '91386', 'xfld', '...   \n",
       "25486  ['\\n', 'xbos', 'xfld', '1', '99850', 'xfld', '...   \n",
       "25487  ['\\n', 'xbos', 'xfld', '1', '89095', 'xfld', '...   \n",
       "25488  ['\\n', 'xbos', 'xfld', '1', '80272', 'xfld', '...   \n",
       "25489  ['\\n', 'xbos', 'xfld', '1', '84021', 'xfld', '...   \n",
       "25490  ['\\n', 'xbos', 'xfld', '1', '96836', 'xfld', '...   \n",
       "25491  ['\\n', 'xbos', 'xfld', '1', '91120', 'xfld', '...   \n",
       "25492  ['\\n', 'xbos', 'xfld', '1', '90712', 'xfld', '...   \n",
       "25493  ['\\n', 'xbos', 'xfld', '1', '85722', 'xfld', '...   \n",
       "25494  ['\\n', 'xbos', 'xfld', '1', '98654', 'xfld', '...   \n",
       "25495  ['\\n', 'xbos', 'xfld', '1', '86034', 'xfld', '...   \n",
       "25496  ['\\n', 'xbos', 'xfld', '1', '95350', 'xfld', '...   \n",
       "25497  ['\\n', 'xbos', 'xfld', '1', '88584', 'xfld', '...   \n",
       "25498  ['\\n', 'xbos', 'xfld', '1', '82217', 'xfld', '...   \n",
       "25499  ['\\n', 'xbos', 'xfld', '1', '92141', 'xfld', '...   \n",
       "\n",
       "                                        numerized_tokens  \n",
       "25000  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, ...  \n",
       "25001  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 27...  \n",
       "25002  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1636, ...  \n",
       "25003  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 36...  \n",
       "25004  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 56...  \n",
       "25005  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 167, 4...  \n",
       "25006  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 13...  \n",
       "25007  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...  \n",
       "25008  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 38, 48...  \n",
       "25009  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "25010  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 91, 4,...  \n",
       "25011  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 38...  \n",
       "25012  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12066,...  \n",
       "25013  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...  \n",
       "25014  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12081,...  \n",
       "25015  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "25016  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 131, 6...  \n",
       "25017  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 454...  \n",
       "25018  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 3...  \n",
       "25019  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...  \n",
       "25020  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 333...  \n",
       "25021  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 316, 1...  \n",
       "25022  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 33, 92...  \n",
       "25023  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 62, 13...  \n",
       "25024  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 53...  \n",
       "25025  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1649, ...  \n",
       "25026  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 73...  \n",
       "25027  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 35...  \n",
       "25028  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 27, 60...  \n",
       "25029  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...  \n",
       "...                                                  ...  \n",
       "25470  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 28, 22...  \n",
       "25471  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...  \n",
       "25472  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 4,...  \n",
       "25473  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 109...  \n",
       "25474  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1661, ...  \n",
       "25475  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 133, 1...  \n",
       "25476  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 82...  \n",
       "25477  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 86...  \n",
       "25478  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 64, 8,...  \n",
       "25479  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 3...  \n",
       "25480  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 813, 7...  \n",
       "25481  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 13...  \n",
       "25482  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 22145,...  \n",
       "25483  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "25484  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 93, 11...  \n",
       "25485  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 180, 2...  \n",
       "25486  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...  \n",
       "25487  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "25488  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 164, 1...  \n",
       "25489  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 54, 82...  \n",
       "25490  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 10, 17...  \n",
       "25491  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 21...  \n",
       "25492  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 20...  \n",
       "25493  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 82...  \n",
       "25494  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1465, ...  \n",
       "25495  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 21, 71...  \n",
       "25496  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 166, 1...  \n",
       "25497  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 113, 6...  \n",
       "25498  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1472, ...  \n",
       "25499  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1110, ...  \n",
       "\n",
       "[500 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"labels\"] = np.array(probs)[:,1]\n",
    "test_df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46773288"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.labels.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[\"id\", \"labels\"]].to_csv(\"submission_8.25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Numpy Softmax, via comments on https://gist.github.com/stober/1946926\n",
    "    >>> res = softmax(np.array([0, 200, 10]))\n",
    "    >>> np.sum(res)\n",
    "    1.0\n",
    "    >>> np.all(np.abs(res - np.array([0, 1, 0])) < 0.0001)\n",
    "    True\n",
    "    >>> res = softmax(np.array([[0, 200, 10], [0, 10, 200], [200, 0, 10]]))\n",
    "    >>> np.sum(res, axis=1)\n",
    "    array([ 1.,  1.,  1.])\n",
    "    >>> res = softmax(np.array([[0, 200, 10], [0, 10, 200]]))\n",
    "    >>> np.sum(res, axis=1)\n",
    "    array([ 1.,  1.])\n",
    "    '''\n",
    "    if x.ndim == 1:\n",
    "        x = x.reshape((1, -1))\n",
    "    max_x = np.max(x, axis=1).reshape((-1, 1))\n",
    "    exp_x = np.exp(x - max_x)\n",
    "    return exp_x / np.sum(exp_x, axis=1).reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = 500#len(test_clas)\n",
    "\n",
    "test_ds = TextDataset(test_clas[:MAX], test_labels[:MAX])\n",
    "\n",
    "test_dl = DataLoader(test_ds, bs, transpose=True, num_workers=1, pad_idx=1) # for ease of submission, don't sort out of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting val_dl to verify that it works\n",
    "learn.data.test_dl = test_dl\n",
    "log_preds_test = learn.predict(is_test=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting probs from logprobs\n",
    "#probs_test = F.softmax(V(torch.Tensor(log_preds_test)));\n",
    "probs_test = softmax(log_preds_test); # trying this custom softmax. SAME RESULT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.93232, 0.06768],\n",
       "       [0.98529, 0.01471],\n",
       "       [0.98943, 0.01057],\n",
       "       [0.99674, 0.00326],\n",
       "       [0.99803, 0.00197],\n",
       "       [0.95644, 0.04356],\n",
       "       [0.99805, 0.00195],\n",
       "       [0.98405, 0.01595],\n",
       "       [0.95762, 0.04238],\n",
       "       [0.58386, 0.41614],\n",
       "       [0.99652, 0.00348],\n",
       "       [0.95782, 0.04218],\n",
       "       [0.9977 , 0.0023 ],\n",
       "       [0.99088, 0.00912],\n",
       "       [0.9978 , 0.0022 ],\n",
       "       [0.99455, 0.00545],\n",
       "       [0.93929, 0.06071],\n",
       "       [0.99871, 0.00129],\n",
       "       [0.99864, 0.00136],\n",
       "       [0.96728, 0.03272],\n",
       "       [0.03287, 0.96713],\n",
       "       [0.99671, 0.00329],\n",
       "       [0.90676, 0.09324],\n",
       "       [0.9977 , 0.0023 ],\n",
       "       [0.99843, 0.00157],\n",
       "       [0.9232 , 0.0768 ],\n",
       "       [0.97885, 0.02115],\n",
       "       [0.9984 , 0.0016 ],\n",
       "       [0.9834 , 0.0166 ],\n",
       "       [0.99543, 0.00457],\n",
       "       [0.97133, 0.02867],\n",
       "       [0.94973, 0.05027],\n",
       "       [0.97322, 0.02678],\n",
       "       [0.99739, 0.00261],\n",
       "       [0.98691, 0.01309],\n",
       "       [0.99433, 0.00567],\n",
       "       [0.99835, 0.00165],\n",
       "       [0.97764, 0.02236],\n",
       "       [0.99479, 0.00521],\n",
       "       [0.97166, 0.02834],\n",
       "       [0.98794, 0.01206],\n",
       "       [0.9805 , 0.0195 ],\n",
       "       [0.96809, 0.03191],\n",
       "       [0.93616, 0.06384],\n",
       "       [0.98954, 0.01046],\n",
       "       [0.92061, 0.07939],\n",
       "       [0.96299, 0.03701],\n",
       "       [0.98456, 0.01544],\n",
       "       [0.99623, 0.00377],\n",
       "       [0.99667, 0.00333],\n",
       "       [0.98128, 0.01872],\n",
       "       [0.98192, 0.01808],\n",
       "       [0.99297, 0.00703],\n",
       "       [0.96827, 0.03173],\n",
       "       [0.99138, 0.00862],\n",
       "       [0.98447, 0.01553],\n",
       "       [0.9785 , 0.0215 ],\n",
       "       [0.98854, 0.01146],\n",
       "       [0.99796, 0.00204],\n",
       "       [0.92562, 0.07438],\n",
       "       [0.997  , 0.003  ],\n",
       "       [0.99749, 0.00251],\n",
       "       [0.99634, 0.00366],\n",
       "       [0.93828, 0.06172],\n",
       "       [0.97238, 0.02762],\n",
       "       [0.98139, 0.01861],\n",
       "       [0.99288, 0.00712],\n",
       "       [0.95825, 0.04175],\n",
       "       [0.96616, 0.03384],\n",
       "       [0.9544 , 0.0456 ],\n",
       "       [0.9914 , 0.0086 ],\n",
       "       [0.89696, 0.10304],\n",
       "       [0.94898, 0.05102],\n",
       "       [0.98097, 0.01903],\n",
       "       [0.85556, 0.14444],\n",
       "       [0.99751, 0.00249],\n",
       "       [0.99906, 0.00094],\n",
       "       [0.99892, 0.00108],\n",
       "       [0.99798, 0.00202],\n",
       "       [0.9054 , 0.0946 ],\n",
       "       [0.99454, 0.00546],\n",
       "       [0.84898, 0.15102],\n",
       "       [0.99352, 0.00648],\n",
       "       [0.99911, 0.00089],\n",
       "       [0.97881, 0.02119],\n",
       "       [0.99749, 0.00251],\n",
       "       [0.88257, 0.11743],\n",
       "       [0.99644, 0.00356],\n",
       "       [0.97763, 0.02237],\n",
       "       [0.9986 , 0.0014 ],\n",
       "       [0.95833, 0.04167],\n",
       "       [0.99594, 0.00406],\n",
       "       [0.99478, 0.00522],\n",
       "       [0.99859, 0.00141],\n",
       "       [0.87071, 0.12929],\n",
       "       [0.99646, 0.00354],\n",
       "       [0.82001, 0.17999],\n",
       "       [0.99536, 0.00464],\n",
       "       [0.99787, 0.00213],\n",
       "       [0.99164, 0.00836],\n",
       "       [0.98023, 0.01977],\n",
       "       [0.99467, 0.00533],\n",
       "       [0.99461, 0.00539],\n",
       "       [0.99558, 0.00442],\n",
       "       [0.99488, 0.00512],\n",
       "       [0.79476, 0.20524],\n",
       "       [0.9816 , 0.0184 ],\n",
       "       [0.99821, 0.00179],\n",
       "       [0.99624, 0.00376],\n",
       "       [0.99825, 0.00175],\n",
       "       [0.99813, 0.00187],\n",
       "       [0.88331, 0.11669],\n",
       "       [0.98875, 0.01125],\n",
       "       [0.99272, 0.00728],\n",
       "       [0.98769, 0.01231],\n",
       "       [0.99851, 0.00149],\n",
       "       [0.99031, 0.00969],\n",
       "       [0.99459, 0.00541],\n",
       "       [0.98418, 0.01582],\n",
       "       [0.99882, 0.00118],\n",
       "       [0.9126 , 0.0874 ],\n",
       "       [0.93526, 0.06474],\n",
       "       [0.98862, 0.01138],\n",
       "       [0.97938, 0.02062],\n",
       "       [0.9797 , 0.0203 ],\n",
       "       [0.99834, 0.00166],\n",
       "       [0.99837, 0.00163],\n",
       "       [0.92294, 0.07706],\n",
       "       [0.99599, 0.00401],\n",
       "       [0.98084, 0.01916],\n",
       "       [0.9709 , 0.0291 ],\n",
       "       [0.99876, 0.00124],\n",
       "       [0.99773, 0.00227],\n",
       "       [0.9426 , 0.0574 ],\n",
       "       [0.62983, 0.37017],\n",
       "       [0.9982 , 0.0018 ],\n",
       "       [0.98845, 0.01155],\n",
       "       [0.95138, 0.04862],\n",
       "       [0.9972 , 0.0028 ],\n",
       "       [0.99725, 0.00275],\n",
       "       [0.99064, 0.00936],\n",
       "       [0.99624, 0.00376],\n",
       "       [0.94453, 0.05547],\n",
       "       [0.98787, 0.01213],\n",
       "       [0.99561, 0.00439],\n",
       "       [0.98883, 0.01117],\n",
       "       [0.98994, 0.01006],\n",
       "       [0.91432, 0.08568],\n",
       "       [0.73206, 0.26794],\n",
       "       [0.95262, 0.04738],\n",
       "       [0.98429, 0.01571],\n",
       "       [0.92293, 0.07707],\n",
       "       [0.9032 , 0.0968 ],\n",
       "       [0.99734, 0.00266],\n",
       "       [0.96071, 0.03929],\n",
       "       [0.99633, 0.00367],\n",
       "       [0.23045, 0.76955],\n",
       "       [0.83476, 0.16524],\n",
       "       [0.89055, 0.10945],\n",
       "       [0.98932, 0.01068],\n",
       "       [0.08661, 0.91339],\n",
       "       [0.98807, 0.01193],\n",
       "       [0.90651, 0.09349],\n",
       "       [0.97501, 0.02499],\n",
       "       [0.99594, 0.00406],\n",
       "       [0.96821, 0.03179],\n",
       "       [0.99748, 0.00252],\n",
       "       [0.85068, 0.14932],\n",
       "       [0.99792, 0.00208],\n",
       "       [0.99543, 0.00457],\n",
       "       [0.97478, 0.02522],\n",
       "       [0.96223, 0.03777],\n",
       "       [0.91556, 0.08444],\n",
       "       [0.93901, 0.06099],\n",
       "       [0.99403, 0.00597],\n",
       "       [0.9649 , 0.03511],\n",
       "       [0.97883, 0.02117],\n",
       "       [0.99433, 0.00567],\n",
       "       [0.11146, 0.88854],\n",
       "       [0.40294, 0.59706],\n",
       "       [0.99446, 0.00554],\n",
       "       [0.9661 , 0.0339 ],\n",
       "       [0.85425, 0.14575],\n",
       "       [0.98347, 0.01653],\n",
       "       [0.94458, 0.05542],\n",
       "       [0.88121, 0.11879],\n",
       "       [0.98825, 0.01175],\n",
       "       [0.95236, 0.04764],\n",
       "       [0.99171, 0.00829],\n",
       "       [0.63143, 0.36857],\n",
       "       [0.97619, 0.02381],\n",
       "       [0.3514 , 0.6486 ],\n",
       "       [0.98524, 0.01476],\n",
       "       [0.84731, 0.15269],\n",
       "       [0.97923, 0.02077],\n",
       "       [0.76347, 0.23653],\n",
       "       [0.99507, 0.00493],\n",
       "       [0.915  , 0.085  ],\n",
       "       [0.82898, 0.17102],\n",
       "       [0.98634, 0.01366],\n",
       "       [0.99785, 0.00215],\n",
       "       [0.99786, 0.00214],\n",
       "       [0.95545, 0.04455],\n",
       "       [0.84793, 0.15207],\n",
       "       [0.9443 , 0.0557 ],\n",
       "       [0.84412, 0.15588],\n",
       "       [0.99059, 0.00941],\n",
       "       [0.99679, 0.00321],\n",
       "       [0.99588, 0.00412],\n",
       "       [0.99155, 0.00845],\n",
       "       [0.99274, 0.00726],\n",
       "       [0.84952, 0.15048],\n",
       "       [0.99724, 0.00276],\n",
       "       [0.99768, 0.00232],\n",
       "       [0.98242, 0.01758],\n",
       "       [0.9619 , 0.0381 ],\n",
       "       [0.19005, 0.80995],\n",
       "       [0.76688, 0.23312],\n",
       "       [0.90088, 0.09912],\n",
       "       [0.91428, 0.08572],\n",
       "       [0.99265, 0.00735],\n",
       "       [0.87114, 0.12886],\n",
       "       [0.9942 , 0.0058 ],\n",
       "       [0.99601, 0.00399],\n",
       "       [0.95662, 0.04338],\n",
       "       [0.92351, 0.0765 ],\n",
       "       [0.99751, 0.00249],\n",
       "       [0.38449, 0.61551],\n",
       "       [0.98553, 0.01447],\n",
       "       [0.89594, 0.10406],\n",
       "       [0.99288, 0.00712],\n",
       "       [0.96587, 0.03413],\n",
       "       [0.99459, 0.00541],\n",
       "       [0.15683, 0.84317],\n",
       "       [0.99704, 0.00295],\n",
       "       [0.98444, 0.01556],\n",
       "       [0.94899, 0.05101],\n",
       "       [0.99048, 0.00952],\n",
       "       [0.96024, 0.03976],\n",
       "       [0.99187, 0.00813],\n",
       "       [0.99013, 0.00987],\n",
       "       [0.99271, 0.00729],\n",
       "       [0.98462, 0.01538],\n",
       "       [0.98408, 0.01592],\n",
       "       [0.33412, 0.66588],\n",
       "       [0.99628, 0.00372],\n",
       "       [0.94113, 0.05887],\n",
       "       [0.92194, 0.07806],\n",
       "       [0.99129, 0.00871],\n",
       "       [0.83426, 0.16574],\n",
       "       [0.2049 , 0.7951 ],\n",
       "       [0.9929 , 0.0071 ],\n",
       "       [0.91395, 0.08605],\n",
       "       [0.99265, 0.00735],\n",
       "       [0.97458, 0.02542],\n",
       "       [0.95461, 0.04539],\n",
       "       [0.99235, 0.00765],\n",
       "       [0.80027, 0.19973],\n",
       "       [0.99181, 0.00819],\n",
       "       [0.94258, 0.05742],\n",
       "       [0.86701, 0.13299],\n",
       "       [0.99807, 0.00193],\n",
       "       [0.97413, 0.02587],\n",
       "       [0.99531, 0.00469],\n",
       "       [0.92417, 0.07583],\n",
       "       [0.92341, 0.07659],\n",
       "       [0.28365, 0.71635],\n",
       "       [0.98489, 0.01511],\n",
       "       [0.98888, 0.01112],\n",
       "       [0.99579, 0.00421],\n",
       "       [0.99562, 0.00438],\n",
       "       [0.97672, 0.02328],\n",
       "       [0.99733, 0.00267],\n",
       "       [0.93214, 0.06786],\n",
       "       [0.54671, 0.45329],\n",
       "       [0.95488, 0.04512],\n",
       "       [0.99829, 0.00171],\n",
       "       [0.99693, 0.00307],\n",
       "       [0.97877, 0.02123],\n",
       "       [0.98314, 0.01686],\n",
       "       [0.3606 , 0.6394 ],\n",
       "       [0.59429, 0.40571],\n",
       "       [0.46598, 0.53402],\n",
       "       [0.1313 , 0.8687 ],\n",
       "       [0.99725, 0.00275],\n",
       "       [0.94737, 0.05263],\n",
       "       [0.99782, 0.00218],\n",
       "       [0.99727, 0.00273],\n",
       "       [0.9594 , 0.0406 ],\n",
       "       [0.96622, 0.03378],\n",
       "       [0.94733, 0.05267],\n",
       "       [0.94288, 0.05712],\n",
       "       [0.99519, 0.00481],\n",
       "       [0.99752, 0.00248],\n",
       "       [0.99801, 0.00199],\n",
       "       [0.99603, 0.00397],\n",
       "       [0.99504, 0.00496],\n",
       "       [0.95046, 0.04954],\n",
       "       [0.91571, 0.08429],\n",
       "       [0.94572, 0.05428],\n",
       "       [0.997  , 0.003  ],\n",
       "       [0.01425, 0.98575],\n",
       "       [0.99661, 0.00339],\n",
       "       [0.99036, 0.00964],\n",
       "       [0.99791, 0.00209],\n",
       "       [0.98624, 0.01376],\n",
       "       [0.92816, 0.07184],\n",
       "       [0.98817, 0.01183],\n",
       "       [0.97902, 0.02098],\n",
       "       [0.85979, 0.14021],\n",
       "       [0.27228, 0.72772],\n",
       "       [0.99336, 0.00664],\n",
       "       [0.33373, 0.66627],\n",
       "       [0.92415, 0.07585],\n",
       "       [0.97189, 0.02811],\n",
       "       [0.79558, 0.20442],\n",
       "       [0.99345, 0.00655],\n",
       "       [0.96274, 0.03726],\n",
       "       [0.9179 , 0.0821 ],\n",
       "       [0.34755, 0.65245],\n",
       "       [0.96974, 0.03026],\n",
       "       [0.96633, 0.03367],\n",
       "       [0.95031, 0.04969],\n",
       "       [0.99394, 0.00606],\n",
       "       [0.99109, 0.00891],\n",
       "       [0.11366, 0.88634],\n",
       "       [0.97241, 0.02759],\n",
       "       [0.96711, 0.03289],\n",
       "       [0.95727, 0.04273],\n",
       "       [0.98656, 0.01344],\n",
       "       [0.98065, 0.01935],\n",
       "       [0.98462, 0.01538],\n",
       "       [0.95932, 0.04068],\n",
       "       [0.99787, 0.00213],\n",
       "       [0.98631, 0.01369],\n",
       "       [0.9833 , 0.0167 ],\n",
       "       [0.83237, 0.16763],\n",
       "       [0.99176, 0.00824],\n",
       "       [0.60646, 0.39354],\n",
       "       [0.99526, 0.00474],\n",
       "       [0.99485, 0.00515],\n",
       "       [0.983  , 0.017  ],\n",
       "       [0.99728, 0.00272],\n",
       "       [0.97373, 0.02627],\n",
       "       [0.97726, 0.02274],\n",
       "       [0.99532, 0.00468],\n",
       "       [0.99837, 0.00163],\n",
       "       [0.78902, 0.21098],\n",
       "       [0.59754, 0.40246],\n",
       "       [0.00584, 0.99416],\n",
       "       [0.98562, 0.01438],\n",
       "       [0.85367, 0.14633],\n",
       "       [0.87922, 0.12078],\n",
       "       [0.99549, 0.00451],\n",
       "       [0.97623, 0.02377],\n",
       "       [0.99315, 0.00685],\n",
       "       [0.99625, 0.00375],\n",
       "       [0.97866, 0.02134],\n",
       "       [0.99576, 0.00424],\n",
       "       [0.98285, 0.01715],\n",
       "       [0.96621, 0.03379],\n",
       "       [0.99422, 0.00578],\n",
       "       [0.99767, 0.00233],\n",
       "       [0.95598, 0.04402],\n",
       "       [0.98508, 0.01492],\n",
       "       [0.99698, 0.00302],\n",
       "       [0.94825, 0.05175],\n",
       "       [0.98985, 0.01015],\n",
       "       [0.99393, 0.00607],\n",
       "       [0.96598, 0.03402],\n",
       "       [0.99469, 0.00531],\n",
       "       [0.93824, 0.06176],\n",
       "       [0.99512, 0.00488],\n",
       "       [0.88961, 0.11039],\n",
       "       [0.98263, 0.01737],\n",
       "       [0.99617, 0.00383],\n",
       "       [0.99506, 0.00494],\n",
       "       [0.99302, 0.00698],\n",
       "       [0.99539, 0.00461],\n",
       "       [0.97816, 0.02184],\n",
       "       [0.44794, 0.55206],\n",
       "       [0.92976, 0.07024],\n",
       "       [0.98517, 0.01483],\n",
       "       [0.98219, 0.01781],\n",
       "       [0.5196 , 0.4804 ],\n",
       "       [0.97059, 0.02941],\n",
       "       [0.99765, 0.00235],\n",
       "       [0.9975 , 0.0025 ],\n",
       "       [0.95388, 0.04612],\n",
       "       [0.99627, 0.00373],\n",
       "       [0.94883, 0.05117],\n",
       "       [0.96491, 0.03509],\n",
       "       [0.97834, 0.02166],\n",
       "       [0.97602, 0.02398],\n",
       "       [0.99735, 0.00265],\n",
       "       [0.97077, 0.02923],\n",
       "       [0.92594, 0.07406],\n",
       "       [0.99213, 0.00787],\n",
       "       [0.9264 , 0.0736 ],\n",
       "       [0.98602, 0.01398],\n",
       "       [0.98663, 0.01337],\n",
       "       [0.99788, 0.00212],\n",
       "       [0.98533, 0.01467],\n",
       "       [0.99497, 0.00503],\n",
       "       [0.99302, 0.00698],\n",
       "       [0.78003, 0.21997],\n",
       "       [0.98046, 0.01954],\n",
       "       [0.97636, 0.02364],\n",
       "       [0.99064, 0.00936],\n",
       "       [0.98495, 0.01505],\n",
       "       [0.96526, 0.03474],\n",
       "       [0.99496, 0.00504],\n",
       "       [0.99724, 0.00276],\n",
       "       [0.80899, 0.19101],\n",
       "       [0.9916 , 0.0084 ],\n",
       "       [0.99841, 0.00159],\n",
       "       [0.99102, 0.00898],\n",
       "       [0.19148, 0.80852],\n",
       "       [0.94603, 0.05397],\n",
       "       [0.98237, 0.01763],\n",
       "       [0.97883, 0.02117],\n",
       "       [0.98422, 0.01578],\n",
       "       [0.96371, 0.03629],\n",
       "       [0.45799, 0.54201],\n",
       "       [0.13467, 0.86533],\n",
       "       [0.98794, 0.01206],\n",
       "       [0.021  , 0.979  ],\n",
       "       [0.98432, 0.01568],\n",
       "       [0.99016, 0.00984],\n",
       "       [0.99846, 0.00154],\n",
       "       [0.31783, 0.68217],\n",
       "       [0.61203, 0.38797],\n",
       "       [0.99831, 0.00169],\n",
       "       [0.99647, 0.00353],\n",
       "       [0.70165, 0.29835],\n",
       "       [0.99285, 0.00715],\n",
       "       [0.1792 , 0.82079],\n",
       "       [0.99787, 0.00213],\n",
       "       [0.96322, 0.03678],\n",
       "       [0.97345, 0.02655],\n",
       "       [0.99299, 0.00701],\n",
       "       [0.97988, 0.02012],\n",
       "       [0.99578, 0.00422],\n",
       "       [0.86154, 0.13847],\n",
       "       [0.47655, 0.52345],\n",
       "       [0.99889, 0.00111],\n",
       "       [0.99767, 0.00233],\n",
       "       [0.99803, 0.00197],\n",
       "       [0.96467, 0.03533],\n",
       "       [0.74544, 0.25456],\n",
       "       [0.99157, 0.00843],\n",
       "       [0.9976 , 0.0024 ],\n",
       "       [0.99292, 0.00708],\n",
       "       [0.99699, 0.00301],\n",
       "       [0.99553, 0.00447],\n",
       "       [0.99745, 0.00255],\n",
       "       [0.74509, 0.25491],\n",
       "       [0.99278, 0.00722],\n",
       "       [0.99706, 0.00294],\n",
       "       [0.9977 , 0.0023 ],\n",
       "       [0.99522, 0.00478],\n",
       "       [0.99463, 0.00537],\n",
       "       [0.95423, 0.04577],\n",
       "       [0.94288, 0.05712],\n",
       "       [0.96991, 0.03009],\n",
       "       [0.99187, 0.00813],\n",
       "       [0.99843, 0.00157],\n",
       "       [0.97937, 0.02063],\n",
       "       [0.996  , 0.004  ],\n",
       "       [0.99844, 0.00156],\n",
       "       [0.99862, 0.00138],\n",
       "       [0.99807, 0.00193],\n",
       "       [0.98853, 0.01147],\n",
       "       [0.92822, 0.07178],\n",
       "       [0.99652, 0.00348],\n",
       "       [0.99617, 0.00383],\n",
       "       [0.95911, 0.04089],\n",
       "       [0.58968, 0.41032],\n",
       "       [0.44429, 0.55571],\n",
       "       [0.99769, 0.00231],\n",
       "       [0.70716, 0.29284],\n",
       "       [0.99837, 0.00163],\n",
       "       [0.97702, 0.02298],\n",
       "       [0.98877, 0.01123],\n",
       "       [0.99789, 0.00211],\n",
       "       [0.98669, 0.01331],\n",
       "       [0.95442, 0.04558],\n",
       "       [0.03297, 0.96703],\n",
       "       [0.84787, 0.15213],\n",
       "       [0.99848, 0.00152],\n",
       "       [0.97212, 0.02788],\n",
       "       [0.96533, 0.03467],\n",
       "       [0.97469, 0.02531],\n",
       "       [0.99057, 0.00943],\n",
       "       [0.39532, 0.60468],\n",
       "       [0.99799, 0.00201],\n",
       "       [0.96745, 0.03255],\n",
       "       [0.98976, 0.01024],\n",
       "       [0.99763, 0.00237],\n",
       "       [0.99147, 0.00853]], dtype=float32)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-02 *\n",
       "  8.7492\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probs_test.detach().data.cpu().numpy()[:, 1].mean()\n",
    "probs_test[:, 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df[\"labels\"] = probs_test.detach().data.cpu().numpy()[:, 1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>numerized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>98481</td>\n",
       "      <td>0.800664</td>\n",
       "      <td>Bud Abbott and Lou Costello always had a good ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 98481, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>88606</td>\n",
       "      <td>0.917258</td>\n",
       "      <td>This film is not your typical Hollywood fare, ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 88606, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>88639</td>\n",
       "      <td>0.791573</td>\n",
       "      <td>Henry Thomas, and Robin Tunny, are a couple of...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 88639, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1636, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>76170</td>\n",
       "      <td>0.585307</td>\n",
       "      <td>This digital horror film brings us into the Mi...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 76170, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 36...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>81803</td>\n",
       "      <td>0.146130</td>\n",
       "      <td>I just saw this on a local independent station...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 81803, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test</td>\n",
       "      <td>93371</td>\n",
       "      <td>0.976136</td>\n",
       "      <td>Those wishing to see film noir remakes, should...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 93371, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 167, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test</td>\n",
       "      <td>87360</td>\n",
       "      <td>0.113354</td>\n",
       "      <td>I never read the book. Now I don't really want...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 87360, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test</td>\n",
       "      <td>88547</td>\n",
       "      <td>0.854794</td>\n",
       "      <td>I think that there was too much action in the ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 88547, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test</td>\n",
       "      <td>88215</td>\n",
       "      <td>0.886257</td>\n",
       "      <td>Have wanted to see this for a while: I never t...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 88215, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 38, 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test</td>\n",
       "      <td>96187</td>\n",
       "      <td>0.951508</td>\n",
       "      <td>This is an interesting, hard to find movie fro...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 96187, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test</td>\n",
       "      <td>81251</td>\n",
       "      <td>0.354020</td>\n",
       "      <td>Well, the Hero and the Terror is slightly belo...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 81251, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 91, 4,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test</td>\n",
       "      <td>98086</td>\n",
       "      <td>0.979950</td>\n",
       "      <td>I have been an avid chipmunk fan since the lat...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 98086, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test</td>\n",
       "      <td>79688</td>\n",
       "      <td>0.189360</td>\n",
       "      <td>42/100. Often referred as \"Tarzan with clothes...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 79688, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12066,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test</td>\n",
       "      <td>90580</td>\n",
       "      <td>0.833677</td>\n",
       "      <td>I caught this movie late one night and never k...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 90580, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test</td>\n",
       "      <td>86756</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>Tyrone Power was cast in the lead as Solomon. ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 86756, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12081,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test</td>\n",
       "      <td>77906</td>\n",
       "      <td>0.079038</td>\n",
       "      <td>This is one of those religious horror films wh...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 77906, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test</td>\n",
       "      <td>95742</td>\n",
       "      <td>0.941689</td>\n",
       "      <td>Being advertised as the most expensive movie e...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 95742, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 131, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test</td>\n",
       "      <td>77455</td>\n",
       "      <td>0.069222</td>\n",
       "      <td>The Jaws rip off is the trashiest of the all t...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 77455, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 454...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test</td>\n",
       "      <td>76454</td>\n",
       "      <td>0.145270</td>\n",
       "      <td>After seeing this film I felt sick to my stoma...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 76454, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test</td>\n",
       "      <td>92650</td>\n",
       "      <td>0.970550</td>\n",
       "      <td>I first saw this mini-series as a child and th...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 92650, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test</td>\n",
       "      <td>98042</td>\n",
       "      <td>0.997075</td>\n",
       "      <td>The beautiful, charming, supremely versatile a...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 98042, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test</td>\n",
       "      <td>81107</td>\n",
       "      <td>0.114117</td>\n",
       "      <td>Everyone I know loves this movie, but I am afr...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 81107, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 316, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test</td>\n",
       "      <td>83839</td>\n",
       "      <td>0.825491</td>\n",
       "      <td>CORRIDORS OF BLOOD &lt;br /&gt;&lt;br /&gt;Aspect ratio: 1...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 83839, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 33, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test</td>\n",
       "      <td>87324</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>If this movie had been directed by a man, he w...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 87324, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 62, 13...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test</td>\n",
       "      <td>84526</td>\n",
       "      <td>0.125871</td>\n",
       "      <td>I like Kevin Bacon and Cathy Moriarty, and I l...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 84526, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test</td>\n",
       "      <td>93868</td>\n",
       "      <td>0.960230</td>\n",
       "      <td>Passion In The Desert exemplifies spatial gran...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 93868, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1649, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test</td>\n",
       "      <td>88605</td>\n",
       "      <td>0.944729</td>\n",
       "      <td>I would recommend this film to anyone who is s...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 88605, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test</td>\n",
       "      <td>84436</td>\n",
       "      <td>0.144978</td>\n",
       "      <td>No budget direct to video tale of aliens in Ar...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 84436, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test</td>\n",
       "      <td>91698</td>\n",
       "      <td>0.827979</td>\n",
       "      <td>Film about the failure of government and the s...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 91698, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 27, 60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test</td>\n",
       "      <td>82413</td>\n",
       "      <td>0.309286</td>\n",
       "      <td>I bought this movie for a couple of dollars at...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 82413, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>test</td>\n",
       "      <td>80982</td>\n",
       "      <td>0.332379</td>\n",
       "      <td>did anyone notice?when miss brook went skinny ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 80982, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 89, 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>test</td>\n",
       "      <td>91715</td>\n",
       "      <td>0.887710</td>\n",
       "      <td>i was very impressed with this production on l...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 91715, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>test</td>\n",
       "      <td>86777</td>\n",
       "      <td>0.218858</td>\n",
       "      <td>I can't knock this film too terribly, because ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 86777, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>test</td>\n",
       "      <td>81441</td>\n",
       "      <td>0.127447</td>\n",
       "      <td>The combination of Dan Haggerty (Elves) and Li...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 81441, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>test</td>\n",
       "      <td>97172</td>\n",
       "      <td>0.853092</td>\n",
       "      <td>Perhaps the deepest cartoon made in the USA, \"...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 97172, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 409, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>test</td>\n",
       "      <td>76066</td>\n",
       "      <td>0.246388</td>\n",
       "      <td>I'm no director or writer or anything related ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 76066, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>test</td>\n",
       "      <td>97373</td>\n",
       "      <td>0.921476</td>\n",
       "      <td>\"Cherry\" tells of a naive, unmarried virgin wh...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 97373, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 16, 97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>test</td>\n",
       "      <td>79730</td>\n",
       "      <td>0.766686</td>\n",
       "      <td>This is one of the best looking films of the p...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 79730, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>test</td>\n",
       "      <td>87434</td>\n",
       "      <td>0.710443</td>\n",
       "      <td>This is among one of many USA attempts of rema...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 87434, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>test</td>\n",
       "      <td>83930</td>\n",
       "      <td>0.462911</td>\n",
       "      <td>I'd never thought that I would be caught sayin...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 83930, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>test</td>\n",
       "      <td>86844</td>\n",
       "      <td>0.142833</td>\n",
       "      <td>This movie was utterly and unequivocally terri...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 86844, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>test</td>\n",
       "      <td>77190</td>\n",
       "      <td>0.157745</td>\n",
       "      <td>My roommate and I have another friend that wor...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 77190, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 77, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>test</td>\n",
       "      <td>83936</td>\n",
       "      <td>0.151391</td>\n",
       "      <td>The fact that this cruddy series could elicit ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 83936, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>test</td>\n",
       "      <td>78994</td>\n",
       "      <td>0.593336</td>\n",
       "      <td>Mediocre at best. Slow, but probably more ente...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 78994, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1572, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>test</td>\n",
       "      <td>87983</td>\n",
       "      <td>0.860947</td>\n",
       "      <td>i see there are great reviews of this film alr...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 87983, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>test</td>\n",
       "      <td>76549</td>\n",
       "      <td>0.776804</td>\n",
       "      <td>After watching this film, I thought to myself,...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 76549, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>test</td>\n",
       "      <td>89227</td>\n",
       "      <td>0.907711</td>\n",
       "      <td>This movie starts off somewhat slowly and gets...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 89227, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>test</td>\n",
       "      <td>98472</td>\n",
       "      <td>0.772110</td>\n",
       "      <td>I grew up with the Abbott and Costello movies,...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 98472, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>test</td>\n",
       "      <td>92694</td>\n",
       "      <td>0.803387</td>\n",
       "      <td>I saw this film at the 2005 Palm Springs Inter...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 92694, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>test</td>\n",
       "      <td>98615</td>\n",
       "      <td>0.979689</td>\n",
       "      <td>I remember seeing this in the early 90's on UK...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 98615, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>test</td>\n",
       "      <td>96298</td>\n",
       "      <td>0.374073</td>\n",
       "      <td>This BRASS EYE special PAEDO-GEDDON was swampe...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 96298, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>test</td>\n",
       "      <td>77215</td>\n",
       "      <td>0.088223</td>\n",
       "      <td>A total and utter travesty of a movie.'Dark po...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 77215, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 6, 951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>test</td>\n",
       "      <td>90501</td>\n",
       "      <td>0.672782</td>\n",
       "      <td>Rather than go on location and make a realisti...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 90501, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 273, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>test</td>\n",
       "      <td>77327</td>\n",
       "      <td>0.192292</td>\n",
       "      <td>Consider \"I Know All\" Action hero is lighting ...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 77327, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1185, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>test</td>\n",
       "      <td>79437</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>I admit to a secret admiration of the original...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 79437, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>test</td>\n",
       "      <td>80957</td>\n",
       "      <td>0.092605</td>\n",
       "      <td>This movie reminds me old B movies, but not in...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 80957, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>test</td>\n",
       "      <td>76319</td>\n",
       "      <td>0.130617</td>\n",
       "      <td>The Man (Gaston Modot) and the Young Girl (Lya...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 76319, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>test</td>\n",
       "      <td>92207</td>\n",
       "      <td>0.870846</td>\n",
       "      <td>i really love this movie , i saw it for the fi...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 92207, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 82...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>test</td>\n",
       "      <td>75575</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>There are some great Canadian films. There are...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 75575, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 54, 35...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>test</td>\n",
       "      <td>75814</td>\n",
       "      <td>0.145314</td>\n",
       "      <td>Detective Sergent Vince De Carlo (James Luisi)...</td>\n",
       "      <td>[\\n, xbos, xfld, 1, 75814, xfld, 1, 3, xfld, 2...</td>\n",
       "      <td>[42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1359, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dataset     id    labels  \\\n",
       "0      test  98481  0.800664   \n",
       "1      test  88606  0.917258   \n",
       "2      test  88639  0.791573   \n",
       "3      test  76170  0.585307   \n",
       "4      test  81803  0.146130   \n",
       "5      test  93371  0.976136   \n",
       "6      test  87360  0.113354   \n",
       "7      test  88547  0.854794   \n",
       "8      test  88215  0.886257   \n",
       "9      test  96187  0.951508   \n",
       "10     test  81251  0.354020   \n",
       "11     test  98086  0.979950   \n",
       "12     test  79688  0.189360   \n",
       "13     test  90580  0.833677   \n",
       "14     test  86756  0.036847   \n",
       "15     test  77906  0.079038   \n",
       "16     test  95742  0.941689   \n",
       "17     test  77455  0.069222   \n",
       "18     test  76454  0.145270   \n",
       "19     test  92650  0.970550   \n",
       "20     test  98042  0.997075   \n",
       "21     test  81107  0.114117   \n",
       "22     test  83839  0.825491   \n",
       "23     test  87324  0.114128   \n",
       "24     test  84526  0.125871   \n",
       "25     test  93868  0.960230   \n",
       "26     test  88605  0.944729   \n",
       "27     test  84436  0.144978   \n",
       "28     test  91698  0.827979   \n",
       "29     test  82413  0.309286   \n",
       "..      ...    ...       ...   \n",
       "970    test  80982  0.332379   \n",
       "971    test  91715  0.887710   \n",
       "972    test  86777  0.218858   \n",
       "973    test  81441  0.127447   \n",
       "974    test  97172  0.853092   \n",
       "975    test  76066  0.246388   \n",
       "976    test  97373  0.921476   \n",
       "977    test  79730  0.766686   \n",
       "978    test  87434  0.710443   \n",
       "979    test  83930  0.462911   \n",
       "980    test  86844  0.142833   \n",
       "981    test  77190  0.157745   \n",
       "982    test  83936  0.151391   \n",
       "983    test  78994  0.593336   \n",
       "984    test  87983  0.860947   \n",
       "985    test  76549  0.776804   \n",
       "986    test  89227  0.907711   \n",
       "987    test  98472  0.772110   \n",
       "988    test  92694  0.803387   \n",
       "989    test  98615  0.979689   \n",
       "990    test  96298  0.374073   \n",
       "991    test  77215  0.088223   \n",
       "992    test  90501  0.672782   \n",
       "993    test  77327  0.192292   \n",
       "994    test  79437  0.149589   \n",
       "995    test  80957  0.092605   \n",
       "996    test  76319  0.130617   \n",
       "997    test  92207  0.870846   \n",
       "998    test  75575  0.005534   \n",
       "999    test  75814  0.145314   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Bud Abbott and Lou Costello always had a good ...   \n",
       "1    This film is not your typical Hollywood fare, ...   \n",
       "2    Henry Thomas, and Robin Tunny, are a couple of...   \n",
       "3    This digital horror film brings us into the Mi...   \n",
       "4    I just saw this on a local independent station...   \n",
       "5    Those wishing to see film noir remakes, should...   \n",
       "6    I never read the book. Now I don't really want...   \n",
       "7    I think that there was too much action in the ...   \n",
       "8    Have wanted to see this for a while: I never t...   \n",
       "9    This is an interesting, hard to find movie fro...   \n",
       "10   Well, the Hero and the Terror is slightly belo...   \n",
       "11   I have been an avid chipmunk fan since the lat...   \n",
       "12   42/100. Often referred as \"Tarzan with clothes...   \n",
       "13   I caught this movie late one night and never k...   \n",
       "14   Tyrone Power was cast in the lead as Solomon. ...   \n",
       "15   This is one of those religious horror films wh...   \n",
       "16   Being advertised as the most expensive movie e...   \n",
       "17   The Jaws rip off is the trashiest of the all t...   \n",
       "18   After seeing this film I felt sick to my stoma...   \n",
       "19   I first saw this mini-series as a child and th...   \n",
       "20   The beautiful, charming, supremely versatile a...   \n",
       "21   Everyone I know loves this movie, but I am afr...   \n",
       "22   CORRIDORS OF BLOOD <br /><br />Aspect ratio: 1...   \n",
       "23   If this movie had been directed by a man, he w...   \n",
       "24   I like Kevin Bacon and Cathy Moriarty, and I l...   \n",
       "25   Passion In The Desert exemplifies spatial gran...   \n",
       "26   I would recommend this film to anyone who is s...   \n",
       "27   No budget direct to video tale of aliens in Ar...   \n",
       "28   Film about the failure of government and the s...   \n",
       "29   I bought this movie for a couple of dollars at...   \n",
       "..                                                 ...   \n",
       "970  did anyone notice?when miss brook went skinny ...   \n",
       "971  i was very impressed with this production on l...   \n",
       "972  I can't knock this film too terribly, because ...   \n",
       "973  The combination of Dan Haggerty (Elves) and Li...   \n",
       "974  Perhaps the deepest cartoon made in the USA, \"...   \n",
       "975  I'm no director or writer or anything related ...   \n",
       "976  \"Cherry\" tells of a naive, unmarried virgin wh...   \n",
       "977  This is one of the best looking films of the p...   \n",
       "978  This is among one of many USA attempts of rema...   \n",
       "979  I'd never thought that I would be caught sayin...   \n",
       "980  This movie was utterly and unequivocally terri...   \n",
       "981  My roommate and I have another friend that wor...   \n",
       "982  The fact that this cruddy series could elicit ...   \n",
       "983  Mediocre at best. Slow, but probably more ente...   \n",
       "984  i see there are great reviews of this film alr...   \n",
       "985  After watching this film, I thought to myself,...   \n",
       "986  This movie starts off somewhat slowly and gets...   \n",
       "987  I grew up with the Abbott and Costello movies,...   \n",
       "988  I saw this film at the 2005 Palm Springs Inter...   \n",
       "989  I remember seeing this in the early 90's on UK...   \n",
       "990  This BRASS EYE special PAEDO-GEDDON was swampe...   \n",
       "991  A total and utter travesty of a movie.'Dark po...   \n",
       "992  Rather than go on location and make a realisti...   \n",
       "993  Consider \"I Know All\" Action hero is lighting ...   \n",
       "994  I admit to a secret admiration of the original...   \n",
       "995  This movie reminds me old B movies, but not in...   \n",
       "996  The Man (Gaston Modot) and the Young Girl (Lya...   \n",
       "997  i really love this movie , i saw it for the fi...   \n",
       "998  There are some great Canadian films. There are...   \n",
       "999  Detective Sergent Vince De Carlo (James Luisi)...   \n",
       "\n",
       "                                        tokenized_text  \\\n",
       "0    [\\n, xbos, xfld, 1, 98481, xfld, 1, 3, xfld, 2...   \n",
       "1    [\\n, xbos, xfld, 1, 88606, xfld, 1, 3, xfld, 2...   \n",
       "2    [\\n, xbos, xfld, 1, 88639, xfld, 1, 3, xfld, 2...   \n",
       "3    [\\n, xbos, xfld, 1, 76170, xfld, 1, 3, xfld, 2...   \n",
       "4    [\\n, xbos, xfld, 1, 81803, xfld, 1, 3, xfld, 2...   \n",
       "5    [\\n, xbos, xfld, 1, 93371, xfld, 1, 3, xfld, 2...   \n",
       "6    [\\n, xbos, xfld, 1, 87360, xfld, 1, 3, xfld, 2...   \n",
       "7    [\\n, xbos, xfld, 1, 88547, xfld, 1, 3, xfld, 2...   \n",
       "8    [\\n, xbos, xfld, 1, 88215, xfld, 1, 3, xfld, 2...   \n",
       "9    [\\n, xbos, xfld, 1, 96187, xfld, 1, 3, xfld, 2...   \n",
       "10   [\\n, xbos, xfld, 1, 81251, xfld, 1, 3, xfld, 2...   \n",
       "11   [\\n, xbos, xfld, 1, 98086, xfld, 1, 3, xfld, 2...   \n",
       "12   [\\n, xbos, xfld, 1, 79688, xfld, 1, 3, xfld, 2...   \n",
       "13   [\\n, xbos, xfld, 1, 90580, xfld, 1, 3, xfld, 2...   \n",
       "14   [\\n, xbos, xfld, 1, 86756, xfld, 1, 3, xfld, 2...   \n",
       "15   [\\n, xbos, xfld, 1, 77906, xfld, 1, 3, xfld, 2...   \n",
       "16   [\\n, xbos, xfld, 1, 95742, xfld, 1, 3, xfld, 2...   \n",
       "17   [\\n, xbos, xfld, 1, 77455, xfld, 1, 3, xfld, 2...   \n",
       "18   [\\n, xbos, xfld, 1, 76454, xfld, 1, 3, xfld, 2...   \n",
       "19   [\\n, xbos, xfld, 1, 92650, xfld, 1, 3, xfld, 2...   \n",
       "20   [\\n, xbos, xfld, 1, 98042, xfld, 1, 3, xfld, 2...   \n",
       "21   [\\n, xbos, xfld, 1, 81107, xfld, 1, 3, xfld, 2...   \n",
       "22   [\\n, xbos, xfld, 1, 83839, xfld, 1, 3, xfld, 2...   \n",
       "23   [\\n, xbos, xfld, 1, 87324, xfld, 1, 3, xfld, 2...   \n",
       "24   [\\n, xbos, xfld, 1, 84526, xfld, 1, 3, xfld, 2...   \n",
       "25   [\\n, xbos, xfld, 1, 93868, xfld, 1, 3, xfld, 2...   \n",
       "26   [\\n, xbos, xfld, 1, 88605, xfld, 1, 3, xfld, 2...   \n",
       "27   [\\n, xbos, xfld, 1, 84436, xfld, 1, 3, xfld, 2...   \n",
       "28   [\\n, xbos, xfld, 1, 91698, xfld, 1, 3, xfld, 2...   \n",
       "29   [\\n, xbos, xfld, 1, 82413, xfld, 1, 3, xfld, 2...   \n",
       "..                                                 ...   \n",
       "970  [\\n, xbos, xfld, 1, 80982, xfld, 1, 3, xfld, 2...   \n",
       "971  [\\n, xbos, xfld, 1, 91715, xfld, 1, 3, xfld, 2...   \n",
       "972  [\\n, xbos, xfld, 1, 86777, xfld, 1, 3, xfld, 2...   \n",
       "973  [\\n, xbos, xfld, 1, 81441, xfld, 1, 3, xfld, 2...   \n",
       "974  [\\n, xbos, xfld, 1, 97172, xfld, 1, 3, xfld, 2...   \n",
       "975  [\\n, xbos, xfld, 1, 76066, xfld, 1, 3, xfld, 2...   \n",
       "976  [\\n, xbos, xfld, 1, 97373, xfld, 1, 3, xfld, 2...   \n",
       "977  [\\n, xbos, xfld, 1, 79730, xfld, 1, 3, xfld, 2...   \n",
       "978  [\\n, xbos, xfld, 1, 87434, xfld, 1, 3, xfld, 2...   \n",
       "979  [\\n, xbos, xfld, 1, 83930, xfld, 1, 3, xfld, 2...   \n",
       "980  [\\n, xbos, xfld, 1, 86844, xfld, 1, 3, xfld, 2...   \n",
       "981  [\\n, xbos, xfld, 1, 77190, xfld, 1, 3, xfld, 2...   \n",
       "982  [\\n, xbos, xfld, 1, 83936, xfld, 1, 3, xfld, 2...   \n",
       "983  [\\n, xbos, xfld, 1, 78994, xfld, 1, 3, xfld, 2...   \n",
       "984  [\\n, xbos, xfld, 1, 87983, xfld, 1, 3, xfld, 2...   \n",
       "985  [\\n, xbos, xfld, 1, 76549, xfld, 1, 3, xfld, 2...   \n",
       "986  [\\n, xbos, xfld, 1, 89227, xfld, 1, 3, xfld, 2...   \n",
       "987  [\\n, xbos, xfld, 1, 98472, xfld, 1, 3, xfld, 2...   \n",
       "988  [\\n, xbos, xfld, 1, 92694, xfld, 1, 3, xfld, 2...   \n",
       "989  [\\n, xbos, xfld, 1, 98615, xfld, 1, 3, xfld, 2...   \n",
       "990  [\\n, xbos, xfld, 1, 96298, xfld, 1, 3, xfld, 2...   \n",
       "991  [\\n, xbos, xfld, 1, 77215, xfld, 1, 3, xfld, 2...   \n",
       "992  [\\n, xbos, xfld, 1, 90501, xfld, 1, 3, xfld, 2...   \n",
       "993  [\\n, xbos, xfld, 1, 77327, xfld, 1, 3, xfld, 2...   \n",
       "994  [\\n, xbos, xfld, 1, 79437, xfld, 1, 3, xfld, 2...   \n",
       "995  [\\n, xbos, xfld, 1, 80957, xfld, 1, 3, xfld, 2...   \n",
       "996  [\\n, xbos, xfld, 1, 76319, xfld, 1, 3, xfld, 2...   \n",
       "997  [\\n, xbos, xfld, 1, 92207, xfld, 1, 3, xfld, 2...   \n",
       "998  [\\n, xbos, xfld, 1, 75575, xfld, 1, 3, xfld, 2...   \n",
       "999  [\\n, xbos, xfld, 1, 75814, xfld, 1, 3, xfld, 2...   \n",
       "\n",
       "                                      numerized_tokens  \n",
       "0    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 5284, ...  \n",
       "1    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 27...  \n",
       "2    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1636, ...  \n",
       "3    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 36...  \n",
       "4    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 56...  \n",
       "5    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 167, 4...  \n",
       "6    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 13...  \n",
       "7    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...  \n",
       "8    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 38, 48...  \n",
       "9    [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "10   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 91, 4,...  \n",
       "11   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 38...  \n",
       "12   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12066,...  \n",
       "13   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...  \n",
       "14   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12081,...  \n",
       "15   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "16   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 131, 6...  \n",
       "17   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 454...  \n",
       "18   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 3...  \n",
       "19   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 10...  \n",
       "20   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 333...  \n",
       "21   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 316, 1...  \n",
       "22   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 33, 92...  \n",
       "23   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 62, 13...  \n",
       "24   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 53...  \n",
       "25   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1649, ...  \n",
       "26   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 73...  \n",
       "27   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 75, 35...  \n",
       "28   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 27, 60...  \n",
       "29   [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 12...  \n",
       "..                                                 ...  \n",
       "970  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 89, 26...  \n",
       "971  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 20...  \n",
       "972  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 19...  \n",
       "973  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 219...  \n",
       "974  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 409, 2...  \n",
       "975  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 16...  \n",
       "976  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 16, 97...  \n",
       "977  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "978  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 9,...  \n",
       "979  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 32...  \n",
       "980  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...  \n",
       "981  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 77, 61...  \n",
       "982  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 218...  \n",
       "983  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1572, ...  \n",
       "984  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 84...  \n",
       "985  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 121, 1...  \n",
       "986  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...  \n",
       "987  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 21...  \n",
       "988  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 23...  \n",
       "989  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 40...  \n",
       "990  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 33...  \n",
       "991  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 6, 951...  \n",
       "992  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 273, 9...  \n",
       "993  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1185, ...  \n",
       "994  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 99...  \n",
       "995  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 13, 23...  \n",
       "996  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 2, 147...  \n",
       "997  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 12, 82...  \n",
       "998  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 54, 35...  \n",
       "999  [42, 43, 14, 18, 0, 14, 18, 68, 14, 39, 1359, ...  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When I first saw the Premiere Episode of Farscape, I had no idea what to expect. I was immensely impressed and satisfied with \"Premiere\". Subsequent re-watches, however, have made numerous flaws apparent to me that I missed initially. \"Premiere\" is not a great Farscape Episode, but it deserves credit for successfully and efficiently setting up the plot and giving the basic back stories to many of the regular characters.<br /><br />The episode begins with John Crichton (Ben Browder), an astronaut and scientist, preparing to launch into space in the Farscape Module, a small space ship perfected by Crichton and his friend DK. Crichton has a revealing conversation with his father, Jack Crichton, and then begins his test flight in space. Of course, everything goes wrong and Crichton is \"shot through a wormhole\" and winds up in \"a distant part of the galaxy\".<br /><br />After exiting the wormhole, Crichton\\'s module is pulled on board a living space ship. From here, the characters and story line for the Farscape series are introduced in an entertaining albeit rushed manner.<br /><br />The regular characters are properly introduced during the first half of the episode. Of course, there is Crichton, played well by Ben Browder. He offers a the audience a sympathetic character to identify with. He\\'s lost and has no idea how to do much of anything. In \"Premiere\", Crichton has to choose between joining the prisoners or the Peacekeepers. He knows nothing at all about either side, but in helping Aeryn (a captured Peacekeeper pilot) it becomes clear that he intends to help the Peacekeepers. He probably would not have ended up siding with the prisoners if it hadn\\'t been for Crais, a Peacekeeper captain, declaring Crichton to be the murderer of his brother. This puts Crichton in an interesting situation: he\\'s stuck with bizarre, violent escaped prisoners in a far-off galaxy about which he knows nothing at all. Crichton\\'s total lack of knowledge of the Farsape world makes him a particularly interesting protagonist during Farscape\\'s first season.<br /><br />The supporting cast is just as compelling. There\\'s Zhaan, a blue Delvian and former prisoner. She\\'s peaceful and reasonable, as opposed to fellow prisoner Ka D\\'Argo, a powerful and hard-headed warrior. Virginia Hey is totally covered in blue makeup, allowing her character of Zhaan to appear cool and convincing. D\\'Argo\\'s mega-makeup, in contrast, is below-par. He looks kind of silly with his giant tentacles and strange nose, and there is something peculiar about his eyes. They look as if they have had some sort of allergic reaction to his makeup. Farscape would give some improvements to his makeup in Season 1, but the overall costume would, for me at least, remain as a problem until Season 2.<br /><br />The puppet/digital characters of Rygel and Pilot are, to put it simply, excellent. Rygel is a tiny Hynerian Dominar who floats around on some sort of hovercraft. In \"Premiere\" he is given some good dialogue but not much else. Pilot nearly steals the show as the liaison between the living ship, Moya, and Moya\\'s passengers. Even in the first episode, Pilot gives off the appearance of being a real, living alien; he never once in the show seems to be a giant, expensive machine.<br /><br />The Peacekeeper characters introduced are quite interesting as well. The Peacekeepers are made up of a race called Sebaceans, who look just like humans. The chief antagonist is introduced in \"Premiere\" as Captian Crais, who believes that Crichton killed his brother. In reality, Crais\\'s brother\\'s death was merely an accident resulting from an accidental collision with Crichton\\'s ship. Aeryn Sun, a pilot who Crichton helps escape, tries to explain that the death was an accident, but Crais just claims that she is \"irreversiby contaminated\" and refused to change his mind. Crais obsession for revenge, warranted or not (it should be clear to Crais that Crichton isn\\'t responsible), is mysterious in \"Premiere\", but would be explained later in the season. Aeryn herself provides an extremely interesting character. By being forced to leave the Peacekeepers, she changes her whole way of life, and is in that regard in a similar (though less severe) situation as Crichton.<br /><br />The actual episode, as mentioned earlier, feels somewhat rushed and clunky. So much happens that not enough time is spent on anything. Also, D\\'Argo (for now) looks kind of silly running around in his mediocre costume trying to appear menacing. Still, \"Premiere\" is solid entertainment. The special effects (such as in the starburst sequences) are impressive. Most of the costumes and the sets on board Moya are original. Despite its flaws, \"Premiere\" is a must-see for Farscape fans. 3/4'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[(test_df.labels>.4) & (test_df.labels<.5)].text.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission\n",
    "\n",
    "test_df[[\"id\", \"labels\"]].to_csv(\"submission_8.24.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.18:\n",
    "Our predictions are working well w the validation set, but not w test set. Test set is predicting mostly negative, although the directionality appears correct. what to do?\n",
    "\n",
    "added test_dl to md. Trying again w fresh classifier. The mean looks good after training two epochs. Training for three more epochs, see if it remains balanced. out of memory error. submit this version to test. gets #5 on leaderboard. bce of around .25 or .27. Train more and see how it improves. training improves w single unfrozen layer. But! With two unfrozen layers, gets unbalanced again!\n",
    "\n",
    "Start afresh. Unfreeze a single layer. trained again. saved. ready for submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqgYMLn5Byb5"
   },
   "source": [
    "8.23\n",
    "Moving to AWS and increasing batch size and bptt length, first insight was that we're able to train our LM to a much better level. That was promising. Second problem we're still running into is that our first training loss drops way to fast, to not believable levels. this correlates w having way skewed predictions. We've brought in JH's parameters from his imdb folder and are now experimenting w increasing the dropout multiplier. \n",
    "\n",
    "why would accuracy be too high? how could that happen? Could we possibly have duplicates w/in the training data set? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WZ1OFAsaMWg2"
   },
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uqeysp4vMWg3"
   },
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "imdb_D.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
